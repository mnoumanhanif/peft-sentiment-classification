{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bc8575-38ec-493e-91c6-4268858abcc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Quick Diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6193b60-8349-4b9b-b148-827b90e4ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Great! PyTorch can see your GPU.\n",
      "GPU Name: NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ Great! PyTorch can see your GPU.\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"❌ Uh oh. PyTorch CANNOT see your GPU.\")\n",
    "    print(\"This is why your training is running on the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef46279-5af2-4611-9ef4-38879a9abe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! PyTorch can see your NVIDIA RTX A4000.\n",
      "GPU Name: NVIDIA RTX A4000\n",
      "\n",
      "✅ bitsandbytes library loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bitsandbytes\n",
    "\n",
    "# 1. Verify PyTorch can see the GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ Success! PyTorch can see your NVIDIA RTX A4000.\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"❌ Error: PyTorch still CANNOT see your GPU.\")\n",
    "\n",
    "# 2. Verify bitsandbytes loaded\n",
    "print(f\"\\n✅ bitsandbytes library loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90ec51-fde0-4fd5-9052-81fcb4f3574c",
   "metadata": {},
   "source": [
    "# DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d2935-e34d-463c-9768-628357834ab7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6682ac1-a83e-4699-a8c3-ff5dcc18c1a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDb dataset...\n",
      "Tokenizing dataset...\n",
      "--- Preprocessing Complete ---\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'label_text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 24904\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'label_text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 24678\n",
      "    })\n",
      "})\n",
      "Example data point: {'labels': tensor(0), 'label_text': 'negative', 'input_ids': tensor([  101,  1045, 12524,  1045,  2572,  8025,  1011,  3756,  2013,  2026,\n",
      "         2678,  3573,  2138,  1997,  2035,  1996,  6704,  2008,  5129,  2009,\n",
      "         2043,  2009,  2001,  2034,  2207,  1999,  3476,  1012,  1045,  2036,\n",
      "         2657,  2008,  2012,  2034,  2009,  2001,  8243,  2011,  1057,  1012,\n",
      "         1055,  1012,  8205,  2065,  2009,  2412,  2699,  2000,  4607,  2023,\n",
      "         2406,  1010,  3568,  2108,  1037,  5470,  1997,  3152,  2641,  1000,\n",
      "         6801,  1000,  1045,  2428,  2018,  2000,  2156,  2023,  2005,  2870,\n",
      "         1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  1996,\n",
      "         5436,  2003,  8857,  2105,  1037,  2402,  4467,  3689,  3076,  2315,\n",
      "        14229,  2040,  4122,  2000,  4553,  2673,  2016,  2064,  2055,  2166,\n",
      "         1012,  1999,  3327,  2016,  4122,  2000,  3579,  2014,  3086,  2015,\n",
      "         2000,  2437,  2070,  4066,  1997,  4516,  2006,  2054,  1996,  2779,\n",
      "        25430, 14728,  2245,  2055,  3056,  2576,  3314,  2107,  2004,  1996,\n",
      "         5148,  2162,  1998,  2679,  3314,  1999,  1996,  2142,  2163,  1012,\n",
      "         1999,  2090,  4851,  8801,  1998,  6623,  7939,  4697,  3619,  1997,\n",
      "         8947,  2055,  2037, 10740,  2006,  4331,  1010,  2016,  2038,  3348,\n",
      "         2007,  2014,  3689,  3836,  1010, 19846,  1010,  1998,  2496,  2273,\n",
      "         1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  2054,\n",
      "         8563,  2033,  2055,  1045,  2572,  8025,  1011,  3756,  2003,  2008,\n",
      "         2871,  2086,  3283,  1010,  2023,  2001,  2641, 26932,  1012,  2428,\n",
      "         1010,  1996,  3348,  1998, 16371, 25469,  5019,  2024,  2261,  1998,\n",
      "         2521,  2090,  1010,  2130,  2059,  2009,  1005,  1055,  2025,  2915,\n",
      "         2066,  2070, 10036,  2135,  2081, 22555,  2080,  1012,  2096,  2026,\n",
      "         2406,  3549,  2568,  2424,  2009, 16880,  1010,  1999,  4507,  3348,\n",
      "         1998, 16371, 25469,  2024,  1037,  2350, 18785,  1999,  4467,  5988,\n",
      "         1012,  2130, 13749,  7849, 24544,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "Setup complete. Ready for training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset  # <--- Changed this line\n",
    "import evaluate                      # <--- Added this line\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Model and Tokenizer ---\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# --- 2. Load Dataset ---\n",
    "print(\"Loading IMDb dataset...\")\n",
    "dataset = load_dataset(\"mteb/imdb\")\n",
    "\n",
    "# --- 3. Define Preprocessing Function ---\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# --- 4. Format Dataset for Training ---\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "print(\"--- Preprocessing Complete ---\")\n",
    "print(tokenized_dataset)\n",
    "print(f\"Example data point: {tokenized_dataset['train'][0]}\")\n",
    "\n",
    "# --- 5. Define Metric Computation Function ---\n",
    "accuracy_metric = evaluate.load(\"accuracy\")  # <--- Changed this line\n",
    "f1_metric = evaluate.load(\"f1\")              # <--- Changed this line\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(\n",
    "        predictions=predictions, references=labels\n",
    "    )[\"accuracy\"]\n",
    "    \n",
    "    f1 = f1_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"macro\"\n",
    "    )[\"f1\"]\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_macro\": f1,\n",
    "    }\n",
    "\n",
    "print(\"Setup complete. Ready for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111de51d-b1da-4d2d-a4f3-8be2a18871df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 1 - Full Fine-Tuning (ExpID 01, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224cb761-08b8-4fdc-8da9-3047c501059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\2457115683.py:37: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 01: Full Fine-Tuning (Seed 42) ---\n",
      "Model: distilbert-base-uncased\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 12:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.245202</td>\n",
       "      <td>0.904692</td>\n",
       "      <td>0.904575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.251912</td>\n",
       "      <td>0.910284</td>\n",
       "      <td>0.910258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 01 (Seed 42) ---\n",
      "Accuracy: 0.9103\n",
      "F1-macro: 0.9103\n",
      "Training Time (s): 728.67\n",
      "Peak VRAM (GB): 1.6534\n",
      "Trainable Params (M): 66.96\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# --- Define the variable from the previous cell ---\n",
    "model_checkpoint = \"distilbert-base-uncased\" \n",
    "\n",
    "# --- 1. Load Model (Method 1: Full Fine-Tuning) ---\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 01) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/full_ft_seed_42\",  # Directory to save results\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,   # 8 * 2 (grad_accum) = 16\n",
    "    gradient_accumulation_steps=2,   # Effective batch size = 16\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    # Other standard settings\n",
    "    logging_dir=\"./logs/full_ft_seed_42\",\n",
    "    eval_strategy=\"epoch\",      # <-- FIX: Renamed from evaluation_strategy\n",
    "    save_strategy=\"epoch\",      # <-- FIX: Renamed from save_strategy\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 # Disables W&B logging\n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "# IMPORTANT: Make sure you have run the cell that defines 'compute_metrics'\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "# a) Count Trainable Parameters\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "# b) Reset CUDA memory stats (if GPU is available)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 01: Full Fine-Tuning (Seed 42) ---\")\n",
    "print(f\"Model: {model_checkpoint}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb = peak_vram_bytes / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 01 ---\n",
    "print(\"\\n--- Results for ExpID 01 (Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb:.4f}\")\n",
    "print(f\"Trainable Params (M): {trainable_params / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e18f2-c6f8-42b1-a6f9-1b9a9dae2428",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 1 - Full Fine-Tuning (ExpID 01, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2995bc8-20f2-42fb-9ca7-1292b31b04a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model for Full Fine-Tuning (Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\726904404.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 01: Full Fine-Tuning (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 12:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.253366</td>\n",
       "      <td>0.903193</td>\n",
       "      <td>0.903129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.249459</td>\n",
       "      <td>0.908056</td>\n",
       "      <td>0.908018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 01 (Seed 43) ---\n",
      "Accuracy: 0.9081\n",
      "F1-macro: 0.9080\n",
      "Training Time (s): 730.37\n",
      "Peak VRAM (GB): 2.4060\n",
      "Trainable Params (M): 66.96\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Model (Method 1: Full Fine-Tuning) ---\n",
    "# We re-load the model to reset its weights\n",
    "print(\"Reloading model for Full Fine-Tuning (Seed 43)...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 01, Seed 43) ---\n",
    "training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/full_ft_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/full_ft_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                 # <-- Changed\n",
    "    # --------------------------\n",
    "    \n",
    "    # Other standard settings\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_s43 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "trainable_params_s43 = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 01: Full Fine-Tuning (Seed 43) ---\")\n",
    "\n",
    "start_time_s43 = time.time()\n",
    "trainer_s43.train()\n",
    "end_time_s43 = time.time()\n",
    "training_time_s43 = end_time_s43 - start_time_s43\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_s43 = peak_vram_bytes_s43 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_s43 = trainer_s43.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 01 (Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 01 (Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_s43:.4f}\")\n",
    "print(f\"Trainable Params (M): {trainable_params_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2be7b-8316-410d-9615-e5e0defb5bcc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Fine-Tuning (ExpID 02, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c3a665-f80e-4f07-9bbf-f080ca2c864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\1134430940.py:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model Parameter Count:\n",
      "Trainable Params: 739586 | All Params: 67694596 | Trainable %: 1.09\n",
      "--- Starting ExpID 02: LoRA r=8 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 10:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.361700</td>\n",
       "      <td>0.335268</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.851524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.324340</td>\n",
       "      <td>0.857565</td>\n",
       "      <td>0.857563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 02 (Seed 42) ---\n",
      "Accuracy: 0.8576\n",
      "F1-macro: 0.8576\n",
      "Training Time (s): 601.62\n",
      "Peak VRAM (GB): 2.2852\n",
      "Trainable Params (M): 0.74\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "# We must reload the base model to apply adapters, \n",
    "# not use the one we've already fine-tuned.\n",
    "print(\"Reloading base model for LoRA...\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 02) ---\n",
    "# From PDF: r=8, targets=[q,v], placement=Attn, alpha=16\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"], # [q,v] for DistilBert's attention\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", # Sequence Classification\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters to the base model ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params} | \"\n",
    "        f\"All Params: {all_param} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "print(\"LoRA Model Parameter Count:\")\n",
    "print_trainable_parameters(lora_model)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 02, Seed 42) ---\n",
    "lora_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r8_seed_42\",\n",
    "    logging_dir=\"./logs/lora_r8_seed_42\",\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "# We pass the lora_model to the Trainer\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model, # <-- Use the lora_model\n",
    "    args=lora_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 02: LoRA r=8 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora = time.time()\n",
    "lora_trainer.train()\n",
    "end_time_lora = time.time()\n",
    "training_time_lora = end_time_lora - start_time_lora\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora = peak_vram_bytes_lora / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora = lora_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 02 ---\n",
    "print(\"\\n--- Results for ExpID 02 (Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora:.4f}\")\n",
    "\n",
    "# Get the trainable param count again to be precise\n",
    "trainable_params_lora = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00955acf-0e3b-4ce3-81fd-7c0bf7950074",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Fine-Tuning (ExpID 02, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81aa9d9-6340-4de1-8a2d-b0d2ff3b8c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\48087584.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "--- Starting ExpID 02: LoRA r=8 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 09:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.339617</td>\n",
       "      <td>0.850798</td>\n",
       "      <td>0.850786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.326476</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.857200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 02 (Seed 43) ---\n",
      "Accuracy: 0.8572\n",
      "F1-macro: 0.8572\n",
      "Training Time (s): 599.71\n",
      "Peak VRAM (GB): 2.5435\n",
      "Trainable Params (M): 0.74\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for LoRA (Seed 43)...\")\n",
    "base_model_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (Same as before) ---\n",
    "lora_config_s43 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model_s43 = get_peft_model(base_model_s43, lora_config_s43)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 02, Seed 43) ---\n",
    "lora_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r8_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/lora_r8_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                 # <-- Changed\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "lora_trainer_s43 = Trainer(\n",
    "    model=lora_model_s43,\n",
    "    args=lora_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 02: LoRA r=8 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_s43 = time.time()\n",
    "lora_trainer_s43.train()\n",
    "end_time_lora_s43 = time.time()\n",
    "training_time_lora_s43 = end_time_lora_s43 - start_time_lora_s43\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_s43 = peak_vram_bytes_lora_s43 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_s43 = lora_trainer_s43.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 02 (Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 02 (Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_s43 = sum(p.numel() for p in lora_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95443471-3b28-4a78-a42a-5fb45b425f01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Rank Sensitivity (ExpID 03, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1072c5-e23e-4445-9194-6d8bfc2e2674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (r=16, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\3270086200.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_r16_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (r=16) adapters...\n",
      "LoRA (r=16) Model Parameter Count:\n",
      "Trainable Params: 887042 | All Params: 67842052 | Trainable %: 1.31\n",
      "--- Starting ExpID 03: LoRA r=16 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 09:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.333224</td>\n",
       "      <td>0.853189</td>\n",
       "      <td>0.853186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323700</td>\n",
       "      <td>0.322730</td>\n",
       "      <td>0.858052</td>\n",
       "      <td>0.858049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 03 (Seed 42) ---\n",
      "Accuracy: 0.8581\n",
      "F1-macro: 0.8580\n",
      "Training Time (s): 598.60\n",
      "Peak VRAM (GB): 2.8056\n",
      "Trainable Params (M): 0.89\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for LoRA (r=16, Seed 42)...\")\n",
    "base_model_r16 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 03) ---\n",
    "# The ONLY change from ExpID 02 is r=16\n",
    "lora_config_r16 = LoraConfig(\n",
    "    r=16, # <-- CHANGED\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"], # [q,v] for DistilBert\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (r=16) adapters...\")\n",
    "lora_model_r16 = get_peft_model(base_model_r16, lora_config_r16)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"LoRA (r=16) Model Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_r16) # Uses the function from ExpID 02\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 03, Seed 42) ---\n",
    "lora_r16_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r16_seed_42\",\n",
    "    logging_dir=\"./logs/lora_r16_seed_42\",\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_r16_trainer = Trainer(\n",
    "    model=lora_model_r16,\n",
    "    args=lora_r16_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 03: LoRA r=16 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_r16 = time.time()\n",
    "lora_r16_trainer.train()\n",
    "end_time_lora_r16 = time.time()\n",
    "training_time_lora_r16 = end_time_lora_r16 - start_time_lora_r16\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_r16 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_r16 = peak_vram_bytes_lora_r16 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_r16 = lora_r16_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 03 (Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 03 (Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_r16['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_r16['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_r16:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_r16:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_r16 = sum(p.numel() for p in lora_model_r16.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_r16 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa73bbe-c513-4beb-bd22-1f9d8ff5173e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Rank Sensitivity (ExpID 03, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26170f4e-cd01-4275-8339-d9d4ca1c2d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (r=16, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\2080378308.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_r16_s43_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (r=16) adapters...\n",
      "--- Starting ExpID 03: LoRA r=16 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 09:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.346800</td>\n",
       "      <td>0.338122</td>\n",
       "      <td>0.851487</td>\n",
       "      <td>0.851479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.336200</td>\n",
       "      <td>0.325093</td>\n",
       "      <td>0.858092</td>\n",
       "      <td>0.858092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 03 (Seed 43) ---\n",
      "Accuracy: 0.8581\n",
      "F1-macro: 0.8581\n",
      "Training Time (s): 598.44\n",
      "Peak VRAM (GB): 3.0656\n",
      "Trainable Params (M): 0.89\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for LoRA (r=16, Seed 43)...\")\n",
    "base_model_r16_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 03) ---\n",
    "lora_config_r16_s43 = LoraConfig(\n",
    "    r=16, # <-- Rank 16\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (r=16) adapters...\")\n",
    "lora_model_r16_s43 = get_peft_model(base_model_r16_s43, lora_config_r16_s43)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 03, Seed 43) ---\n",
    "lora_r16_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r16_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/lora_r16_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                 # <-- Changed\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "lora_r16_s43_trainer = Trainer(\n",
    "    model=lora_model_r16_s43,\n",
    "    args=lora_r16_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 03: LoRA r=16 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_r16_s43 = time.time()\n",
    "lora_r16_s43_trainer.train()\n",
    "end_time_lora_r16_s43 = time.time()\n",
    "training_time_lora_r16_s43 = end_time_lora_r16_s43 - start_time_lora_r16_s43\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_r16_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_r16_s43 = peak_vram_bytes_lora_r16_s43 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_r16_s43 = lora_r16_s43_trainer.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 03 (Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 03 (Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_r16_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_r16_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_r16_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_r16_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_r16_s43 = sum(p.numel() for p in lora_model_r16_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_r16_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fce40-4c50-46bc-b96f-c89a34170842",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Placement (ExpID 04, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88566f0f-f4d4-41c2-9cea-e80a7084ef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (Attn+FFN, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\3572417805.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_ffn_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA (Attn+FFN) Model Parameter Count:\n",
      "Trainable Params: 1624322 | All Params: 68579332 | Trainable %: 2.37\n",
      "--- Starting ExpID 04: LoRA r=16 Attn+FFN (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 11:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>0.310557</td>\n",
       "      <td>0.864859</td>\n",
       "      <td>0.864837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.300236</td>\n",
       "      <td>0.870614</td>\n",
       "      <td>0.870573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 04 (Seed 42) ---\n",
      "Accuracy: 0.8706\n",
      "F1-macro: 0.8706\n",
      "Training Time (s): 690.14\n",
      "Peak VRAM (GB): 3.5674\n",
      "Trainable Params (M): 1.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for LoRA (Attn+FFN, Seed 42)...\")\n",
    "base_model_ffn = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- Optional: Print model to see all layer names ---\n",
    "# print(base_model_ffn) \n",
    "# You would see 'q_lin', 'v_lin' in 'attention'\n",
    "# and 'lin1', 'lin2' in 'ffn'\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 04) ---\n",
    "# We now add the FFN layers 'lin1' and 'lin2'\n",
    "lora_config_ffn = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"], # <-- CHANGED\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_ffn = get_peft_model(base_model_ffn, lora_config_ffn)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"LoRA (Attn+FFN) Model Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_ffn) # Uses the function from ExpID 02\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 04, Seed 42) ---\n",
    "lora_ffn_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r16_ffn_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/lora_r16_ffn_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_ffn_trainer = Trainer(\n",
    "    model=lora_model_ffn,\n",
    "    args=lora_ffn_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 04: LoRA r=16 Attn+FFN (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_ffn = time.time()\n",
    "lora_ffn_trainer.train()\n",
    "end_time_lora_ffn = time.time()\n",
    "training_time_lora_ffn = end_time_lora_ffn - start_time_lora_ffn\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_ffn = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_ffn = peak_vram_bytes_lora_ffn / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_ffn = lora_ffn_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 04 (Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 04 (Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_ffn['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_ffn['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_ffn:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_ffn:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_ffn = sum(p.numel() for p in lora_model_ffn.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_ffn / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04028bdc-5d1c-408e-966b-70f34fe2206e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Placement (ExpID 04, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5a2d428-baec-4b78-90a4-03d841562986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (Attn+FFN, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19708\\2419051285.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_ffn_s43_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "--- Starting ExpID 04: LoRA r=16 Attn+FFN (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 11:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.314523</td>\n",
       "      <td>0.865386</td>\n",
       "      <td>0.865380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.299579</td>\n",
       "      <td>0.870816</td>\n",
       "      <td>0.870797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 04 (Seed 43) ---\n",
      "Accuracy: 0.8708\n",
      "F1-macro: 0.8708\n",
      "Training Time (s): 690.48\n",
      "Peak VRAM (GB): 3.8356\n",
      "Trainable Params (M): 1.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for LoRA (Attn+FFN, Seed 43)...\")\n",
    "base_model_ffn_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 04) ---\n",
    "lora_config_ffn_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"], # Attn + FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_ffn_s43 = get_peft_model(base_model_ffn_s43, lora_config_ffn_s43)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 04, Seed 43) ---\n",
    "lora_ffn_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r16_ffn_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/lora_r16_ffn_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                 # <-- Changed\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "lora_ffn_s43_trainer = Trainer(\n",
    "    model=lora_model_ffn_s43,\n",
    "    args=lora_ffn_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 04: LoRA r=16 Attn+FFN (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_ffn_s43 = time.time()\n",
    "lora_ffn_s43_trainer.train()\n",
    "end_time_lora_ffn_s43 = time.time()\n",
    "training_time_lora_ffn_s43 = end_time_lora_ffn_s43 - start_time_lora_ffn_s43\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_ffn_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_ffn_s43 = peak_vram_bytes_lora_ffn_s43 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_ffn_s43 = lora_ffn_s43_trainer.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 04 (Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 04 (Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_ffn_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_ffn_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_ffn_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_ffn_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_ffn_s43 = sum(p.numel() for p in lora_model_ffn_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_ffn_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8f176-57bf-46ca-b613-9e5546f50801",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 3 - QLORA (ExpID 05, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "618e1a6b-ee06-41bc-91df-2e3b1bd8b73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading fresh base model (safe)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model for k-bit training...\n",
      "Diagnostic check for modules_to_check: ['classifier', 'pre_classifier']\n",
      "[ok] classifier: can be set to requires_grad.\n",
      "[fail] pre_classifier: cannot be made trainable -> only Tensors of floating point dtype can require gradients\n",
      "[replace] pre_classifier: replaced with nn.Linear(1->294912) float32\n",
      "One or more failing modules were replaced with float nn.Linear. Retesting makes sense.\n",
      "[ok] classifier: can be set to requires_grad.\n",
      "[ok] pre_classifier: can be set to requires_grad.\n",
      "All checked modules are now float/trainable (or absent). Proceeding to get_peft_model.\n",
      "PEFT injection complete. Model is ready.\n"
     ]
    }
   ],
   "source": [
    "# Safe auto-diagnostic + minimal auto-fix for the 'only Tensors of floating point dtype can require gradients' error\n",
    "import torch, torch.nn as nn\n",
    "from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
    "\n",
    "# --- Adjust these as in your environment ---\n",
    "model_checkpoint = model_checkpoint  # keep your variable\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
    "                               bnb_4bit_compute_dtype=torch.float16, bnb_4bit_use_double_quant=True)\n",
    "\n",
    "# --- 0. Reload a fresh base model (avoids \"modified a model with PEFT for a second time\" issues) ---\n",
    "print(\"Reloading fresh base model (safe)...\")\n",
    "base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=2, quantization_config=bnb_config, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# --- 1. prepare for k-bit training ---\n",
    "print(\"Preparing model for k-bit training...\")\n",
    "base = prepare_model_for_kbit_training(base)\n",
    "\n",
    "# --- 2. define your LoRA config (modules_to_save should include classifier or other small heads you want saved) ---\n",
    "qlora_lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    modules_to_save=[\"classifier\", \"pre_classifier\"]  # include suspected small heads\n",
    ")\n",
    "\n",
    "# --- Helper: test requires_grad on every parameter in a named module; returns True if OK, False if fails ---\n",
    "def test_set_requires_grad(model, module_path):\n",
    "    parts = module_path.split(\".\")\n",
    "    parent = model\n",
    "    try:\n",
    "        for p in parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        name = parts[-1]\n",
    "        mod = getattr(parent, name)\n",
    "    except Exception:\n",
    "        print(f\"[test] {module_path} not found.\")\n",
    "        return True  # treat missing as okay for now\n",
    "\n",
    "    # attempt to set requires_grad on every parameter of that module (in try/except)\n",
    "    try:\n",
    "        for param in mod.parameters():\n",
    "            param.requires_grad_(True)\n",
    "        # restore to False (we're just testing)\n",
    "        for param in mod.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        print(f\"[ok] {module_path}: can be set to requires_grad.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[fail] {module_path}: cannot be made trainable -> {e}\")\n",
    "        return False\n",
    "\n",
    "# --- 3. Run diagnostics on modules_to_save and common heads ---\n",
    "modules_to_check = list(set(qlora_lora_config.modules_to_save or [] + [\"classifier\", \"pre_classifier\"]))\n",
    "print(\"Diagnostic check for modules_to_check:\", modules_to_check)\n",
    "\n",
    "failing = []\n",
    "for m in modules_to_check:\n",
    "    ok = test_set_requires_grad(base, m)\n",
    "    if not ok:\n",
    "        failing.append(m)\n",
    "\n",
    "# --- 4. Auto-replace only failing modules with small float nn.Linear if possible ---\n",
    "def replace_with_linear_if_quantized(model, module_path):\n",
    "    parts = module_path.split(\".\")\n",
    "    parent = model\n",
    "    try:\n",
    "        for p in parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        name = parts[-1]\n",
    "        orig = getattr(parent, name)\n",
    "    except Exception:\n",
    "        print(f\"[replace] {module_path}: not found, skipping.\")\n",
    "        return False\n",
    "\n",
    "    # If already float, nothing to do\n",
    "    if hasattr(orig, \"weight\") and orig.weight.is_floating_point():\n",
    "        print(f\"[replace] {module_path}: already float ({orig.weight.dtype}).\")\n",
    "        return True\n",
    "\n",
    "    # Replace only if we can infer a 2D weight (linear)\n",
    "    if hasattr(orig, \"weight\") and orig.weight.ndim == 2:\n",
    "        w = orig.weight\n",
    "        out_f, in_f = w.shape\n",
    "        bias_exists = hasattr(orig, \"bias\") and getattr(orig, \"bias\") is not None\n",
    "        new = nn.Linear(in_f, out_f, bias=bias_exists)\n",
    "        # move new to same device as model params\n",
    "        dev = next(model.parameters()).device\n",
    "        new = new.to(device=dev, dtype=torch.float32)\n",
    "        setattr(parent, name, new)\n",
    "        print(f\"[replace] {module_path}: replaced with nn.Linear({in_f}->{out_f}) float32\")\n",
    "        return True\n",
    "\n",
    "    print(f\"[replace] {module_path}: cannot infer shape (skipped).\")\n",
    "    return False\n",
    "\n",
    "replaced_any = False\n",
    "for m in failing:\n",
    "    replaced = replace_with_linear_if_quantized(base, m)\n",
    "    replaced_any = replaced_any or replaced\n",
    "\n",
    "if replaced_any:\n",
    "    print(\"One or more failing modules were replaced with float nn.Linear. Retesting makes sense.\")\n",
    "    # re-run diagnostic to confirm\n",
    "    failing = [m for m in modules_to_check if not test_set_requires_grad(base, m)]\n",
    "\n",
    "if len(failing) > 0:\n",
    "    print(\"Still failing modules after auto-replacements:\", failing)\n",
    "    print(\"Please paste this list if you want me to craft replacements manually.\")\n",
    "else:\n",
    "    print(\"All checked modules are now float/trainable (or absent). Proceeding to get_peft_model.\")\n",
    "\n",
    "# --- 5. Now call get_peft_model safely ---\n",
    "qlora_model = get_peft_model(base, qlora_lora_config)\n",
    "print(\"PEFT injection complete. Model is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9a2c81-6c0d-4f33-952c-4023dc4e27bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\3661179343.py:118: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "Detected hidden size: 768\n",
      "✅ pre_classifier fixed as nn.Linear(768, 768)\n",
      "🔹 Applying LoRA adapters...\n",
      "✅ LoRA adapters successfully injected.\n",
      "Trainable params: 1,624,322 / 47,345,668 (3.43% trainable)\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "\n",
      "🚀 Starting QLoRA Fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 16:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>0.313890</td>\n",
       "      <td>0.865305</td>\n",
       "      <td>0.865277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>0.301151</td>\n",
       "      <td>0.871505</td>\n",
       "      <td>0.871477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === QLoRA Experiment Summary ===\n",
      "Accuracy: 0.8715\n",
      "F1-macro: 0.8715\n",
      "Training Time: 16.60 min\n",
      "Peak VRAM Usage: 0.65 GB\n",
      "Trainable Params: 1.62M / 47.35M (3.43% trainable)\n",
      "\n",
      "✅ Training completed successfully.\n",
      "💾 Model and tokenizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# ✅ QLoRA Fine-Tuning (DistilBERT, r=16) — Final Stable Version\n",
    "# ================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# ================================================================\n",
    "# 1️⃣ Load quantized DistilBERT\n",
    "# ================================================================\n",
    "model_checkpoint = \"distilbert-base-uncased\"   # or your own checkpoint\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "print(\"🔹 Loading 4-bit quantized model...\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# 2️⃣ Prepare for k-bit training\n",
    "# ================================================================\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# ================================================================\n",
    "# 3️⃣ Ensure pre_classifier is float & correct shape\n",
    "# ================================================================\n",
    "hidden_size = getattr(base_model.config, \"hidden_size\", 768)\n",
    "device = next(base_model.parameters()).device\n",
    "print(f\"Detected hidden size: {hidden_size}\")\n",
    "\n",
    "# Replace pre_classifier safely (768→768 for DistilBERT)\n",
    "base_model.pre_classifier = nn.Linear(hidden_size, hidden_size).to(device=device, dtype=torch.float32)\n",
    "print(f\"✅ pre_classifier fixed as nn.Linear({hidden_size}, {hidden_size})\")\n",
    "\n",
    "# ================================================================\n",
    "# 4️⃣ Define LoRA configuration\n",
    "# ================================================================\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    modules_to_save=[\"classifier\", \"pre_classifier\"],  # safe now\n",
    ")\n",
    "\n",
    "print(\"🔹 Applying LoRA adapters...\")\n",
    "qlora_model = get_peft_model(base_model, lora_config)\n",
    "print(\"✅ LoRA adapters successfully injected.\")\n",
    "\n",
    "# ================================================================\n",
    "# 5️⃣ Print parameter summary\n",
    "# ================================================================\n",
    "def print_trainable_parameters(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable params: {trainable:,} / {total:,} \"\n",
    "          f\"({100 * trainable / total:.2f}% trainable)\")\n",
    "\n",
    "print_trainable_parameters(qlora_model)\n",
    "\n",
    "# ================================================================\n",
    "# 6️⃣ Optimizer fallback\n",
    "# ================================================================\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ bitsandbytes optimizer not usable ({e}), falling back to adamw_torch.\")\n",
    "    optim_choice = \"adamw_torch\"\n",
    "\n",
    "# ================================================================\n",
    "# 7️⃣ TrainingArguments\n",
    "# ================================================================\n",
    "qlora_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/qlora_r16_seed_42\",\n",
    "    logging_dir=\"./logs/qlora_r16_seed_42\",\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    optim=optim_choice,\n",
    "    eval_strategy=\"epoch\",          # correct for your transformers version\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# 8️⃣ Initialize Trainer (define compute_metrics earlier)\n",
    "# ================================================================\n",
    "qlora_trainer = Trainer(\n",
    "    model=qlora_model,\n",
    "    args=qlora_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# 9️⃣ Train and evaluate\n",
    "# ================================================================\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(\"\\n🚀 Starting QLoRA Fine-tuning...\")\n",
    "start_time = time.time()\n",
    "train_result = qlora_trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# ================================================================\n",
    "# 🔟 Evaluate and report\n",
    "# ================================================================\n",
    "print(\"\\n🔹 Evaluating on test set...\")\n",
    "eval_results = qlora_trainer.evaluate()\n",
    "\n",
    "peak_vram_gb = (torch.cuda.max_memory_allocated() / (1024**3)) if torch.cuda.is_available() else 0\n",
    "\n",
    "print(\"\\n📊 === QLoRA Experiment Summary ===\")\n",
    "print(f\"Accuracy: {eval_results.get('eval_accuracy', 0):.4f}\")\n",
    "print(f\"F1-macro: {eval_results.get('eval_f1_macro', 0):.4f}\")\n",
    "print(f\"Training Time: {training_time/60:.2f} min\")\n",
    "print(f\"Peak VRAM Usage: {peak_vram_gb:.2f} GB\")\n",
    "\n",
    "trainable_params = sum(p.numel() for p in qlora_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in qlora_model.parameters())\n",
    "print(f\"Trainable Params: {trainable_params/1_000_000:.2f}M / {total_params/1_000_000:.2f}M \"\n",
    "      f\"({100*trainable_params/total_params:.2f}% trainable)\")\n",
    "\n",
    "print(\"\\n✅ Training completed successfully.\")\n",
    "\n",
    "# ================================================================\n",
    "# 11️⃣ Optional: Save final model\n",
    "# ================================================================\n",
    "qlora_model.save_pretrained(\"./qlora_distilbert_lora_r16_seed42\")\n",
    "tokenizer.save_pretrained(\"./qlora_distilbert_lora_r16_seed42\")\n",
    "print(\"💾 Model and tokenizer saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdf5f2-bfc6-4437-bc4f-e935c2e2087b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 3 - QLORA (ExpID 05, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fbd9cf5-ceaa-4d05-b5bf-4fcf693427f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model (Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\2747728494.py:67: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "✅ pre_classifier fixed as nn.Linear(768, 768)\n",
      "🔹 Applying LoRA adapters...\n",
      "✅ LoRA adapters successfully injected.\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "\n",
      "🚀 Starting QLoRA Fine-tuning (Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 16:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.330500</td>\n",
       "      <td>0.319542</td>\n",
       "      <td>0.863968</td>\n",
       "      <td>0.863966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.302799</td>\n",
       "      <td>0.869195</td>\n",
       "      <td>0.869191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 === QLoRA Experiment Summary (Seed 43) ===\n",
      "Accuracy: 0.8692\n",
      "F1-macro: 0.8692\n",
      "Training Time: 16.52 min\n",
      "Peak VRAM Usage: 0.77 GB\n",
      "Trainable Params (M): 1.62M\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load 4-bit Quantized Base Model ---\n",
    "print(\"🔹 Loading 4-bit quantized model (Seed 43)...\")\n",
    "bnb_config_s43 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "base_model_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config_s43,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# --- 2. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "base_model_s43 = prepare_model_for_kbit_training(base_model_s43)\n",
    "\n",
    "# --- 3. Ensure pre_classifier is float & correct shape ---\n",
    "hidden_size_s43 = getattr(base_model_s43.config, \"hidden_size\", 768)\n",
    "device_s43 = next(base_model_s43.parameters()).device\n",
    "base_model_s43.pre_classifier = nn.Linear(hidden_size_s43, hidden_size_s43).to(device=device_s43, dtype=torch.float32)\n",
    "print(f\"✅ pre_classifier fixed as nn.Linear({hidden_size_s43}, {hidden_size_s43})\")\n",
    "\n",
    "# --- 4. Define LoRA configuration ---\n",
    "lora_config_s43 = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    modules_to_save=[\"classifier\", \"pre_classifier\"],\n",
    ")\n",
    "print(\"🔹 Applying LoRA adapters...\")\n",
    "qlora_model_s43 = get_peft_model(base_model_s43, lora_config_s43)\n",
    "print(\"✅ LoRA adapters successfully injected.\")\n",
    "\n",
    "# --- 5. Optimizer fallback ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice_s43 = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except Exception:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice_s43 = \"adamw_torch\"\n",
    "\n",
    "# --- 6. TrainingArguments ---\n",
    "qlora_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/qlora_r16_seed_43\",  # <-- CHANGED\n",
    "    logging_dir=\"./logs/qlora_r16_seed_43\",    # <-- CHANGED\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                  # <-- CHANGED\n",
    "    optim=optim_choice_s43,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# --- 7. Initialize Trainer ---\n",
    "qlora_trainer_s43 = Trainer(\n",
    "    model=qlora_model_s43,\n",
    "    args=qlora_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# --- 8. Train and evaluate ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(\"\\n🚀 Starting QLoRA Fine-tuning (Seed 43)...\")\n",
    "start_time_s43 = time.time()\n",
    "qlora_trainer_s43.train()\n",
    "end_time_s43 = time.time()\n",
    "training_time_s43 = end_time_s43 - start_time_s43\n",
    "\n",
    "# --- 9. Evaluate and report ---\n",
    "print(\"\\n🔹 Evaluating on test set...\")\n",
    "eval_results_s43 = qlora_trainer_s43.evaluate()\n",
    "\n",
    "peak_vram_gb_s43 = (torch.cuda.max_memory_allocated() / (1024**3)) if torch.cuda.is_available() else 0\n",
    "\n",
    "print(\"\\n📊 === QLoRA Experiment Summary (Seed 43) ===\")\n",
    "print(f\"Accuracy: {eval_results_s43.get('eval_accuracy', 0):.4f}\")\n",
    "print(f\"F1-macro: {eval_results_s43.get('eval_f1_macro', 0):.4f}\")\n",
    "print(f\"Training Time: {training_time_s43/60:.2f} min\")\n",
    "print(f\"Peak VRAM Usage: {peak_vram_gb_s43:.2f} GB\")\n",
    "\n",
    "trainable_params_s43 = sum(p.numel() for p in qlora_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_s43/1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7aef1-ff56-4bcd-bdf8-d47191a4e5e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 4 - Adapter Tuning (IA³) (ExpID 06, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf976bdd-4ffc-41b2-a3b6-6e3b73a950d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for IA³...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\3739718729.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable params: 615,170 / 67,570,180 (0.91% trainable)\n",
      "--- Starting ExpID 06: IA³ Attn+FFN (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 09:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.547100</td>\n",
       "      <td>0.508368</td>\n",
       "      <td>0.809061</td>\n",
       "      <td>0.809036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.472900</td>\n",
       "      <td>0.462834</td>\n",
       "      <td>0.815747</td>\n",
       "      <td>0.815743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 06 (Seed 42) ---\n",
      "Accuracy: 0.8157\n",
      "F1-macro: 0.8157\n",
      "Training Time (s): 597.67\n",
      "Peak VRAM (GB): 1.3990\n",
      "Trainable Params (M): 0.62\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, IA3Config\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for IA³...\")\n",
    "base_model_ia3 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (ExpID 06) ---\n",
    "# PDF: Location=Attn+FFN, targets=v-only\n",
    "# For DistilBert, this means 'v_lin' in attention and 'lin2' in the FFN.\n",
    "ia3_config = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"v_lin\", \"lin2\"],  # <-- FIX: List ALL targets here\n",
    "    feedforward_modules=[\"lin2\"],   # <-- FIX: List FFN layers here (must be subset of above)\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model = get_peft_model(base_model_ia3, ia3_config)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model) # Uses the function from ExpID 02\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 06, Seed 42) ---\n",
    "ia3_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/ia3_ffn_seed_42\",\n",
    "    logging_dir=\"./logs/ia3_ffn_seed_42\",   \n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer = Trainer(\n",
    "    model=ia3_model,\n",
    "    args=ia3_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 06: IA³ Attn+FFN (Seed 42) ---\")\n",
    "\n",
    "start_time_ia3 = time.time()\n",
    "ia3_trainer.train()\n",
    "end_time_ia3 = time.time()\n",
    "training_time_ia3 = end_time_ia3 - start_time_ia3\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3 = peak_vram_bytes_ia3 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3 = ia3_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 06 (Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 06 (Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3 = sum(p.numel() for p in ia3_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07014e00-5551-45cd-87c8-227de86c41c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 3 - QLORA (ExpID 05, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75e339f3-21ce-4c12-9ad2-c90ad4a7288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for IA³ (Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\1462578776.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "--- Starting ExpID 06: IA³ Attn+FFN (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 09:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.552400</td>\n",
       "      <td>0.517113</td>\n",
       "      <td>0.806062</td>\n",
       "      <td>0.805919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>0.813153</td>\n",
       "      <td>0.813151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 06 (Seed 43) ---\n",
      "Accuracy: 0.8132\n",
      "F1-macro: 0.8132\n",
      "Training Time (s): 598.99\n",
      "Peak VRAM (GB): 1.6573\n",
      "Trainable Params (M): 0.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for IA³ (Seed 43)...\")\n",
    "base_model_ia3_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (ExpID 06) ---\n",
    "ia3_config_s43 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"v_lin\", \"lin2\"],  # Attn + FFN\n",
    "    feedforward_modules=[\"lin2\"],   # FFN layers\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_s43 = get_peft_model(base_model_ia3_s43, ia3_config_s43)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 06, Seed 43) ---\n",
    "ia3_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/ia3_ffn_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/ia3_ffn_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                               # <-- Changed\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "ia3_trainer_s43 = Trainer(\n",
    "    model=ia3_model_s43,\n",
    "    args=ia3_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 06: IA³ Attn+FFN (Seed 43) ---\")\n",
    "\n",
    "start_time_ia3_s43 = time.time()\n",
    "ia3_trainer_s43.train()\n",
    "end_time_ia3_s43 = time.time()\n",
    "training_time_ia3_s43 = end_time_ia3_s43 - start_time_ia3_s43\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_s43 = peak_vram_bytes_ia3_s43 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_s43 = ia3_trainer_s43.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 06 (Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 06 (Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_s43 = sum(p.numel() for p in ia3_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f10f5-4bc8-43d8-91d7-99ad9bcaf87a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a853532-10a5-4441-ab76-020d14783207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\704383729.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_ft_lr2 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 07: Full FT, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 12:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.256462</td>\n",
       "      <td>0.904247</td>\n",
       "      <td>0.904018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.272858</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.913679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (Full FT, Seed 42) ---\n",
      "Accuracy: 0.9137\n",
      "F1-macro: 0.9137\n",
      "Training Time (s): 748.98\n",
      "Peak VRAM (GB): 2.6488\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Model (Full Fine-Tuning) ---\n",
    "print(\"Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 42)...\")\n",
    "model_ft_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 07, Full FT) ---\n",
    "training_args_ft_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/full_ft_lr2_seed_42\",  # <-- Changed\n",
    "    logging_dir=\"./logs/full_ft_lr2_seed_42\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_ft_lr2 = Trainer(\n",
    "    model=model_ft_lr2,\n",
    "    args=training_args_ft_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: Full FT, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_ft_lr2 = time.time()\n",
    "trainer_ft_lr2.train()\n",
    "end_time_ft_lr2 = time.time()\n",
    "training_time_ft_lr2 = end_time_ft_lr2 - start_time_ft_lr2\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_ft_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ft_lr2 = peak_vram_bytes_ft_lr2 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ft_lr2 = trainer_ft_lr2.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 07 (Full FT, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (Full FT, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ft_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ft_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ft_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ft_lr2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21447eb-d228-4445-aa4d-624b34732658",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f5e59e3-78eb-45a5-8b7a-aee28a2d2c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\3793349534.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_ft_lr2_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 07: Full FT, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 12:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.260791</td>\n",
       "      <td>0.906637</td>\n",
       "      <td>0.906557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.258446</td>\n",
       "      <td>0.913364</td>\n",
       "      <td>0.913347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (Full FT, Seed 43) ---\n",
      "Accuracy: 0.9134\n",
      "F1-macro: 0.9133\n",
      "Training Time (s): 749.50\n",
      "Peak VRAM (GB): 3.4007\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Model (Full Fine-Tuning) ---\n",
    "print(\"Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 43)...\")\n",
    "model_ft_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 07, Full FT, Seed 43) ---\n",
    "training_args_ft_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/full_ft_lr2_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/full_ft_lr2_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_ft_lr2_s43 = Trainer(\n",
    "    model=model_ft_lr2_s43,\n",
    "    args=training_args_ft_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: Full FT, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_ft_lr2_s43 = time.time()\n",
    "trainer_ft_lr2_s43.train()\n",
    "end_time_ft_lr2_s43 = time.time()\n",
    "training_time_ft_lr2_s43 = end_time_ft_lr2_s43 - start_time_ft_lr2_s43\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_ft_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ft_lr2_s43 = peak_vram_bytes_ft_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ft_lr2_s43 = trainer_ft_lr2_s43.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 07 (Full FT, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (Full FT, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ft_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ft_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ft_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ft_lr2_s43:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ab4e5-fff5-4edf-aeea-54ba7d544ae4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, LoRA, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc1e0d8f-d282-40d0-b12d-dcde5f4a097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\4153122601.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_lr2_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "--- Starting ExpID 07: LoRA r=16 Attn+FFN, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 11:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.286867</td>\n",
       "      <td>0.878191</td>\n",
       "      <td>0.878112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.276663</td>\n",
       "      <td>0.883337</td>\n",
       "      <td>0.883282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (LoRA, Seed 42) ---\n",
      "Accuracy: 0.8833\n",
      "F1-macro: 0.8833\n",
      "Training Time (s): 704.68\n",
      "Peak VRAM (GB): 3.5138\n",
      "Trainable Params (M): 1.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 42)...\")\n",
    "base_model_lora_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (Same as ExpID 04) ---\n",
    "lora_config_lr2 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"], # Attn + FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_lr2 = get_peft_model(base_model_lora_lr2, lora_config_lr2)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 07, LoRA, Seed 42) ---\n",
    "lora_lr2_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r16_ffn_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/lora_r16_ffn_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "lora_lr2_trainer = Trainer(\n",
    "    model=lora_model_lr2,\n",
    "    args=lora_lr2_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: LoRA r=16 Attn+FFN, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_lr2 = time.time()\n",
    "lora_lr2_trainer.train()\n",
    "end_time_lora_lr2 = time.time()\n",
    "training_time_lora_lr2 = end_time_lora_lr2 - start_time_lora_lr2\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_lr2 = peak_vram_bytes_lora_lr2 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_lr2 = lora_lr2_trainer.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 07 (LoRA, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (LoRA, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_lr2:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_lr2 = sum(p.numel() for p in lora_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b1a7e-35fa-48a9-93c4-cfbc77ff45e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, LoRA, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ae22c69-5e5a-48e1-a658-2936222fffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\1446254035.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_lr2_s43_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "--- Starting ExpID 07: LoRA r=16 Attn+FFN, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 11:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.288945</td>\n",
       "      <td>0.878434</td>\n",
       "      <td>0.878424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.289700</td>\n",
       "      <td>0.274506</td>\n",
       "      <td>0.884229</td>\n",
       "      <td>0.884204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (LoRA, Seed 43) ---\n",
      "Accuracy: 0.8842\n",
      "F1-macro: 0.8842\n",
      "Training Time (s): 703.27\n",
      "Peak VRAM (GB): 3.7824\n",
      "Trainable Params (M): 1.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 43)...\")\n",
    "base_model_lora_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (Same as ExpID 04) ---\n",
    "lora_config_lr2_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"], # Attn + FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_lr2_s43 = get_peft_model(base_model_lora_lr2_s43, lora_config_lr2_s43)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 07, LoRA, Seed 43) ---\n",
    "lora_lr2_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/lora_r16_ffn_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/lora_r16_ffn_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "lora_lr2_s43_trainer = Trainer(\n",
    "    model=lora_model_lr2_s43,\n",
    "    args=lora_lr2_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: LoRA r=16 Attn+FFN, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_lr2_s43 = time.time()\n",
    "lora_lr2_s43_trainer.train()\n",
    "end_time_lora_lr2_s43 = time.time()\n",
    "training_time_lora_lr2_s43 = end_time_lora_lr2_s43 - start_time_lora_lr2_s43\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_lr2_s43 = peak_vram_bytes_lora_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_lr2_s43 = lora_lr2_s43_trainer.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 07 (LoRA, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (LoRA, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_lr2_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_lr2_s43 = sum(p.numel() for p in lora_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc9527-da1a-44dc-a39b-72c9e6822948",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, QLORA, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e65cb850-8b6c-4334-b525-410433cd61cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\1656351016.py:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer_lr2 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "✅ pre_classifier fixed as nn.Linear(768, 768)\n",
      "🔹 Applying LoRA adapters...\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 07: QLORA r=16, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 16:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.294374</td>\n",
       "      <td>0.875517</td>\n",
       "      <td>0.875369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.278556</td>\n",
       "      <td>0.883824</td>\n",
       "      <td>0.883762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (QLORA, Seed 42) ---\n",
      "Accuracy: 0.8838\n",
      "F1-macro: 0.8838\n",
      "Training Time (s): 988.63\n",
      "Peak VRAM (GB): 3.3912\n",
      "Trainable Params (M): 1.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define Quantization Config (for QLORA) ---\n",
    "bnb_config_lr2 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 2. Load the 4-bit Quantized Base Model ---\n",
    "print(\"🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 42)...\")\n",
    "qlora_base_model_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config_lr2,\n",
    "    device_map=\"auto\" \n",
    ")\n",
    "\n",
    "# --- 3. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "qlora_base_model_lr2 = prepare_model_for_kbit_training(qlora_base_model_lr2)\n",
    "\n",
    "# --- 4. Ensure pre_classifier is float & correct shape ---\n",
    "hidden_size_lr2 = getattr(qlora_base_model_lr2.config, \"hidden_size\", 768)\n",
    "device_lr2 = next(qlora_base_model_lr2.parameters()).device\n",
    "qlora_base_model_lr2.pre_classifier = nn.Linear(hidden_size_lr2, hidden_size_lr2).to(device=device_lr2, dtype=torch.float32)\n",
    "print(f\"✅ pre_classifier fixed as nn.Linear({hidden_size_lr2}, {hidden_size_lr2})\")\n",
    "\n",
    "# --- 5. Define LoRA Configuration (Same as ExpID 05) ---\n",
    "qlora_lora_config_lr2 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"], # Attn + FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"classifier\", \"pre_classifier\"],\n",
    ")\n",
    "\n",
    "# --- 6. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters...\")\n",
    "qlora_model_lr2 = get_peft_model(qlora_base_model_lr2, qlora_lora_config_lr2)\n",
    "\n",
    "# --- 7. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice_lr2 = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice_lr2 = \"adamw_torch\"\n",
    "\n",
    "# --- 8. Define Training Arguments (ExpID 07, QLORA, Seed 42) ---\n",
    "qlora_training_args_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/qlora_r16_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/qlora_r16_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    \n",
    "    optim=optim_choice_lr2, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 9. Initialize Trainer ---\n",
    "qlora_trainer_lr2 = Trainer(\n",
    "    model=qlora_model_lr2,\n",
    "    args=qlora_training_args_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 10. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 11. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: QLORA r=16, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_qlora_lr2 = time.time()\n",
    "qlora_trainer_lr2.train()\n",
    "end_time_qlora_lr2 = time.time()\n",
    "training_time_qlora_lr2 = end_time_qlora_lr2 - start_time_qlora_lr2\n",
    "\n",
    "# --- 12. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_lr2 = peak_vram_bytes_qlora_lr2 / (1024**3)\n",
    "\n",
    "# --- 13. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_lr2 = qlora_trainer_lr2.evaluate()\n",
    "\n",
    "# --- 14. Report All Metrics for ExpID 07 (QLORA, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (QLORA, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_lr2:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_qlora_lr2 = sum(p.numel() for p in qlora_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96539faf-42be-4436-a3b1-714b89db541b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, QLORA, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a08a871-34a4-4d91-a358-2827ea4d30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\1844524865.py:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer_lr2_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "✅ pre_classifier fixed as nn.Linear(768, 768)\n",
      "🔹 Applying LoRA adapters...\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 07: QLORA r=16, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 16:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.292013</td>\n",
       "      <td>0.876003</td>\n",
       "      <td>0.875995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.275819</td>\n",
       "      <td>0.882649</td>\n",
       "      <td>0.882636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (QLORA, Seed 43) ---\n",
      "Accuracy: 0.8826\n",
      "F1-macro: 0.8826\n",
      "Training Time (s): 989.31\n",
      "Peak VRAM (GB): 3.5203\n",
      "Trainable Params (M): 1.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define Quantization Config (for QLORA) ---\n",
    "bnb_config_lr2_s43 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 2. Load the 4-bit Quantized Base Model ---\n",
    "print(\"🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 43)...\")\n",
    "qlora_base_model_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config_lr2_s43,\n",
    "    device_map=\"auto\" \n",
    ")\n",
    "\n",
    "# --- 3. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "qlora_base_model_lr2_s43 = prepare_model_for_kbit_training(qlora_base_model_lr2_s43)\n",
    "\n",
    "# --- 4. Ensure pre_classifier is float & correct shape ---\n",
    "hidden_size_lr2_s43 = getattr(qlora_base_model_lr2_s43.config, \"hidden_size\", 768)\n",
    "device_lr2_s43 = next(qlora_base_model_lr2_s43.parameters()).device\n",
    "qlora_base_model_lr2_s43.pre_classifier = nn.Linear(hidden_size_lr2_s43, hidden_size_lr2_s43).to(device=device_lr2_s43, dtype=torch.float32)\n",
    "print(f\"✅ pre_classifier fixed as nn.Linear({hidden_size_lr2_s43}, {hidden_size_lr2_s43})\")\n",
    "\n",
    "# --- 5. Define LoRA Configuration (Same as ExpID 05) ---\n",
    "qlora_lora_config_lr2_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"lin1\", \"lin2\"], # Attn + FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"classifier\", \"pre_classifier\"],\n",
    ")\n",
    "\n",
    "# --- 6. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters...\")\n",
    "qlora_model_lr2_s43 = get_peft_model(qlora_base_model_lr2_s43, qlora_lora_config_lr2_s43)\n",
    "\n",
    "# --- 7. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice_lr2_s43 = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice_lr2_s43 = \"adamw_torch\"\n",
    "\n",
    "# --- 8. Define Training Arguments (ExpID 07, QLORA, Seed 43) ---\n",
    "qlora_training_args_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/qlora_r16_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/qlora_r16_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    \n",
    "    optim=optim_choice_lr2_s43, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 9. Initialize Trainer ---\n",
    "qlora_trainer_lr2_s43 = Trainer(\n",
    "    model=qlora_model_lr2_s43,\n",
    "    args=qlora_training_args_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 10. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 11. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: QLORA r=16, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_qlora_lr2_s43 = time.time()\n",
    "qlora_trainer_lr2_s43.train()\n",
    "end_time_qlora_lr2_s43 = time.time()\n",
    "training_time_qlora_lr2_s43 = end_time_qlora_lr2_s43 - start_time_qlora_lr2_s43\n",
    "\n",
    "# --- 12. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_lr2_s43 = peak_vram_bytes_qlora_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 13. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_lr2_s43 = qlora_trainer_lr2_s43.evaluate()\n",
    "\n",
    "# --- 14. Report All Metrics for ExpID 07 (QLORA, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (QLORA, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_lr2_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_qlora_lr2_s43 = sum(p.numel() for p in qlora_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7163ad3a-c317-4964-a0c3-744216b34c75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, IA³, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b13662f-d6e9-4967-a17b-6a26421d0f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\3362923580.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer_lr2 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "--- Starting ExpID 07: IA³ Attn+FFN, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 09:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.403731</td>\n",
       "      <td>0.826445</td>\n",
       "      <td>0.826444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.379771</td>\n",
       "      <td>0.833293</td>\n",
       "      <td>0.833291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (IA³, Seed 42) ---\n",
      "Accuracy: 0.8333\n",
      "F1-macro: 0.8333\n",
      "Training Time (s): 597.94\n",
      "Peak VRAM (GB): 4.2074\n",
      "Trainable Params (M): 0.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 42)...\")\n",
    "base_model_ia3_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (Same as ExpID 06) ---\n",
    "ia3_config_lr2 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"v_lin\", \"lin2\"],  # Attn + FFN\n",
    "    feedforward_modules=[\"lin2\"],   # FFN layers\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_lr2 = get_peft_model(base_model_ia3_lr2, ia3_config_lr2)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 07, IA³, Seed 42) ---\n",
    "ia3_training_args_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/ia3_ffn_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/ia3_ffn_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "ia3_trainer_lr2 = Trainer(\n",
    "    model=ia3_model_lr2,\n",
    "    args=ia3_training_args_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: IA³ Attn+FFN, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_ia3_lr2 = time.time()\n",
    "ia3_trainer_lr2.train()\n",
    "end_time_ia3_lr2 = time.time()\n",
    "training_time_ia3_lr2 = end_time_ia3_lr2 - start_time_ia3_lr2\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_lr2 = peak_vram_bytes_ia3_lr2 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_lr2 = ia3_trainer_lr2.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 07 (IA³, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (IA³, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_lr2:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_lr2 = sum(p.numel() for p in ia3_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756b72a-0bfa-4afb-8434-ae17e9769fa5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, IA³, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbbe73d-f9d0-4efc-8963-ee982a34e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_8040\\635537131.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer_lr2_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "--- Starting ExpID 07: IA³ Attn+FFN, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 09:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.437800</td>\n",
       "      <td>0.405045</td>\n",
       "      <td>0.824662</td>\n",
       "      <td>0.824585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.396200</td>\n",
       "      <td>0.380174</td>\n",
       "      <td>0.831550</td>\n",
       "      <td>0.831550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (IA³, Seed 43) ---\n",
      "Accuracy: 0.8316\n",
      "F1-macro: 0.8315\n",
      "Training Time (s): 596.08\n",
      "Peak VRAM (GB): 4.4643\n",
      "Trainable Params (M): 0.62\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(\"Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 43)...\")\n",
    "base_model_ia3_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (Same as ExpID 06) ---\n",
    "ia3_config_lr2_s43 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"v_lin\", \"lin2\"],  # Attn + FFN\n",
    "    feedforward_modules=[\"lin2\"],   # FFN layers\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_lr2_s43 = get_peft_model(base_model_ia3_lr2_s43, ia3_config_lr2_s43)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 07, IA³, Seed 43) ---\n",
    "ia3_training_args_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/ia3_ffn_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/ia3_ffn_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "ia3_trainer_lr2_s43 = Trainer(\n",
    "    model=ia3_model_lr2_s43,\n",
    "    args=ia3_training_args_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: IA³ Attn+FFN, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_ia3_lr2_s43 = time.time()\n",
    "ia3_trainer_lr2_s43.train()\n",
    "end_time_ia3_lr2_s43 = time.time()\n",
    "training_time_ia3_lr2_s43 = end_time_ia3_lr2_s43 - start_time_ia3_lr2_s43\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_lr2_s43 = peak_vram_bytes_ia3_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_lr2_s43 = ia3_trainer_lr2_s43.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 07 (IA³, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (IA³, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_lr2_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_lr2_s43 = sum(p.numel() for p in ia3_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175657b-b433-4bf4-b82e-41dad24913cf",
   "metadata": {},
   "source": [
    "# RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea7035-27be-4918-acbd-a1d703d0c9ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "429dfe08-6c8a-4bb3-8f6b-bddde093ac99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for: roberta-base\n",
      "Reloading original IMDb dataset...\n",
      "Tokenizing dataset with RoBERTa tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1f582d48b04573aec78d90876c9e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ab5a3982ed4d5cb534c41288a5e929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessing Complete for RoBERTa ---\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'label_text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 24904\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'label_text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 24678\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset  # <--- Changed this line\n",
    "import evaluate                      # <--- Added this line\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Define NEW Globals ---\n",
    "model_checkpoint = \"roberta-base\"\n",
    "MAX_LENGTH = 256 # From \"Design Matrix\" defaults\n",
    "\n",
    "# --- 2. Load RoBERTa Tokenizer ---\n",
    "print(f\"Loading tokenizer for: {model_checkpoint}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# --- 3. Load Dataset (already in memory, but for clarity) ---\n",
    "# We are re-using the 'dataset' variable we loaded in the very first step\n",
    "print(\"Reloading original IMDb dataset...\")\n",
    "dataset = load_dataset(\"mteb/imdb\")\n",
    "\n",
    "# --- 4. Define Preprocessing Function (same as before) ---\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize text, truncate to max_length, and apply padding\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing dataset with RoBERTa tokenizer...\")\n",
    "# Re-map the *original* dataset with the *new* tokenizer\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# --- 5. Format Dataset for Training ---\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "print(\"--- Preprocessing Complete for RoBERTa ---\")\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b46359-5585-4a79-8e4a-cd17b8c76df7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 1 - Full Fine-Tuning (ExpID 01, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0da95456-8008-4cbd-b401-e5d37d83802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for Full Fine-Tuning (roberta-base)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\456114652.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using GPU: NVIDIA RTX A4000\n",
      "--- Starting ExpID 01: roberta-base Full FT (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 24:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.275798</td>\n",
       "      <td>0.919523</td>\n",
       "      <td>0.919224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.219963</td>\n",
       "      <td>0.938852</td>\n",
       "      <td>0.938848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 01 (roberta-base, Seed 42) ---\n",
      "Accuracy: 0.9389\n",
      "F1-macro: 0.9388\n",
      "Training Time (s): 1461.66\n",
      "Peak VRAM (GB): 3.1157\n",
      "Trainable Params (M): 124.65\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "# These must be in memory from your previous \"reset\" cell\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "\n",
    "# --- 1. Load Model (Method 1: Full Fine-Tuning, roberta-base) ---\n",
    "print(f\"Loading model for Full Fine-Tuning ({model_checkpoint})...\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 01, roberta-base) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_full_ft_seed_42\",\n",
    "    logging_dir=\"./logs/roberta_full_ft_seed_42\",\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,   # Effective batch size = 16\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    # Other standard settings\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"], \n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "# a) Count Trainable Parameters\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "# b) Reset CUDA memory stats\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    print(f\"\\nUsing GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\\nUsing CPU\")\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 01: roberta-base Full FT (Seed 42) ---\")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb = peak_vram_bytes / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 01 (roberta-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 01 (roberta-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb:.4f}\")\n",
    "print(f\"Trainable Params (M): {trainable_params / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d4faf6-629e-4f94-9121-5e43e0c47474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 1 - Full Fine-Tuning (ExpID 01, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c939d15e-e0ab-498c-b147-25352512aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for Full Fine-Tuning (roberta-base, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\1654026637.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 01: roberta-base Full FT (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 24:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.205279</td>\n",
       "      <td>0.934395</td>\n",
       "      <td>0.934395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.207166</td>\n",
       "      <td>0.939055</td>\n",
       "      <td>0.939044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 01 (roberta-base, Seed 43) ---\n",
      "Accuracy: 0.9391\n",
      "F1-macro: 0.9390\n",
      "Training Time (s): 1462.09\n",
      "Peak VRAM (GB): 4.5080\n",
      "Trainable Params (M): 124.65\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Model (Method 1: Full Fine-Tuning, roberta-base) ---\n",
    "print(f\"Loading model for Full Fine-Tuning ({model_checkpoint}, Seed 43)...\")\n",
    "\n",
    "model_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 01, roberta-base, Seed 43) ---\n",
    "training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_full_ft_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_full_ft_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                         # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_s43 = Trainer(\n",
    "    model=model_s43,\n",
    "    args=training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"], \n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "trainable_params_s43 = sum(\n",
    "    p.numel() for p in model_s43.parameters() if p.requires_grad\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 01: roberta-base Full FT (Seed 43) ---\")\n",
    "\n",
    "start_time_s43 = time.time()\n",
    "trainer_s43.train()\n",
    "end_time_s43 = time.time()\n",
    "training_time_s43 = end_time_s43 - start_time_s43\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_s43 = peak_vram_bytes_s43 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_s43 = trainer_s43.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 01 (roberta-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 01 (roberta-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_s43:.4f}\")\n",
    "print(f\"Trainable Params (M): {trainable_params_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a8086-28ba-4719-9ba7-cc61f8dcd94f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Fine-Tuning (ExpID 02, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddd9f3d-7c06-44c0-8766-c385bc2e507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (roberta-base, r=8, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\1550070431.py:94: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model Parameter Count:\n",
      "Trainable Params: 887,042 | All Params: 125,534,212 | Trainable %: 0.71\n",
      "--- Starting ExpID 02: roberta-base LoRA r=8 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.240053</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>0.908910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.235900</td>\n",
       "      <td>0.227713</td>\n",
       "      <td>0.913567</td>\n",
       "      <td>0.913554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 02 (roberta-base, Seed 42) ---\n",
      "Accuracy: 0.9136\n",
      "F1-macro: 0.9136\n",
      "Training Time (s): 1154.42\n",
      "Peak VRAM (GB): 4.2753\n",
      "Trainable Params (M): 0.89\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "# These must be in memory from your previous \"reset\" cell\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION (This was the missing part) ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=8, Seed 42)...\")\n",
    "base_model_lora = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 02 for RoBERTa) ---\n",
    "# From PDF: r=8, targets=[q,v], placement=Attn, alpha=16\n",
    "# RoBERTa's attention layers are 'query' and 'value'\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"], # <-- RoBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", # Sequence Classification\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters to the base model ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model = get_peft_model(base_model_lora, lora_config)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"LoRA Model Parameter Count:\")\n",
    "print_trainable_parameters(lora_model) # <-- This will now work\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 02, Seed 42) ---\n",
    "lora_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r8_seed_42\",\n",
    "    logging_dir=\"./logs/roberta_lora_r8_seed_42\",\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model, # <-- Use the lora_model\n",
    "    args=lora_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 02: roberta-base LoRA r=8 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora = time.time()\n",
    "lora_trainer.train()\n",
    "end_time_lora = time.time()\n",
    "training_time_lora = end_time_lora - start_time_lora\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora = peak_vram_bytes_lora / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora = lora_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 02 (roberta-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 02 (roberta-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora:.4f}\")\n",
    "\n",
    "# Get the trainable param count again to be precise\n",
    "trainable_params_lora = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8881ab5-55c3-403a-9e58-a78f8debefea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Fine-Tuning (ExpID 02, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c894b6be-6329-440a-b0b8-1a507bc2dfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (roberta-base, r=8, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\1454071876.py:91: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model Parameter Count:\n",
      "Trainable Params: 887,042 | All Params: 125,534,212 | Trainable %: 0.71\n",
      "--- Starting ExpID 02: roberta-base LoRA r=8 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>0.249662</td>\n",
       "      <td>0.908623</td>\n",
       "      <td>0.908594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.228024</td>\n",
       "      <td>0.912959</td>\n",
       "      <td>0.912948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 02 (roberta-base, Seed 43) ---\n",
      "Accuracy: 0.9130\n",
      "F1-macro: 0.9129\n",
      "Training Time (s): 1160.46\n",
      "Peak VRAM (GB): 4.7503\n",
      "Trainable Params (M): 0.89\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=8, Seed 43)...\")\n",
    "base_model_lora_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 02 for RoBERTa) ---\n",
    "lora_config_s43 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"], # RoBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters to the base model ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model_s43 = get_peft_model(base_model_lora_s43, lora_config_s43)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"LoRA Model Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 02, Seed 43) ---\n",
    "lora_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r8_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_lora_r8_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_trainer_s43 = Trainer(\n",
    "    model=lora_model_s43, \n",
    "    args=lora_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 02: roberta-base LoRA r=8 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_s43 = time.time()\n",
    "lora_trainer_s43.train()\n",
    "end_time_lora_s43 = time.time()\n",
    "training_time_lora_s43 = end_time_lora_s43 - start_time_lora_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_s43 = peak_vram_bytes_lora_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_s43 = lora_trainer_s43.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 02 (roberta-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 02 (roberta-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again to be precise\n",
    "trainable_params_lora_s43 = sum(p.numel() for p in lora_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca13c2-52c4-4fb9-9e8f-9824da80ec20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Rank Sensitivity (ExpID 03, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0ae3c5-9d01-427f-b372-a015c113b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (roberta-base, r=16, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\331957043.py:87: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_r16_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model (r=16) Parameter Count:\n",
      "Trainable Params: 1,181,954 | All Params: 125,829,124 | Trainable %: 0.94\n",
      "--- Starting ExpID 03: roberta-base LoRA r=16 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.232573</td>\n",
       "      <td>0.910933</td>\n",
       "      <td>0.910911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.222584</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.915048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 03 (roberta-base, Seed 42) ---\n",
      "Accuracy: 0.9151\n",
      "F1-macro: 0.9150\n",
      "Training Time (s): 1156.19\n",
      "Peak VRAM (GB): 5.2322\n",
      "Trainable Params (M): 1.18\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=16, Seed 42)...\")\n",
    "base_model_lora_r16 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 03 for RoBERTa) ---\n",
    "lora_config_r16 = LoraConfig(\n",
    "    r=16, # <-- CHANGED\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"], # RoBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model_r16 = get_peft_model(base_model_lora_r16, lora_config_r16)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (r=16) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_r16)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_r16_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r16_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_lora_r16_seed_42\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_r16_trainer = Trainer(\n",
    "    model=lora_model_r16,\n",
    "    args=lora_r16_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 03: roberta-base LoRA r=16 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_r16 = time.time()\n",
    "lora_r16_trainer.train()\n",
    "end_time_lora_r16 = time.time()\n",
    "training_time_lora_r16 = end_time_lora_r16 - start_time_lora_r16\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_r16 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_r16 = peak_vram_bytes_lora_r16 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_r16 = lora_r16_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 03 (roberta-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 03 (roberta-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_r16['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_r16['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_r16:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_r16:.4f}\")\n",
    "\n",
    "trainable_params_lora_r16 = sum(p.numel() for p in lora_model_r16.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_r16 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1831e9-74f0-4ad9-ac2f-af5a5d023fc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Rank Sensitivity (ExpID 03, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe7b373-637a-4537-9873-2d7eab4794fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (roberta-base, r=16, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\732307474.py:87: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_r16_s43_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model (r=16) Parameter Count:\n",
      "Trainable Params: 1,181,954 | All Params: 125,829,124 | Trainable %: 0.94\n",
      "--- Starting ExpID 03: roberta-base LoRA r=16 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.245799</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>0.909653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.225742</td>\n",
       "      <td>0.913486</td>\n",
       "      <td>0.913475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 03 (roberta-base, Seed 43) ---\n",
      "Accuracy: 0.9135\n",
      "F1-macro: 0.9135\n",
      "Training Time (s): 1157.97\n",
      "Peak VRAM (GB): 5.7104\n",
      "Trainable Params (M): 1.18\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=16, Seed 43)...\")\n",
    "base_model_lora_r16_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 03 for RoBERTa) ---\n",
    "lora_config_r16_s43 = LoraConfig(\n",
    "    r=16, # <-- Rank 16\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"], # RoBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model_r16_s43 = get_peft_model(base_model_lora_r16_s43, lora_config_r16_s43)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (r=16) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_r16_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_r16_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r16_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_lora_r16_seed_43\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_r16_s43_trainer = Trainer(\n",
    "    model=lora_model_r16_s43,\n",
    "    args=lora_r16_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 03: roberta-base LoRA r=16 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_r16_s43 = time.time()\n",
    "lora_r16_s43_trainer.train()\n",
    "end_time_lora_r16_s43 = time.time()\n",
    "training_time_lora_r16_s43 = end_time_lora_r16_s43 - start_time_lora_r16_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_r16_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_r16_s43 = peak_vram_bytes_lora_r16_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_r16_s43 = lora_r16_s43_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 03 (roberta-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 03 (roberta-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_r16_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_r16_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_r16_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_r16_s43:.4f}\")\n",
    "\n",
    "trainable_params_lora_r16_s43 = sum(p.numel() for p in lora_model_r16_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_r16_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2c604-9743-428d-93a2-dc9b9a7e3209",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Placement (ExpID 04, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6154690-803e-4899-a416-4af9b2a9b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (roberta-base, Attn+FFN, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\2793887053.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_ffn_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA Model (Attn+FFN) Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 127,598,596 | Trainable %: 2.31\n",
      "--- Starting ExpID 04: roberta-base LoRA r=16 Attn+FFN (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 22:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.216023</td>\n",
       "      <td>0.918632</td>\n",
       "      <td>0.918576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.202689</td>\n",
       "      <td>0.923738</td>\n",
       "      <td>0.923705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 04 (roberta-base, Seed 42) ---\n",
      "Accuracy: 0.9237\n",
      "F1-macro: 0.9237\n",
      "Training Time (s): 1374.43\n",
      "Peak VRAM (GB): 6.7595\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, Attn+FFN, Seed 42)...\")\n",
    "base_model_lora_ffn = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 04 for RoBERTa) ---\n",
    "# We add the FFN layers 'intermediate.dense' and 'output.dense'\n",
    "lora_config_ffn = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # <-- CHANGED\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_ffn = get_peft_model(base_model_lora_ffn, lora_config_ffn)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (Attn+FFN) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_ffn)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_ffn_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r16_ffn_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_lora_r16_ffn_seed_42\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_ffn_trainer = Trainer(\n",
    "    model=lora_model_ffn,\n",
    "    args=lora_ffn_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 04: roberta-base LoRA r=16 Attn+FFN (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_ffn = time.time()\n",
    "lora_ffn_trainer.train()\n",
    "end_time_lora_ffn = time.time()\n",
    "training_time_lora_ffn = end_time_lora_ffn - start_time_lora_ffn\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_ffn = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_ffn = peak_vram_bytes_lora_ffn / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_ffn = lora_ffn_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 04 (roberta-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 04 (roberta-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_ffn['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_ffn['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_ffn:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_ffn:.4f}\")\n",
    "\n",
    "trainable_params_lora_ffn = sum(p.numel() for p in lora_model_ffn.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_ffn / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a41c29-cf43-4bc9-b709-8e5f04b503ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Placement (ExpID 04, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f61fd13-ffd3-4fdf-99bb-3255254efdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (roberta-base, Attn+FFN, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_12144\\3322183969.py:87: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_ffn_s43_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA Model (Attn+FFN) Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 127,598,596 | Trainable %: 2.31\n",
      "--- Starting ExpID 04: roberta-base LoRA r=16 Attn+FFN (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 22:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.242600</td>\n",
       "      <td>0.223088</td>\n",
       "      <td>0.918429</td>\n",
       "      <td>0.918403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.223800</td>\n",
       "      <td>0.202357</td>\n",
       "      <td>0.923535</td>\n",
       "      <td>0.923524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 04 (roberta-base, Seed 43) ---\n",
      "Accuracy: 0.9235\n",
      "F1-macro: 0.9235\n",
      "Training Time (s): 1374.89\n",
      "Peak VRAM (GB): 7.2576\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, Attn+FFN, Seed 43)...\")\n",
    "base_model_lora_ffn_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 04 for RoBERTa) ---\n",
    "lora_config_ffn_s43 = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # Attn + FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_ffn_s43 = get_peft_model(base_model_lora_ffn_s43, lora_config_ffn_s43)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (Attn+FFN) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_ffn_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_ffn_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r16_ffn_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_lora_r16_ffn_seed_43\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                         # <-- CHANGED\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_ffn_s43_trainer = Trainer(\n",
    "    model=lora_model_ffn_s43,\n",
    "    args=lora_ffn_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 04: roberta-base LoRA r=16 Attn+FFN (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_ffn_s43 = time.time()\n",
    "lora_ffn_s43_trainer.train()\n",
    "end_time_lora_ffn_s43 = time.time()\n",
    "training_time_lora_ffn_s43 = end_time_lora_ffn_s43 - start_time_lora_ffn_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_ffn_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_ffn_s43 = peak_vram_bytes_lora_ffn_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_ffn_s43 = lora_ffn_s43_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 04 (roberta-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 04 (roberta-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_ffn_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_ffn_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_ffn_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_ffn_s43:.4f}\")\n",
    "\n",
    "trainable_params_lora_ffn_s43 = sum(p.numel() for p in lora_model_ffn_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_ffn_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c63bc-3245-4ba8-8267-e27f30429680",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 3 - QLORA (ExpID 05, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda394c0-2d98-4f0f-b1c9-0f60b591ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model for QLORA (roberta-base)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "Detected hidden size: 768, num_labels: 2\n",
      "✅ roberta-base classifier head fixed with float nn.Linear layers.\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 85,723,398 | Trainable %: 3.44\n",
      "✅ Using paged_adamw_8bit optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_17200\\1587739038.py:120: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 05: roberta-base QLORA r=16 (Seed 42) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 32:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.259340</td>\n",
       "      <td>0.902545</td>\n",
       "      <td>0.902387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.234202</td>\n",
       "      <td>0.911865</td>\n",
       "      <td>0.911831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 05 (roberta-base, Seed 42) ---\n",
      "Accuracy: 0.9119\n",
      "F1-macro: 0.9118\n",
      "Training Time (s): 1948.28\n",
      "Peak VRAM (GB): 0.4878\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Define Quantization Config (for QLORA) ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 2. Load the 4-bit Quantized Base Model ---\n",
    "print(\"🔹 Loading 4-bit quantized model for QLORA (roberta-base)...\")\n",
    "qlora_base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\" \n",
    ")\n",
    "\n",
    "# --- 3. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "qlora_base_model = prepare_model_for_kbit_training(qlora_base_model)\n",
    "\n",
    "# --- 4. FIX: Ensure RoBERTa classification head is float ---\n",
    "hidden_size = getattr(qlora_base_model.config, \"hidden_size\", 768)\n",
    "num_labels = getattr(qlora_base_model.config, \"num_labels\", 2)\n",
    "device = next(qlora_base_model.parameters()).device\n",
    "print(f\"Detected hidden size: {hidden_size}, num_labels: {num_labels}\")\n",
    "qlora_base_model.classifier.dense = nn.Linear(hidden_size, hidden_size).to(device=device, dtype=torch.float32)\n",
    "qlora_base_model.classifier.out_proj = nn.Linear(hidden_size, num_labels).to(device=device, dtype=torch.float32)\n",
    "print(f\"✅ roberta-base classifier head fixed with float nn.Linear layers.\")\n",
    "\n",
    "# --- 5. Define LoRA Configuration (ExpID 05 for RoBERTa) ---\n",
    "qlora_lora_config = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # RoBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"classifier.dense\", \"classifier.out_proj\"], # RoBERTa head names\n",
    ")\n",
    "\n",
    "# --- 6. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model = get_peft_model(qlora_base_model, qlora_lora_config)\n",
    "\n",
    "# --- 7. Calculate and Print Trainable Parameters ---\n",
    "print(\"QLORA Model Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model)\n",
    "\n",
    "# --- 8. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice = \"adamw_torch\"\n",
    "\n",
    "# --- 9. Define Training Arguments (ExpID 05, Seed 42) ---\n",
    "qlora_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_qlora_r16_seed_42\", \n",
    "    logging_dir=\"./logs/roberta_qlora_r16_seed_42\",   \n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    optim=optim_choice, \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, # <-- THIS IS THE FIX\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 10. Initialize Trainer ---\n",
    "qlora_trainer = Trainer(\n",
    "    model=qlora_model,\n",
    "    args=qlora_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 11. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 12. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 05: roberta-base QLORA r=16 (Seed 42) ---\")\n",
    "\n",
    "start_time_qlora = time.time()\n",
    "qlora_trainer.train() # <-- This will no longer crash\n",
    "end_time_qlora = time.time()\n",
    "training_time_qlora = end_time_qlora - start_time_qlora\n",
    "\n",
    "# --- 13. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora = peak_vram_bytes_qlora / (1024**3)\n",
    "\n",
    "# --- 14. Evaluate Model ---\n",
    "# Since load_best_model_at_end=False, this evaluates the model at the FINAL step\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora = qlora_trainer.evaluate()\n",
    "\n",
    "# --- 15. Report All Metrics for ExpID 05 (roberta-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 05 (roberta-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora:.4f}\")\n",
    "\n",
    "trainable_params_qlora = sum(p.numel() for p in qlora_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2878a-6969-4503-8188-e3ad258ddf0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 3 - QLORA (ExpID 05, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6af833-bbcd-43fe-ad93-bfce30d2d5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model for QLORA (roberta-base, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "Detected hidden size: 768, num_labels: 2\n",
      "✅ roberta-base classifier head fixed with float nn.Linear layers.\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 85,723,398 | Trainable %: 3.44\n",
      "✅ Using paged_adamw_8bit optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_17200\\2057650352.py:121: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 05: roberta-base QLORA r=16 (Seed 43) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 32:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.286976</td>\n",
       "      <td>0.895453</td>\n",
       "      <td>0.895450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.244295</td>\n",
       "      <td>0.908461</td>\n",
       "      <td>0.908433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 05 (roberta-base, Seed 43) ---\n",
      "Accuracy: 0.9085\n",
      "F1-macro: 0.9084\n",
      "Training Time (s): 1950.87\n",
      "Peak VRAM (GB): 0.6962\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Define Quantization Config (for QLORA) ---\n",
    "bnb_config_s43 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 2. Load the 4-bit Quantized Base Model ---\n",
    "print(\"🔹 Loading 4-bit quantized model for QLORA (roberta-base, Seed 43)...\")\n",
    "qlora_base_model_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config_s43,\n",
    "    device_map=\"auto\" \n",
    ")\n",
    "\n",
    "# --- 3. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "qlora_base_model_s43 = prepare_model_for_kbit_training(qlora_base_model_s43)\n",
    "\n",
    "# --- 4. FIX: Ensure RoBERTa classification head is float ---\n",
    "hidden_size_s43 = getattr(qlora_base_model_s43.config, \"hidden_size\", 768)\n",
    "num_labels_s43 = getattr(qlora_base_model_s43.config, \"num_labels\", 2)\n",
    "device_s43 = next(qlora_base_model_s43.parameters()).device\n",
    "print(f\"Detected hidden size: {hidden_size_s43}, num_labels: {num_labels_s43}\")\n",
    "qlora_base_model_s43.classifier.dense = nn.Linear(hidden_size_s43, hidden_size_s43).to(device=device_s43, dtype=torch.float32)\n",
    "qlora_base_model_s43.classifier.out_proj = nn.Linear(hidden_size_s43, num_labels_s43).to(device=device_s43, dtype=torch.float32)\n",
    "print(f\"✅ roberta-base classifier head fixed with float nn.Linear layers.\")\n",
    "\n",
    "# --- 5. Define LoRA Configuration (ExpID 05 for RoBERTa) ---\n",
    "qlora_lora_config_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # RoBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"classifier.dense\", \"classifier.out_proj\"], # RoBERTa head names\n",
    ")\n",
    "\n",
    "# --- 6. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model_s43 = get_peft_model(qlora_base_model_s43, qlora_lora_config_s43)\n",
    "\n",
    "# --- 7. Calculate and Print Trainable Parameters ---\n",
    "print(\"QLORA Model Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model_s43)\n",
    "\n",
    "# --- 8. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice_s43 = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice_s43 = \"adamw_torch\"\n",
    "\n",
    "# --- 9. Define Training Arguments (ExpID 05, Seed 43) ---\n",
    "qlora_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_qlora_r16_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_qlora_r16_seed_43\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    optim=optim_choice_s43, \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, # <-- Fix from last run\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 10. Initialize Trainer ---\n",
    "qlora_trainer_s43 = Trainer(\n",
    "    model=qlora_model_s43,\n",
    "    args=qlora_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 11. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 12. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 05: roberta-base QLORA r=16 (Seed 43) ---\")\n",
    "\n",
    "start_time_qlora_s43 = time.time()\n",
    "qlora_trainer_s43.train()\n",
    "end_time_qlora_s43 = time.time()\n",
    "training_time_qlora_s43 = end_time_qlora_s43 - start_time_qlora_s43\n",
    "\n",
    "# --- 13. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_s43 = peak_vram_bytes_qlora_s43 / (1024**3)\n",
    "\n",
    "# --- 14. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_s43 = qlora_trainer_s43.evaluate()\n",
    "\n",
    "# --- 15. Report All Metrics for ExpID 05 (roberta-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 05 (roberta-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_s43:.4f}\")\n",
    "\n",
    "trainable_params_qlora_s43 = sum(p.numel() for p in qlora_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113db83-4b13-4af6-a000-aa95ae936fd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 4 - Adapter Tuning (IA³) (ExpID 06, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014f2780-2b2c-43a6-bbc1-49af1f4f9891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for IA³ (roberta-base, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_17200\\1420702825.py:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable Params: 647,426 | All Params: 125,294,596 | Trainable %: 0.52\n",
      "--- Starting ExpID 06: roberta-base IA³ Attn+FFN (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.673700</td>\n",
       "      <td>0.669044</td>\n",
       "      <td>0.810884</td>\n",
       "      <td>0.810217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.828187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 06 (roberta-base, Seed 42) ---\n",
      "Accuracy: 0.8282\n",
      "F1-macro: 0.8282\n",
      "Training Time (s): 1152.95\n",
      "Peak VRAM (GB): 2.1118\n",
      "Trainable Params (M): 0.65\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for IA³ ({model_checkpoint}, Seed 42)...\")\n",
    "base_model_ia3 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (ExpID 06 for RoBERTa) ---\n",
    "# PDF: Location=Attn+FFN, targets=v-only\n",
    "# RoBERTa: 'value' (Attn), 'output.dense' (FFN)\n",
    "ia3_config = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"value\", \"output.dense\"],  # <-- RoBERTa layer names\n",
    "    feedforward_modules=[\"output.dense\"],   # <-- RoBERTa FFN layer\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model = get_peft_model(base_model_ia3, ia3_config)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model) # Expect this to be very small\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 06, Seed 42) ---\n",
    "ia3_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_ia3_ffn_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_ia3_ffn_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, # This should be fine for IA3\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer = Trainer(\n",
    "    model=ia3_model,\n",
    "    args=ia3_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 06: roberta-base IA³ Attn+FFN (Seed 42) ---\")\n",
    "\n",
    "start_time_ia3 = time.time()\n",
    "ia3_trainer.train()\n",
    "end_time_ia3 = time.time()\n",
    "training_time_ia3 = end_time_ia3 - start_time_ia3\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3 = peak_vram_bytes_ia3 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3 = ia3_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 06 (roberta-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 06 (roberta-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3 = sum(p.numel() for p in ia3_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53475898-928b-4ad1-8998-8ebc7f45cd44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 4 - Adapter Tuning (IA³) (ExpID 06, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad721275-eeea-4e02-bc48-7461eeecfd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for IA³ (roberta-base, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_17200\\3245670029.py:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable Params: 647,426 | All Params: 125,294,596 | Trainable %: 0.52\n",
      "--- Starting ExpID 06: roberta-base IA³ Attn+FFN (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.671500</td>\n",
       "      <td>0.667935</td>\n",
       "      <td>0.810601</td>\n",
       "      <td>0.810234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.655737</td>\n",
       "      <td>0.815868</td>\n",
       "      <td>0.815222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 06 (roberta-base, Seed 43) ---\n",
      "Accuracy: 0.8159\n",
      "F1-macro: 0.8152\n",
      "Training Time (s): 1150.16\n",
      "Peak VRAM (GB): 2.5831\n",
      "Trainable Params (M): 0.65\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for IA³ ({model_checkpoint}, Seed 43)...\")\n",
    "base_model_ia3_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (ExpID 06 for RoBERTa) ---\n",
    "ia3_config_s43 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"value\", \"output.dense\"],  # RoBERTa layer names\n",
    "    feedforward_modules=[\"output.dense\"],   # RoBERTa FFN layer\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_s43 = get_peft_model(base_model_ia3_s43, ia3_config_s43)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 06, Seed 43) ---\n",
    "ia3_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_ia3_ffn_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_ia3_ffn_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer_s43 = Trainer(\n",
    "    model=ia3_model_s43,\n",
    "    args=ia3_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 06: roberta-base IA³ Attn+FFN (Seed 43) ---\")\n",
    "\n",
    "start_time_ia3_s43 = time.time()\n",
    "ia3_trainer_s43.train()\n",
    "end_time_ia3_s43 = time.time()\n",
    "training_time_ia3_s43 = end_time_ia3_s43 - start_time_ia3_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_s43 = peak_vram_bytes_ia3_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_s43 = ia3_trainer_s43.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 06 (roberta-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 06 (roberta-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_s43 = sum(p.numel() for p in ia3_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ae357-b9db-4703-a572-28fa42907568",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, Full FT, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b2b106-cda4-4a60-bd4c-07c8317aa333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_17200\\3671014904.py:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_ft_lr2 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 07: roberta-base Full FT, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 24:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.240747</td>\n",
       "      <td>0.933260</td>\n",
       "      <td>0.933210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.940879</td>\n",
       "      <td>0.940871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, Full FT, Seed 42) ---\n",
      "Accuracy: 0.9409\n",
      "F1-macro: 0.9409\n",
      "Training Time (s): 1442.87\n",
      "Peak VRAM (GB): 4.4691\n",
      "Trainable Params (M): 124.65\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load Model (Full Fine-Tuning) ---\n",
    "print(f\"Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 42)...\")\n",
    "model_ft_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 07, Full FT) ---\n",
    "training_args_ft_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_full_ft_lr2_seed_42\",  # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_full_ft_lr2_seed_42\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_ft_lr2 = Trainer(\n",
    "    model=model_ft_lr2,\n",
    "    args=training_args_ft_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base Full FT, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_ft_lr2 = time.time()\n",
    "trainer_ft_lr2.train()\n",
    "end_time_ft_lr2 = time.time()\n",
    "training_time_ft_lr2 = end_time_ft_lr2 - start_time_ft_lr2\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_ft_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ft_lr2 = peak_vram_bytes_ft_lr2 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ft_lr2 = trainer_ft_lr2.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 07 (roberta-base, Full FT, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, Full FT, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ft_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ft_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ft_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ft_lr2:.4f}\")\n",
    "\n",
    "trainable_params_ft_lr2 = sum(p.numel() for p in model_ft_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ft_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0ab6d-9802-4dfb-8316-26c941b0f07e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, Full FT, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446b406e-a33b-42d9-9858-a91bd1caa386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_11744\\3316947935.py:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_ft_lr2_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 07: roberta-base Full FT, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 23:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.251506</td>\n",
       "      <td>0.932896</td>\n",
       "      <td>0.932866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.218916</td>\n",
       "      <td>0.940230</td>\n",
       "      <td>0.940222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, Full FT, Seed 43) ---\n",
      "Accuracy: 0.9402\n",
      "F1-macro: 0.9402\n",
      "Training Time (s): 1435.65\n",
      "Peak VRAM (GB): 3.1157\n",
      "Trainable Params (M): 124.65\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load Model (Full Fine-Tuning) ---\n",
    "print(f\"Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 43)...\")\n",
    "model_ft_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 07, Full FT, Seed 43) ---\n",
    "training_args_ft_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_full_ft_lr2_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_full_ft_lr2_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_ft_lr2_s43 = Trainer(\n",
    "    model=model_ft_lr2_s43,\n",
    "    args=training_args_ft_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base Full FT, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_ft_lr2_s43 = time.time()\n",
    "trainer_ft_lr2_s43.train()\n",
    "end_time_ft_lr2_s43 = time.time()\n",
    "training_time_ft_lr2_s43 = end_time_ft_lr2_s43 - start_time_ft_lr2_s43\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_ft_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ft_lr2_s43 = peak_vram_bytes_ft_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ft_lr2_s43 = trainer_ft_lr2_s43.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 07 (roberta-base, Full FT, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, Full FT, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ft_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ft_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ft_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ft_lr2_s43:.4f}\")\n",
    "\n",
    "trainable_params_ft_lr2_s43 = sum(p.numel() for p in model_ft_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ft_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6bee3-a0ed-4b9e-b8e3-bca9a7e4715d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, LoRA, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186b58fa-06d2-4204-9984-a078a197bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_11744\\1953662284.py:91: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_lr2_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA Model (Attn+FFN, LR=2e-5) Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 127,598,596 | Trainable %: 2.31\n",
      "--- Starting ExpID 07: roberta-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 22:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.200642</td>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.927133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.185286</td>\n",
       "      <td>0.931396</td>\n",
       "      <td>0.931378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, LoRA, Seed 42) ---\n",
      "Accuracy: 0.9314\n",
      "F1-macro: 0.9314\n",
      "Training Time (s): 1367.07\n",
      "Peak VRAM (GB): 3.4568\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 42)...\")\n",
    "base_model_lora_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (Same as ExpID 04) ---\n",
    "lora_config_lr2 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # RoBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_lr2 = get_peft_model(base_model_lora_lr2, lora_config_lr2)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (Attn+FFN, LR=2e-5) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_lr2)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 07, LoRA, Seed 42) ---\n",
    "lora_lr2_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r16_ffn_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_lora_r16_ffn_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_lr2_trainer = Trainer(\n",
    "    model=lora_model_lr2,\n",
    "    args=lora_lr2_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_lr2 = time.time()\n",
    "lora_lr2_trainer.train()\n",
    "end_time_lora_lr2 = time.time()\n",
    "training_time_lora_lr2 = end_time_lora_lr2 - start_time_lora_lr2\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_lr2 = peak_vram_bytes_lora_lr2 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_lr2 = lora_lr2_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 07 (roberta-base, LoRA, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, LoRA, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_lr2:.4f}\")\n",
    "\n",
    "trainable_params_lora_lr2 = sum(p.numel() for p in lora_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19ab07-27dc-450e-a996-d69262e87b6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, LoRA, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e329761d-819f-4193-8f4e-52dc2104e2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19436\\1978894392.py:91: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_lr2_s43_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA Model (Attn+FFN, LR=2e-5) Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 127,598,596 | Trainable %: 2.31\n",
      "--- Starting ExpID 07: roberta-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 23:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.196549</td>\n",
       "      <td>0.927304</td>\n",
       "      <td>0.927276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.184666</td>\n",
       "      <td>0.932166</td>\n",
       "      <td>0.932155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, LoRA, Seed 43) ---\n",
      "Accuracy: 0.9322\n",
      "F1-macro: 0.9322\n",
      "Training Time (s): 1398.40\n",
      "Peak VRAM (GB): 2.0485\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 43)...\")\n",
    "base_model_lora_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (Same as ExpID 04) ---\n",
    "lora_config_lr2_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # RoBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_lr2_s43 = get_peft_model(base_model_lora_lr2_s43, lora_config_lr2_s43)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (Attn+FFN, LR=2e-5) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_lr2_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 07, LoRA, Seed 43) ---\n",
    "lora_lr2_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_lora_r16_ffn_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_lora_r16_ffn_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_lr2_s43_trainer = Trainer(\n",
    "    model=lora_model_lr2_s43,\n",
    "    args=lora_lr2_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_lr2_s43 = time.time()\n",
    "lora_lr2_s43_trainer.train()\n",
    "end_time_lora_lr2_s43 = time.time()\n",
    "training_time_lora_lr2_s43 = end_time_lora_lr2_s43 - start_time_lora_lr2_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_lr2_s43 = peak_vram_bytes_lora_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_lr2_s43 = lora_lr2_s43_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 07 (roberta-base, LoRA, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, LoRA, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_lr2_s43:.4f}\")\n",
    "\n",
    "trainable_params_lora_lr2_s43 = sum(p.numel() for p in lora_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34947c6-ecd7-4014-ad42-dbeac399d863",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, QLORA, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d157a089-45db-4bbe-a5ea-cb40690a57e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19436\\3355012053.py:124: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer_lr2 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "Detected hidden size: 768, num_labels: 2\n",
      "✅ roberta-base classifier head fixed with float nn.Linear layers.\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 85,723,398 | Trainable %: 3.44\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 07: roberta-base QLORA r=16, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 33:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>0.241834</td>\n",
       "      <td>0.910892</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.210994</td>\n",
       "      <td>0.920820</td>\n",
       "      <td>0.920791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, QLORA, Seed 42) ---\n",
      "Accuracy: 0.9208\n",
      "F1-macro: 0.9208\n",
      "Training Time (s): 1992.34\n",
      "Peak VRAM (GB): 1.0033\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Define Quantization Config (for QLORA) ---\n",
    "bnb_config_lr2 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 2. Load the 4-bit Quantized Base Model ---\n",
    "print(\"🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 42)...\")\n",
    "qlora_base_model_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config_lr2,\n",
    "    device_map=\"auto\" \n",
    ")\n",
    "\n",
    "# --- 3. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "qlora_base_model_lr2 = prepare_model_for_kbit_training(qlora_base_model_lr2)\n",
    "\n",
    "# --- 4. FIX: Ensure RoBERTa classification head is float ---\n",
    "hidden_size_lr2 = getattr(qlora_base_model_lr2.config, \"hidden_size\", 768)\n",
    "num_labels_lr2 = getattr(qlora_base_model_lr2.config, \"num_labels\", 2)\n",
    "device_lr2 = next(qlora_base_model_lr2.parameters()).device\n",
    "print(f\"Detected hidden size: {hidden_size_lr2}, num_labels: {num_labels_lr2}\")\n",
    "qlora_base_model_lr2.classifier.dense = nn.Linear(hidden_size_lr2, hidden_size_lr2).to(device=device_lr2, dtype=torch.float32)\n",
    "qlora_base_model_lr2.classifier.out_proj = nn.Linear(hidden_size_lr2, num_labels_lr2).to(device=device_lr2, dtype=torch.float32)\n",
    "print(f\"✅ roberta-base classifier head fixed with float nn.Linear layers.\")\n",
    "\n",
    "# --- 5. Define LoRA Configuration (Same as ExpID 05) ---\n",
    "qlora_lora_config_lr2 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # RoBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"classifier.dense\", \"classifier.out_proj\"], # RoBERTa head names\n",
    ")\n",
    "\n",
    "# --- 6. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model_lr2 = get_peft_model(qlora_base_model_lr2, qlora_lora_config_lr2)\n",
    "\n",
    "# --- 7. Calculate and Print Trainable Parameters ---\n",
    "print(\"QLORA Model Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model_lr2)\n",
    "\n",
    "# --- 8. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice_lr2 = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice_lr2 = \"adamw_torch\"\n",
    "\n",
    "# --- 9. Define Training Arguments (ExpID 07, QLORA, Seed 42) ---\n",
    "qlora_training_args_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_qlora_r16_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_qlora_r16_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    \n",
    "    optim=optim_choice_lr2, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, # Fix from ExpID 05\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 10. Initialize Trainer ---\n",
    "qlora_trainer_lr2 = Trainer(\n",
    "    model=qlora_model_lr2,\n",
    "    args=qlora_training_args_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 11. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 12. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base QLORA r=16, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_qlora_lr2 = time.time()\n",
    "qlora_trainer_lr2.train()\n",
    "end_time_qlora_lr2 = time.time()\n",
    "training_time_qlora_lr2 = end_time_qlora_lr2 - start_time_qlora_lr2\n",
    "\n",
    "# --- 13. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_lr2 = peak_vram_bytes_qlora_lr2 / (1024**3)\n",
    "\n",
    "# --- 14. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_lr2 = qlora_trainer_lr2.evaluate()\n",
    "\n",
    "# --- 15. Report All Metrics for ExpID 07 (roberta-base, QLORA, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, QLORA, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_lr2:.4f}\")\n",
    "\n",
    "trainable_params_qlora_lr2 = sum(p.numel() for p in qlora_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b1076-1cfe-4ae4-b7a8-ddfb26e1f28f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, QLORA, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b17371-65ac-420a-a317-5a3adff1e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19436\\621949862.py:124: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  qlora_trainer_lr2_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Preparing model for k-bit training...\n",
      "Detected hidden size: 768, num_labels: 2\n",
      "✅ roberta-base classifier head fixed with float nn.Linear layers.\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 85,723,398 | Trainable %: 3.44\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 07: roberta-base QLORA r=16, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 32:59, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.227908</td>\n",
       "      <td>0.917619</td>\n",
       "      <td>0.917611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.206203</td>\n",
       "      <td>0.922036</td>\n",
       "      <td>0.922020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 03:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, QLORA, Seed 43) ---\n",
      "Accuracy: 0.9220\n",
      "F1-macro: 0.9220\n",
      "Training Time (s): 1980.27\n",
      "Peak VRAM (GB): 1.2111\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Define Quantization Config (for QLORA) ---\n",
    "bnb_config_lr2_s43 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 2. Load the 4-bit Quantized Base Model ---\n",
    "print(\"🔹 Loading 4-bit quantized model for ExpID 07 (QLORA, LR=2e-5, Seed 43)...\")\n",
    "qlora_base_model_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config_lr2_s43,\n",
    "    device_map=\"auto\" \n",
    ")\n",
    "\n",
    "# --- 3. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "qlora_base_model_lr2_s43 = prepare_model_for_kbit_training(qlora_base_model_lr2_s43)\n",
    "\n",
    "# --- 4. FIX: Ensure RoBERTa classification head is float ---\n",
    "hidden_size_lr2_s43 = getattr(qlora_base_model_lr2_s43.config, \"hidden_size\", 768)\n",
    "num_labels_lr2_s43 = getattr(qlora_base_model_lr2_s43.config, \"num_labels\", 2)\n",
    "device_lr2_s43 = next(qlora_base_model_lr2_s43.parameters()).device\n",
    "print(f\"Detected hidden size: {hidden_size_lr2_s43}, num_labels: {num_labels_lr2_s43}\")\n",
    "qlora_base_model_lr2_s43.classifier.dense = nn.Linear(hidden_size_lr2_s43, hidden_size_lr2_s43).to(device=device_lr2_s43, dtype=torch.float32)\n",
    "qlora_base_model_lr2_s43.classifier.out_proj = nn.Linear(hidden_size_lr2_s43, num_labels_lr2_s43).to(device=device_lr2_s43, dtype=torch.float32)\n",
    "print(f\"✅ roberta-base classifier head fixed with float nn.Linear layers.\")\n",
    "\n",
    "# --- 5. Define LoRA Configuration (Same as ExpID 05) ---\n",
    "qlora_lora_config_lr2_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\", \"intermediate.dense\", \"output.dense\"], # RoBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"classifier.dense\", \"classifier.out_proj\"], # RoBERTa head names\n",
    ")\n",
    "\n",
    "# --- 6. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model_lr2_s43 = get_peft_model(qlora_base_model_lr2_s43, qlora_lora_config_lr2_s43)\n",
    "\n",
    "# --- 7. Calculate and Print Trainable Parameters ---\n",
    "print(\"QLORA Model Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model_lr2_s43)\n",
    "\n",
    "# --- 8. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice_lr2_s43 = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice_lr2_s43 = \"adamw_torch\"\n",
    "\n",
    "# --- 9. Define Training Arguments (ExpID 07, QLORA, Seed 43) ---\n",
    "qlora_training_args_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_qlora_r16_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_qlora_r16_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    \n",
    "    optim=optim_choice_lr2_s43, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, # Fix from ExpID 05\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 10. Initialize Trainer ---\n",
    "qlora_trainer_lr2_s43 = Trainer(\n",
    "    model=qlora_model_lr2_s43,\n",
    "    args=qlora_training_args_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 11. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 12. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base QLORA r=16, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_qlora_lr2_s43 = time.time()\n",
    "qlora_trainer_lr2_s43.train()\n",
    "end_time_qlora_lr2_s43 = time.time()\n",
    "training_time_qlora_lr2_s43 = end_time_qlora_lr2_s43 - start_time_qlora_lr2_s43\n",
    "\n",
    "# --- 13. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_lr2_s43 = peak_vram_bytes_qlora_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 14. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_lr2_s43 = qlora_trainer_lr2_s43.evaluate()\n",
    "\n",
    "# --- 15. Report All Metrics for ExpID 07 (roberta-base, QLORA, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, QLORA, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_lr2_s43:.4f}\")\n",
    "\n",
    "trainable_params_qlora_lr2_s43 = sum(p.numel() for p in qlora_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d918a6-a6b1-4af3-aac8-f0bdf53acad4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, IA³, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65316b5b-5bfe-4c7e-8b09-8c41b63516e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19436\\387149638.py:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer_lr2 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable Params: 647,426 | All Params: 125,294,596 | Trainable %: 0.52\n",
      "--- Starting ExpID 07: roberta-base IA³ Attn+FFN, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.638100</td>\n",
       "      <td>0.620864</td>\n",
       "      <td>0.838844</td>\n",
       "      <td>0.838843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.560800</td>\n",
       "      <td>0.563682</td>\n",
       "      <td>0.853270</td>\n",
       "      <td>0.853214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, IA³, Seed 42) ---\n",
      "Accuracy: 0.8533\n",
      "F1-macro: 0.8532\n",
      "Training Time (s): 1145.99\n",
      "Peak VRAM (GB): 2.6262\n",
      "Trainable Params (M): 0.65\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 42)...\")\n",
    "base_model_ia3_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (Same as ExpID 06 for RoBERTa) ---\n",
    "ia3_config_lr2 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"value\", \"output.dense\"],  # RoBERTa layer names\n",
    "    feedforward_modules=[\"output.dense\"],   # RoBERTa FFN layer\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_lr2 = get_peft_model(base_model_ia3_lr2, ia3_config_lr2)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model_lr2) \n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 07, IA³, Seed 42) ---\n",
    "ia3_training_args_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_ia3_ffn_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_ia3_ffn_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer_lr2 = Trainer(\n",
    "    model=ia3_model_lr2,\n",
    "    args=ia3_training_args_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base IA³ Attn+FFN, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_ia3_lr2 = time.time()\n",
    "ia3_trainer_lr2.train()\n",
    "end_time_ia3_lr2 = time.time()\n",
    "training_time_ia3_lr2 = end_time_ia3_lr2 - start_time_ia3_lr2\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_lr2 = peak_vram_bytes_ia3_lr2 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_lr2 = ia3_trainer_lr2.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 07 (roberta-base, IA³, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, IA³, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_lr2:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_lr2 = sum(p.numel() for p in ia3_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf9f7d-dc73-473b-a6fc-58dc995c7586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, IA³, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f986d5-5137-4fc0-a456-8df92f633270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\FAST\\AppData\\Local\\Temp\\ipykernel_19436\\3714316742.py:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ia3_trainer_lr2_s43 = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable Params: 647,426 | All Params: 125,294,596 | Trainable %: 0.52\n",
      "--- Starting ExpID 07: roberta-base IA³ Attn+FFN, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3114' max='3114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3114/3114 19:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>0.822230</td>\n",
       "      <td>0.821304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.561159</td>\n",
       "      <td>0.852095</td>\n",
       "      <td>0.852079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 02:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (roberta-base, IA³, Seed 43) ---\n",
      "Accuracy: 0.8521\n",
      "F1-macro: 0.8521\n",
      "Training Time (s): 1150.47\n",
      "Peak VRAM (GB): 3.0978\n",
      "Trainable Params (M): 0.65\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"roberta-base\", \"model_checkpoint is not set to 'roberta-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 43)...\")\n",
    "base_model_ia3_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (Same as ExpID 06 for RoBERTa) ---\n",
    "ia3_config_lr2_s43 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"value\", \"output.dense\"],  # RoBERTa layer names\n",
    "    feedforward_modules=[\"output.dense\"],   # RoBERTa FFN layer\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_lr2_s43 = get_peft_model(base_model_ia3_lr2_s43, ia3_config_lr2_s43)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model_lr2_s43) \n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 07, IA³, Seed 43) ---\n",
    "ia3_training_args_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/roberta_ia3_ffn_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/roberta_ia3_ffn_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer_lr2_s43 = Trainer(\n",
    "    model=ia3_model_lr2_s43,\n",
    "    args=ia3_training_args_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: roberta-base IA³ Attn+FFN, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_ia3_lr2_s43 = time.time()\n",
    "ia3_trainer_lr2_s43.train()\n",
    "end_time_ia3_lr2_s43 = time.time()\n",
    "training_time_ia3_lr2_s43 = end_time_ia3_lr2_s43 - start_time_ia3_lr2_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_lr2_s43 = peak_vram_bytes_ia3_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_lr2_s43 = ia3_trainer_lr2_s43.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 07 (roberta-base, IA³, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (roberta-base, IA³, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_lr2_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_lr2_s43 = sum(p.numel() for p in ia3_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d0efe-723f-4a14-b00a-f10a375372cd",
   "metadata": {},
   "source": [
    "# DeBERTa "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f3901-4fe5-4b45-a539-63cd2492c9b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f37cb7d-3bee-457e-b0df-bdb3277b1891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for: microsoft/deberta-v3-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading original IMDb dataset...\n",
      "Tokenizing dataset with microsoft/deberta-v3-base tokenizer...\n",
      "--- Preprocessing Complete for DeBERTa-v3 ---\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 24904\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 24678\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define NEW Globals ---\n",
    "model_checkpoint = \"microsoft/deberta-v3-base\"\n",
    "MAX_LENGTH = 256 # From \"Design Matrix\" defaults\n",
    "\n",
    "# --- 2. Load DeBERTa-v3 Tokenizer ---\n",
    "print(f\"Loading tokenizer for: {model_checkpoint}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# --- 3. Load Dataset (already in memory, but for clarity) ---\n",
    "print(\"Reloading original IMDb dataset...\")\n",
    "dataset = load_dataset(\"mteb/imdb\")\n",
    "\n",
    "# --- 4. Define Preprocessing Function (same as before) ---\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize text, truncate to max_length, and apply padding\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "print(f\"Tokenizing dataset with {model_checkpoint} tokenizer...\")\n",
    "# Re-map the *original* dataset with the *new* tokenizer\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# --- 5. Format Dataset for Training ---\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "print(\"--- Preprocessing Complete for DeBERTa-v3 ---\")\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7793ef1-c89c-4805-98f6-4e654faf30c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 1 - Full Fine-Tuning (ExpID 01, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f079b66c-60d0-4a0a-9eef-8ce6f5926d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for Full Fine-Tuning (microsoft/deberta-v3-base)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using GPU: NVIDIA RTX A4000\n",
      "--- Starting ExpID 01: deberta-v3-base Full FT (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 35:42, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.252553</td>\n",
       "      <td>0.930181</td>\n",
       "      <td>0.929948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>0.949186</td>\n",
       "      <td>0.949182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 01 (deberta-v3-base, Seed 42) ---\n",
      "Accuracy: 0.9492\n",
      "F1-macro: 0.9492\n",
      "Training Time (s): 2143.51\n",
      "Peak VRAM (GB): 6.1535\n",
      "Trainable Params (M): 184.42\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load Model (Full Fine-Tuning, deberta-v3-base) ---\n",
    "print(f\"Loading model for Full Fine-Tuning ({model_checkpoint})...\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 01, deberta-v3-base) ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_full_ft_seed_42\",  # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_full_ft_seed_42\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,   # Effective batch size = 16\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    # Other standard settings\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"], \n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    print(f\"\\nUsing GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\\nUsing CPU\")\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 01: deberta-v3-base Full FT (Seed 42) ---\")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb = peak_vram_bytes / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 01 (deberta-v3-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 01 (deberta-v3-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb:.4f}\")\n",
    "print(f\"Trainable Params (M): {trainable_params / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c32ee-a19d-47fc-9ad0-3c27c6ab0dea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 1 - Full Fine-Tuning (ExpID 01, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f772f968-ad0d-4750-ad3b-8a70a0ccf1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for Full Fine-Tuning (microsoft/deberta-v3-base, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 01: deberta-v3-base Full FT (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 35:46, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.171476</td>\n",
       "      <td>0.946471</td>\n",
       "      <td>0.946470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.169453</td>\n",
       "      <td>0.949753</td>\n",
       "      <td>0.949752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 01 (deberta-v3-base, Seed 43) ---\n",
      "Accuracy: 0.9498\n",
      "F1-macro: 0.9498\n",
      "Training Time (s): 2147.26\n",
      "Peak VRAM (GB): 8.2392\n",
      "Trainable Params (M): 184.42\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load Model (Full Fine-Tuning, deberta-v3-base) ---\n",
    "print(f\"Loading model for Full Fine-Tuning ({model_checkpoint}, Seed 43)...\")\n",
    "\n",
    "model_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 01, deberta-v3-base, Seed 43) ---\n",
    "training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_full_ft_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_full_ft_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                         # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_s43 = Trainer(\n",
    "    model=model_s43,\n",
    "    args=training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"], \n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "trainable_params_s43 = sum(\n",
    "    p.numel() for p in model_s43.parameters() if p.requires_grad\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 01: deberta-v3-base Full FT (Seed 43) ---\")\n",
    "\n",
    "start_time_s43 = time.time()\n",
    "trainer_s43.train()\n",
    "end_time_s43 = time.time()\n",
    "training_time_s43 = end_time_s43 - start_time_s43\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_s43 = peak_vram_bytes_s43 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_s43 = trainer_s43.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 01 (deberta-v3-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 01 (deberta-v3-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_s43:.4f}\")\n",
    "print(f\"Trainable Params (M): {trainable_params_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934f9c32-f0f1-42b1-b12a-a669a719b76e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Fine-Tuning (ExpID 02, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6bf876-a00d-4d9e-b8ca-25b41fda0a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (microsoft/deberta-v3-base, r=8, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model Parameter Count:\n",
      "Trainable Params: 296,450 | All Params: 184,720,132 | Trainable %: 0.16\n",
      "--- Starting ExpID 02: deberta-v3-base LoRA r=8 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 29:18, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.442700</td>\n",
       "      <td>0.268452</td>\n",
       "      <td>0.904692</td>\n",
       "      <td>0.904679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.229449</td>\n",
       "      <td>0.914377</td>\n",
       "      <td>0.914344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 02 (deberta-v3-base, Seed 42) ---\n",
      "Accuracy: 0.9144\n",
      "F1-macro: 0.9143\n",
      "Training Time (s): 1759.22\n",
      "Peak VRAM (GB): 7.9864\n",
      "Trainable Params (M): 0.30\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=8, Seed 42)...\")\n",
    "base_model_lora = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 02 for DeBERTa) ---\n",
    "# From PDF: r=8, targets=[q,v], placement=Attn, alpha=16\n",
    "# DeBERTa's attention layers are 'query_proj' and 'value_proj'\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query_proj\", \"value_proj\"], # <-- DeBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", # Sequence Classification\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters to the base model ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model = get_peft_model(base_model_lora, lora_config)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"LoRA Model Parameter Count:\")\n",
    "print_trainable_parameters(lora_model) \n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 02, Seed 42) ---\n",
    "lora_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r8_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r8_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model, # <-- Use the lora_model\n",
    "    args=lora_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 02: deberta-v3-base LoRA r=8 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora = time.time()\n",
    "lora_trainer.train()\n",
    "end_time_lora = time.time()\n",
    "training_time_lora = end_time_lora - start_time_lora\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora = peak_vram_bytes_lora / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora = lora_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 02 (deberta-v3-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 02 (deberta-v3-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora:.4f}\")\n",
    "\n",
    "# Get the trainable param count again to be precise\n",
    "trainable_params_lora = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f622b3f-b23e-4926-96f2-9f335b4add90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Fine-Tuning (ExpID 02, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060dd8eb-b68f-4fdb-9d5b-b400927eb7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (microsoft/deberta-v3-base, r=8, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model Parameter Count:\n",
      "Trainable Params: 296,450 | All Params: 184,720,132 | Trainable %: 0.16\n",
      "--- Starting ExpID 02: deberta-v3-base LoRA r=8 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 29:20, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.493600</td>\n",
       "      <td>0.329484</td>\n",
       "      <td>0.904449</td>\n",
       "      <td>0.904441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.247258</td>\n",
       "      <td>0.912108</td>\n",
       "      <td>0.912108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 02 (deberta-v3-base, Seed 43) ---\n",
      "Accuracy: 0.9121\n",
      "F1-macro: 0.9121\n",
      "Training Time (s): 1761.43\n",
      "Peak VRAM (GB): 8.6848\n",
      "Trainable Params (M): 0.30\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=8, Seed 43)...\")\n",
    "base_model_lora_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 02 for DeBERTa) ---\n",
    "lora_config_s43 = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query_proj\", \"value_proj\"], # DeBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters to the base model ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model_s43 = get_peft_model(base_model_lora_s43, lora_config_s43)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"LoRA Model Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 02, Seed 43) ---\n",
    "lora_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r8_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r8_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_trainer_s43 = Trainer(\n",
    "    model=lora_model_s43, \n",
    "    args=lora_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 02: deberta-v3-base LoRA r=8 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_s43 = time.time()\n",
    "lora_trainer_s43.train()\n",
    "end_time_lora_s43 = time.time()\n",
    "training_time_lora_s43 = end_time_lora_s43 - start_time_lora_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_s43 = peak_vram_bytes_lora_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_s43 = lora_trainer_s43.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 02 (deberta-v3-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 02 (deberta-v3-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again to be precise\n",
    "trainable_params_lora_s43 = sum(p.numel() for p in lora_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d28eb-f218-470b-af2b-2dd637961236",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Rank Sensitivity (ExpID 03, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78080d3a-96f7-47e5-93b7-cb6d5d75ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (microsoft/deberta-v3-base, r=16, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model (r=16) Parameter Count:\n",
      "Trainable Params: 591,362 | All Params: 185,015,044 | Trainable %: 0.32\n",
      "--- Starting ExpID 03: deberta-v3-base LoRA r=16 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 30:19, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.478700</td>\n",
       "      <td>0.366719</td>\n",
       "      <td>0.899303</td>\n",
       "      <td>0.899250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.290048</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.905942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 03 (deberta-v3-base, Seed 42) ---\n",
      "Accuracy: 0.9061\n",
      "F1-macro: 0.9059\n",
      "Training Time (s): 1820.70\n",
      "Peak VRAM (GB): 3.8123\n",
      "Trainable Params (M): 0.59\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=16, Seed 42)...\")\n",
    "base_model_lora_r16 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 03 for DeBERTa) ---\n",
    "lora_config_r16 = LoraConfig(\n",
    "    r=16, # <-- CHANGED\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query_proj\", \"value_proj\"], # DeBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model_r16 = get_peft_model(base_model_lora_r16, lora_config_r16)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (r=16) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_r16)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_r16_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r16_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r16_seed_42\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_r16_trainer = Trainer(\n",
    "    model=lora_model_r16,\n",
    "    args=lora_r16_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 03: deberta-v3-base LoRA r=16 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_r16 = time.time()\n",
    "lora_r16_trainer.train()\n",
    "end_time_lora_r16 = time.time()\n",
    "training_time_lora_r16 = end_time_lora_r16 - start_time_lora_r16\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_r16 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_r16 = peak_vram_bytes_lora_r16 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_r16 = lora_r16_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 03 (deberta-v3-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 03 (deberta-v3-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_r16['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_r16['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_r16:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_r16:.4f}\")\n",
    "\n",
    "trainable_params_lora_r16 = sum(p.numel() for p in lora_model_r16.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_r16 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833d854-8e4f-4c04-9291-fa060161a1c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Rank Sensitivity (ExpID 03, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612e7882-8dbf-464b-86d5-5cdb4862e375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (microsoft/deberta-v3-base, r=16, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapters...\n",
      "LoRA Model (r=16) Parameter Count:\n",
      "Trainable Params: 591,362 | All Params: 185,015,044 | Trainable %: 0.32\n",
      "--- Starting ExpID 03: deberta-v3-base LoRA r=16 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 30:15, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.902707</td>\n",
       "      <td>0.902701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.263700</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>0.912513</td>\n",
       "      <td>0.912510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 03 (deberta-v3-base, Seed 43) ---\n",
      "Accuracy: 0.9125\n",
      "F1-macro: 0.9125\n",
      "Training Time (s): 1816.11\n",
      "Peak VRAM (GB): 4.5215\n",
      "Trainable Params (M): 0.59\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, r=16, Seed 43)...\")\n",
    "base_model_lora_r16_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 03 for DeBERTa) ---\n",
    "lora_config_r16_s43 = LoraConfig(\n",
    "    r=16, # <-- Rank 16\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query_proj\", \"value_proj\"], # DeBERTa layer names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA adapters...\")\n",
    "lora_model_r16_s43 = get_peft_model(base_model_lora_r16_s43, lora_config_r16_s43)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (r=16) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_r16_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_r16_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r16_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r16_seed_43\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_r16_s43_trainer = Trainer(\n",
    "    model=lora_model_r16_s43,\n",
    "    args=lora_r16_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 03: deberta-v3-base LoRA r=16 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_r16_s43 = time.time()\n",
    "lora_r16_s43_trainer.train()\n",
    "end_time_lora_r16_s43 = time.time()\n",
    "training_time_lora_r16_s43 = end_time_lora_r16_s43 - start_time_lora_r16_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_r16_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_r16_s43 = peak_vram_bytes_lora_r16_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_r16_s43 = lora_r16_s43_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 03 (deberta-v3-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 03 (deberta-v3-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_r16_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_r16_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_r16_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_r16_s43:.4f}\")\n",
    "\n",
    "trainable_params_lora_r16_s43 = sum(p.numel() for p in lora_model_r16_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_r16_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31043c7a-798a-471f-8f26-e84cb1f6ba7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Placement (ExpID 04, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f04893b-aa68-4bcd-9376-b01de7f0658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (microsoft/deberta-v3-base, Attn+FFN, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA Model (Attn+FFN) Parameter Count:\n",
      "Trainable Params: 2,360,834 | All Params: 186,784,516 | Trainable %: 1.26\n",
      "--- Starting ExpID 04: deberta-v3-base LoRA r=16 Attn+FFN (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 34:17, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.205209</td>\n",
       "      <td>0.928317</td>\n",
       "      <td>0.928285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.193162</td>\n",
       "      <td>0.932085</td>\n",
       "      <td>0.932068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 04 (deberta-v3-base, Seed 42) ---\n",
      "Accuracy: 0.9321\n",
      "F1-macro: 0.9321\n",
      "Training Time (s): 2057.86\n",
      "Peak VRAM (GB): 5.7940\n",
      "Trainable Params (M): 2.36\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, Attn+FFN, Seed 42)...\")\n",
    "base_model_lora_ffn = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 04 for DeBERTa) ---\n",
    "# We now add the FFN layers 'intermediate.dense' and 'output.dense'\n",
    "lora_config_ffn = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], # <-- CHANGED\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_ffn = get_peft_model(base_model_lora_ffn, lora_config_ffn)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (Attn+FFN) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_ffn)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_ffn_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r16_ffn_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r16_ffn_seed_42\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_ffn_trainer = Trainer(\n",
    "    model=lora_model_ffn,\n",
    "    args=lora_ffn_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 04: deberta-v3-base LoRA r=16 Attn+FFN (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_ffn = time.time()\n",
    "lora_ffn_trainer.train()\n",
    "end_time_lora_ffn = time.time()\n",
    "training_time_lora_ffn = end_time_lora_ffn - start_time_lora_ffn\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_ffn = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_ffn = peak_vram_bytes_lora_ffn / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_ffn = lora_ffn_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 04 (deberta-v3-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 04 (deberta-v3-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_ffn['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_ffn['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_ffn:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_ffn:.4f}\")\n",
    "\n",
    "trainable_params_lora_ffn = sum(p.numel() for p in lora_model_ffn.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_ffn / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d76fd7-7222-4755-a5f9-738bb48dce3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 2 - LoRA Placement (ExpID 04, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea56652-6d6e-42b8-8a12-7dd359ac8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for LoRA (microsoft/deberta-v3-base, Attn+FFN, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA Model (Attn+FFN) Parameter Count:\n",
      "Trainable Params: 2,360,834 | All Params: 186,784,516 | Trainable %: 1.26\n",
      "--- Starting ExpID 04: deberta-v3-base LoRA r=16 Attn+FFN (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 34:33, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.202291</td>\n",
       "      <td>0.928925</td>\n",
       "      <td>0.928883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.210200</td>\n",
       "      <td>0.188837</td>\n",
       "      <td>0.932531</td>\n",
       "      <td>0.932511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 04 (deberta-v3-base, Seed 43) ---\n",
      "Accuracy: 0.9325\n",
      "F1-macro: 0.9325\n",
      "Training Time (s): 2074.57\n",
      "Peak VRAM (GB): 6.5237\n",
      "Trainable Params (M): 2.36\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for LoRA ({model_checkpoint}, Attn+FFN, Seed 43)...\")\n",
    "base_model_lora_ffn_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (ExpID 04 for DeBERTa) ---\n",
    "lora_config_ffn_s43 = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], # DeBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_ffn_s43 = get_peft_model(base_model_lora_ffn_s43, lora_config_ffn_s43)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (Attn+FFN) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_ffn_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments ---\n",
    "lora_ffn_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r16_ffn_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r16_ffn_seed_43\",   # <-- Changed\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                         # <-- CHANGED\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_ffn_s43_trainer = Trainer(\n",
    "    model=lora_model_ffn_s43,\n",
    "    args=lora_ffn_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 04: deberta-v3-base LoRA r=16 Attn+FFN (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_ffn_s43 = time.time()\n",
    "lora_ffn_s43_trainer.train()\n",
    "end_time_lora_ffn_s43 = time.time()\n",
    "training_time_lora_ffn_s43 = end_time_lora_ffn_s43 - start_time_lora_ffn_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_ffn_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_ffn_s43 = peak_vram_bytes_lora_ffn_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_ffn_s43 = lora_ffn_s43_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 04 (deberta-v3-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 04 (deberta-v3-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_ffn_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_ffn_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_ffn_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_ffn_s43:.4f}\")\n",
    "\n",
    "trainable_params_lora_ffn_s43 = sum(p.numel() for p in lora_model_ffn_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_ffn_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747bbe8-ba92-4cbe-a44b-8886b669ea1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 3 - QLORA (ExpID 05, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9320d80e-756d-4ba3-9964-d3f015169223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PreTrainedModel.to monkey-patch applied.\n",
      "✅ DeBERTa _no_split_modules monkey-patch applied.\n",
      "🔹 Loading 4-bit quantized ENCODER for QLORA (deberta-v3-base)...\n",
      "✅ Original PreTrainedModel.to restored.\n",
      "Loaded model device map: {'': 0}\n",
      "Shard distribution: Counter({0: 1})\n",
      "🔹 Preparing model for k-bit training...\n",
      "✅ Encoder loaded and custom float head placed on cuda\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 144,907,780 | Trainable %: 2.04\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 05: deberta-v3-base QLORA r=16 (Seed 42) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 47:53, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.202430</td>\n",
       "      <td>0.925642</td>\n",
       "      <td>0.925560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.931680</td>\n",
       "      <td>0.931650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 05:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 05 (deberta-v3-base, Seed 42) ---\n",
      "Accuracy: 0.9317\n",
      "F1-macro: 0.9316\n",
      "Training Time (s): 2874.87\n",
      "Peak VRAM (GB): 1.3070\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,  # Using AutoModel\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter # For device map printing\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. FIX: Temporary safe patch for .to() ---\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "_orig_pretrainedmodel_to = PreTrainedModel.to\n",
    "\n",
    "def _patched_to(self, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Call original .to, but if it raises the known bitsandbytes ValueError,\n",
    "    swallow it and return self (so dispatch_model can continue).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return _orig_pretrainedmodel_to(self, *args, **kwargs)\n",
    "    except ValueError as e:\n",
    "        msg = str(e)\n",
    "        if \"`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models\" in msg:\n",
    "            # swallow the specific BnB `.to()` error during loading (temporary)\n",
    "            return self\n",
    "        # re-raise anything else\n",
    "        raise\n",
    "\n",
    "# Apply patch\n",
    "PreTrainedModel.to = _patched_to\n",
    "print(\"✅ PreTrainedModel.to monkey-patch applied.\")\n",
    "\n",
    "# Also apply _no_split_modules patch\n",
    "try:\n",
    "    from transformers.models.deberta_v2.modeling_deberta_v2 import DebertaV2Model, DebertaV2PreTrainedModel\n",
    "    DebertaV2Model._no_split_modules = []\n",
    "    DebertaV2PreTrainedModel._no_split_modules = []\n",
    "    print(\"✅ DeBERTa _no_split_modules monkey-patch applied.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not monkey-patch DeBERTa classes: {e}\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 2. Define Quantization Config (for QLORA) ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 3. Load the 4-bit Quantized *Base Encoder* ---\n",
    "print(\"🔹 Loading 4-bit quantized ENCODER for QLORA (deberta-v3-base)...\")\n",
    "encoder = AutoModel.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\", # <-- This should now work\n",
    ")\n",
    "\n",
    "# --- 4. Immediately restore original .to() ---\n",
    "PreTrainedModel.to = _orig_pretrainedmodel_to\n",
    "print(\"✅ Original PreTrainedModel.to restored.\")\n",
    "\n",
    "# --- 5. Inspect device map ---\n",
    "hf_map = getattr(encoder, \"hf_device_map\", None) or getattr(encoder, \"device_map\", None)\n",
    "print(\"Loaded model device map:\", hf_map)\n",
    "if hf_map is None:\n",
    "     print(\"⚠️ device_map is None. Model may be on CPU.\")\n",
    "else:\n",
    "    dests = [d for d in hf_map.values()] if isinstance(hf_map, dict) else None\n",
    "    if dests:\n",
    "        print(\"Shard distribution:\", Counter(dests))\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 6. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "encoder = prepare_model_for_kbit_training(encoder)\n",
    "\n",
    "# --- 7. YOUR \"CLEAN FIX\" WRAPPER CLASS ---\n",
    "class DebertaSeqClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, encoder, hidden_size, num_labels, head_device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head_device = torch.device(head_device)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # expose what PEFT/Trainer expect\n",
    "        self.config = encoder.config\n",
    "        self.base_model = encoder\n",
    "        self.model = encoder\n",
    "\n",
    "        # float32 head on head_device\n",
    "        self.pooler = nn.Linear(hidden_size, hidden_size).to(device=self.head_device, dtype=torch.float32)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels).to(device=self.head_device, dtype=torch.float32)\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.encoder.get_input_embeddings()\n",
    "\n",
    "    def set_input_embeddings(self, new_emb):\n",
    "        return self.encoder.set_input_embeddings(new_emb)\n",
    "\n",
    "    def resize_token_embeddings(self, *args, **kwargs):\n",
    "        return self.encoder.resize_token_embeddings(*args, **kwargs)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        # Remove possible duplicate 'return_dict' passed from outside (Trainer/PEFT)\n",
    "        return_dict = kwargs.pop(\"return_dict\", True)\n",
    "\n",
    "        # Run encoder (it may be sharded/quantized and live on different devices)\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # CLS pooling (index 0)\n",
    "        pooled = encoder_outputs.last_hidden_state[:, 0]\n",
    "\n",
    "        # move pooled representation to head device and cast to float32\n",
    "        pooled = pooled.to(self.head_device, dtype=torch.float32)\n",
    "\n",
    "        # pass through float head\n",
    "        pooled = self.pooler(pooled)\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        outputs = {\"logits\": logits}\n",
    "        if labels is not None:\n",
    "            labels = labels.to(self.head_device)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs[\"loss\"] = loss\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    # override .to() so Trainer.model.to(...) only moves the float head\n",
    "    def to(self, *args, **kwargs):\n",
    "        if len(args) > 0 and args[0] is not None:\n",
    "            device = torch.device(args[0])\n",
    "        else:\n",
    "            device = kwargs.get(\"device\", self.head_device)\n",
    "\n",
    "        self.pooler = self.pooler.to(device=device, dtype=torch.float32)\n",
    "        self.classifier = self.classifier.to(device=device, dtype=torch.float32)\n",
    "        self.head_device = device\n",
    "\n",
    "        # keep aliases consistent\n",
    "        self.base_model = self.encoder\n",
    "        self.model = self.encoder\n",
    "        return self\n",
    "# --- End of Custom Wrapper ---\n",
    "\n",
    "# --- 8. Instantiate the Wrapper Model ---\n",
    "head_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = encoder.config.hidden_size\n",
    "num_labels = 2\n",
    "\n",
    "qlora_base_model = DebertaSeqClassificationModel(encoder, hidden_size, num_labels, head_device)\n",
    "print(f\"✅ Encoder loaded and custom float head placed on {head_device}\")\n",
    "\n",
    "\n",
    "# --- 9. Define LoRA Configuration (ExpID 05 for DeBERTa) ---\n",
    "qlora_lora_config = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], # DeBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"pooler\", \"classifier\"], # <-- Wrapper module names\n",
    ")\n",
    "\n",
    "# --- 10. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model = get_peft_model(qlora_base_model, qlora_lora_config)\n",
    "\n",
    "# --- 11. Calculate and Print Trainable Parameters ---\n",
    "print(\"QLORA Model Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model)\n",
    "\n",
    "# --- 12. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice = \"adamw_torch\"\n",
    "\n",
    "# --- 13. Define Training Arguments (ExpID 05, Seed 42) ---\n",
    "qlora_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_qlora_r16_seed_42\", \n",
    "    logging_dir=\"./logs/deberta_qlora_r16_seed_42\",   \n",
    "    \n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    \n",
    "    optim=optim_choice, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, \n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 14. Initialize Trainer ---\n",
    "qlora_trainer = Trainer(\n",
    "    model=qlora_model,\n",
    "    args=qlora_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 15. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 16. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 05: deberta-v3-base QLORA r=16 (Seed 42) ---\")\n",
    "\n",
    "start_time_qlora = time.time()\n",
    "qlora_trainer.train()\n",
    "end_time_qlora = time.time()\n",
    "training_time_qlora = end_time_qlora - start_time_qlora\n",
    "\n",
    "# --- 17. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora = peak_vram_bytes_qlora / (1024**3)\n",
    "\n",
    "# --- 18. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora = qlora_trainer.evaluate()\n",
    "\n",
    "# --- 19. Report All Metrics for ExpID 05 (deberta-v3-base, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 05 (deberta-v3-base, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora:.4f}\")\n",
    "\n",
    "trainable_params_qlora = sum(p.numel() for p in qlora_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ddff6-5944-454b-9bb4-0bef787bda65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 3 - QLORA (ExpID 05, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0086a19d-e748-4088-bb16-aac2686d1e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PreTrainedModel.to monkey-patch applied.\n",
      "✅ DeBERTa _no_split_modules monkey-patch applied.\n",
      "🔹 Loading 4-bit quantized ENCODER for QLORA (deberta-v3-base, Seed 43)...\n",
      "✅ Original PreTrainedModel.to restored.\n",
      "Loaded model device map: {'': 0}\n",
      "Shard distribution: Counter({0: 1})\n",
      "🔹 Preparing model for k-bit training...\n",
      "✅ Encoder loaded and custom float head placed on cuda\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 144,907,780 | Trainable %: 2.04\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 05: deberta-v3-base QLORA r=16 (Seed 43) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 46:59, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.201055</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>0.927841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.186631</td>\n",
       "      <td>0.931234</td>\n",
       "      <td>0.931215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 05 (deberta-v3-base, Seed 43) ---\n",
      "Accuracy: 0.9312\n",
      "F1-macro: 0.9312\n",
      "Training Time (s): 2820.78\n",
      "Peak VRAM (GB): 1.7365\n",
      "Trainable Params (M): 2.95\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,  # Using AutoModel\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter # For device map printing\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. FIX: Temporary safe patch for .to() ---\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "_orig_pretrainedmodel_to = PreTrainedModel.to\n",
    "\n",
    "def _patched_to(self, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Call original .to, but if it raises the known bitsandbytes ValueError,\n",
    "    swallow it and return self (so dispatch_model can continue).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return _orig_pretrainedmodel_to(self, *args, **kwargs)\n",
    "    except ValueError as e:\n",
    "        msg = str(e)\n",
    "        if \"`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models\" in msg:\n",
    "            # swallow the specific BnB `.to()` error during loading (temporary)\n",
    "            return self\n",
    "        # re-raise anything else\n",
    "        raise\n",
    "\n",
    "# Apply patch\n",
    "PreTrainedModel.to = _patched_to\n",
    "print(\"✅ PreTrainedModel.to monkey-patch applied.\")\n",
    "\n",
    "# Also apply _no_split_modules patch\n",
    "try:\n",
    "    from transformers.models.deberta_v2.modeling_deberta_v2 import DebertaV2Model, DebertaV2PreTrainedModel\n",
    "    DebertaV2Model._no_split_modules = []\n",
    "    DebertaV2PreTrainedModel._no_split_modules = []\n",
    "    print(\"✅ DeBERTa _no_split_modules monkey-patch applied.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not monkey-patch DeBERTa classes: {e}\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 2. Define Quantization Config (for QLORA) ---\n",
    "bnb_config_s43 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 3. Load the 4-bit Quantized *Base Encoder* ---\n",
    "print(\"🔹 Loading 4-bit quantized ENCODER for QLORA (deberta-v3-base, Seed 43)...\")\n",
    "encoder_s43 = AutoModel.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    quantization_config=bnb_config_s43,\n",
    "    device_map=\"auto\", \n",
    ")\n",
    "\n",
    "# --- 4. Immediately restore original .to() ---\n",
    "PreTrainedModel.to = _orig_pretrainedmodel_to\n",
    "print(\"✅ Original PreTrainedModel.to restored.\")\n",
    "\n",
    "# --- 5. Inspect device map ---\n",
    "hf_map_s43 = getattr(encoder_s43, \"hf_device_map\", None) or getattr(encoder_s43, \"device_map\", None)\n",
    "print(\"Loaded model device map:\", hf_map_s43)\n",
    "if hf_map_s43 is None:\n",
    "     print(\"⚠️ device_map is None. Model may be on CPU.\")\n",
    "else:\n",
    "    dests_s43 = [d for d in hf_map_s43.values()] if isinstance(hf_map_s43, dict) else None\n",
    "    if dests_s43:\n",
    "        print(\"Shard distribution:\", Counter(dests_s43))\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 6. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "encoder_s43 = prepare_model_for_kbit_training(encoder_s43)\n",
    "\n",
    "# --- 7. YOUR \"CLEAN FIX\" WRAPPER CLASS ---\n",
    "class DebertaSeqClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, encoder, hidden_size, num_labels, head_device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head_device = torch.device(head_device)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # expose what PEFT/Trainer expect\n",
    "        self.config = encoder.config\n",
    "        self.base_model = encoder\n",
    "        self.model = encoder\n",
    "\n",
    "        # float32 head on head_device\n",
    "        self.pooler = nn.Linear(hidden_size, hidden_size).to(device=self.head_device, dtype=torch.float32)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels).to(device=self.head_device, dtype=torch.float32)\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.encoder.get_input_embeddings()\n",
    "\n",
    "    def set_input_embeddings(self, new_emb):\n",
    "        return self.encoder.set_input_embeddings(new_emb)\n",
    "\n",
    "    def resize_token_embeddings(self, *args, **kwargs):\n",
    "        return self.encoder.resize_token_embeddings(*args, **kwargs)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        # Remove possible duplicate 'return_dict' passed from outside (Trainer/PEFT)\n",
    "        return_dict = kwargs.pop(\"return_dict\", True)\n",
    "\n",
    "        # Run encoder (it may be sharded/quantized and live on different devices)\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # CLS pooling (index 0)\n",
    "        pooled = encoder_outputs.last_hidden_state[:, 0]\n",
    "\n",
    "        # move pooled representation to head device and cast to float32\n",
    "        pooled = pooled.to(self.head_device, dtype=torch.float32)\n",
    "\n",
    "        # pass through float head\n",
    "        pooled = self.pooler(pooled)\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        outputs = {\"logits\": logits}\n",
    "        if labels is not None:\n",
    "            labels = labels.to(self.head_device)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs[\"loss\"] = loss\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    # override .to() so Trainer.model.to(...) only moves the float head\n",
    "    def to(self, *args, **kwargs):\n",
    "        if len(args) > 0 and args[0] is not None:\n",
    "            device = torch.device(args[0])\n",
    "        else:\n",
    "            device = kwargs.get(\"device\", self.head_device)\n",
    "\n",
    "        self.pooler = self.pooler.to(device=device, dtype=torch.float32)\n",
    "        self.classifier = self.classifier.to(device=device, dtype=torch.float32)\n",
    "        self.head_device = device\n",
    "\n",
    "        # keep aliases consistent\n",
    "        self.base_model = self.encoder\n",
    "        self.model = self.encoder\n",
    "        return self\n",
    "# --- End of Custom Wrapper ---\n",
    "\n",
    "# --- 8. Instantiate the Wrapper Model ---\n",
    "head_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size_s43 = encoder_s43.config.hidden_size\n",
    "num_labels_s43 = 2\n",
    "\n",
    "qlora_base_model_s43 = DebertaSeqClassificationModel(encoder_s43, hidden_size_s43, num_labels_s43, head_device)\n",
    "print(f\"✅ Encoder loaded and custom float head placed on {head_device}\")\n",
    "\n",
    "\n",
    "# --- 9. Define LoRA Configuration (ExpID 05 for DeBERTa) ---\n",
    "qlora_lora_config_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], # DeBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"pooler\", \"classifier\"], # <-- Wrapper module names\n",
    ")\n",
    "\n",
    "# --- 10. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model_s43 = get_peft_model(qlora_base_model_s43, qlora_lora_config_s43)\n",
    "\n",
    "# --- 11. Calculate and Print Trainable Parameters ---\n",
    "print(\"QLORA Model Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model_s43)\n",
    "\n",
    "# --- 12. Optimizer Fallback Logic ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice_s43 = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice_s43 = \"adamw_torch\"\n",
    "\n",
    "# --- 13. Define Training Arguments (ExpID 05, Seed 43) ---\n",
    "qlora_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_qlora_r16_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_qlora_r16_seed_43\",   # <-- Changed\n",
    "    \n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    \n",
    "    optim=optim_choice_s43, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, \n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 14. Initialize Trainer ---\n",
    "qlora_trainer_s43 = Trainer(\n",
    "    model=qlora_model_s43,\n",
    "    args=qlora_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 15. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 16. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 05: deberta-v3-base QLORA r=16 (Seed 43) ---\")\n",
    "\n",
    "start_time_qlora_s43 = time.time()\n",
    "qlora_trainer_s43.train()\n",
    "end_time_qlora_s43 = time.time()\n",
    "training_time_qlora_s43 = end_time_qlora_s43 - start_time_qlora_s43\n",
    "\n",
    "# --- 17. Get VRAM Usage ---\n",
    "peak_vram_bytes_qlora_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_s43 = peak_vram_bytes_qlora_s43 / (1024**3)\n",
    "\n",
    "# --- 18. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_s43 = qlora_trainer_s43.evaluate()\n",
    "\n",
    "# --- 19. Report All Metrics for ExpID 05 (deberta-v3-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 05 (deberta-v3-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_s43:.4f}\")\n",
    "\n",
    "trainable_params_qlora_s43 = sum(p.numel() for p in qlora_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_qlora_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f554c-fcdb-4816-b95c-c5ed7c9579a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Method 4 - Adapter Tuning (IA³) (ExpID 06, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632f7d6e-005f-401b-afbb-0abccd3e2dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for IA³ (microsoft/deberta-v3-base, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable Params: 56,834 | All Params: 184,480,516 | Trainable %: 0.03\n",
      "--- Starting ExpID 06: deberta-v3-base IA³ Attn+FFN (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 28:21, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.692802</td>\n",
       "      <td>0.541008</td>\n",
       "      <td>0.528284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.574966</td>\n",
       "      <td>0.566367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 06 (deberta-v3-base, Seed 43) ---\n",
      "Accuracy: 0.5750\n",
      "F1-macro: 0.5664\n",
      "Training Time (s): 1701.93\n",
      "Peak VRAM (GB): 4.4967\n",
      "Trainable Params (M): 0.06\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter # For device map printing\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for IA³ ({model_checkpoint}, Seed 43)...\")\n",
    "base_model_ia3_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (ExpID 06 for DeBERTa) ---\n",
    "ia3_config_s43 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"value_proj\", \"output.dense\"],  # DeBERTa layer names\n",
    "    feedforward_modules=[\"output.dense\"],   # DeBERTa FFN layer\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_s43 = get_peft_model(base_model_ia3_s43, ia3_config_s43)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 06, Seed 43) ---\n",
    "ia3_training_args_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_ia3_ffn_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_ia3_ffn_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, \n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer_s43 = Trainer(\n",
    "    model=ia3_model_s43,\n",
    "    args=ia3_training_args_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 06: deberta-v3-base IA³ Attn+FFN (Seed 43) ---\")\n",
    "\n",
    "start_time_ia3_s43 = time.time()\n",
    "ia3_trainer_s43.train()\n",
    "end_time_ia3_s43 = time.time()\n",
    "training_time_ia3_s43 = end_time_ia3_s43 - start_time_ia3_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_s43 = peak_vram_bytes_ia3_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_s43 = ia3_trainer_s43.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 06 (deberta-v3-base, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 06 (deberta-v3-base, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_s43 = sum(p.numel() for p in ia3_model_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_s43 / 1_000_000:.2f}\") # <-- Corrected line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbade4-30e4-4174-a2bd-709f4b719746",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2c128a-a3b7-431b-b7c0-c8e52c458ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 07: deberta-v3-base Full FT, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 35:39, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.225570</td>\n",
       "      <td>0.935165</td>\n",
       "      <td>0.934996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.186281</td>\n",
       "      <td>0.949712</td>\n",
       "      <td>0.949706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (deberta-v3-base, Full FT, Seed 42) ---\n",
      "Accuracy: 0.9497\n",
      "F1-macro: 0.9497\n",
      "Training Time (s): 2140.87\n",
      "Peak VRAM (GB): 7.5480\n",
      "Trainable Params (M): 184.42\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter # For device map printing\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load Model (Full Fine-Tuning) ---\n",
    "print(f\"Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 42)...\")\n",
    "model_ft_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 07, Full FT) ---\n",
    "training_args_ft_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_full_ft_lr2_seed_42\",  # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_full_ft_lr2_seed_42\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_ft_lr2 = Trainer(\n",
    "    model=model_ft_lr2,\n",
    "    args=training_args_ft_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base Full FT, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_ft_lr2 = time.time()\n",
    "trainer_ft_lr2.train()\n",
    "end_time_ft_lr2 = time.time()\n",
    "training_time_ft_lr2 = end_time_ft_lr2 - start_time_ft_lr2\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_ft_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ft_lr2 = peak_vram_bytes_ft_lr2 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ft_lr2 = trainer_ft_lr2.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 07 (deberta-v3-base, Full FT, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (deberta-v3-base, Full FT, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ft_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ft_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ft_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ft_lr2:.4f}\")\n",
    "\n",
    "trainable_params_ft_lr2 = sum(p.numel() for p in model_ft_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ft_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4db6f5-895b-4a3e-b6f8-ece19e61bb39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb43fbf-6c0c-4a4b-96b2-5f2dc6755b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting ExpID 07: deberta-v3-base Full FT, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 35:45, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.169703</td>\n",
       "      <td>0.945093</td>\n",
       "      <td>0.945093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.184182</td>\n",
       "      <td>0.948861</td>\n",
       "      <td>0.948859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (deberta-v3-base, Full FT, Seed 43) ---\n",
      "Accuracy: 0.9489\n",
      "F1-macro: 0.9489\n",
      "Training Time (s): 2146.23\n",
      "Peak VRAM (GB): 9.6277\n",
      "Trainable Params (M): 184.42\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Model (Full Fine-Tuning) ---\n",
    "print(f\"Reloading model for ExpID 07 (Full FT, LR=2e-5, Seed 43)...\")\n",
    "model_ft_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define Training Arguments (ExpID 07, Full FT, Seed 43) ---\n",
    "training_args_ft_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_full_ft_lr2_seed_43\",  # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_full_ft_lr2_seed_43\",    # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 3. Initialize Trainer ---\n",
    "trainer_ft_lr2_s43 = Trainer(\n",
    "    model=model_ft_lr2_s43,\n",
    "    args=training_args_ft_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 4. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 5. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base Full FT, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_ft_lr2_s43 = time.time()\n",
    "trainer_ft_lr2_s43.train()\n",
    "end_time_ft_lr2_s43 = time.time()\n",
    "training_time_ft_lr2_s43 = end_time_ft_lr2_s43 - start_time_ft_lr2_s43\n",
    "\n",
    "# --- 6. Get VRAM Usage ---\n",
    "peak_vram_bytes_ft_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ft_lr2_s43 = peak_vram_bytes_ft_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 7. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ft_lr2_s43 = trainer_ft_lr2_s43.evaluate()\n",
    "\n",
    "# --- 8. Report All Metrics for ExpID 07 (deberta-v3-base, Full FT, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (deberta-v3-base, Full FT, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ft_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ft_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ft_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ft_lr2_s43:.4f}\")\n",
    "\n",
    "trainable_params_ft_lr2_s43 = sum(p.numel() for p in model_ft_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ft_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e92374-0a17-4229-837b-d95d616c7f77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, LoRA, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf20678d-fafd-487e-afd1-47b6a8105354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "LoRA Model (Attn+FFN, LR=2e-5) Parameter Count:\n",
      "Trainable Params: 2,360,834 | All Params: 186,784,516 | Trainable %: 1.26\n",
      "--- Starting ExpID 07: deberta-v3-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 33:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.189134</td>\n",
       "      <td>0.933909</td>\n",
       "      <td>0.933879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.184900</td>\n",
       "      <td>0.178596</td>\n",
       "      <td>0.936381</td>\n",
       "      <td>0.936363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (deberta-v3-base, LoRA, Seed 42) ---\n",
      "Accuracy: 0.9364\n",
      "F1-macro: 0.9364\n",
      "Training Time (s): 2018.19\n",
      "Peak VRAM (GB): 9.9509\n",
      "Trainable Params (M): 2.36\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 42)...\")\n",
    "base_model_lora_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (Same as ExpID 04 for DeBERTa) ---\n",
    "lora_config_lr2 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], # DeBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_lr2 = get_peft_model(base_model_lora_lr2, lora_config_lr2)\n",
    "\n",
    "# --- 4. Print Trainable Parameters ---\n",
    "print(\"LoRA Model (Attn+FFN, LR=2e-5) Parameter Count:\")\n",
    "print_trainable_parameters(lora_model_lr2)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 07, LoRA, Seed 42) ---\n",
    "lora_lr2_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r16_ffn_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r16_ffn_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "lora_lr2_trainer = Trainer(\n",
    "    model=lora_model_lr2,\n",
    "    args=lora_lr2_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_lora_lr2 = time.time()\n",
    "lora_lr2_trainer.train()\n",
    "end_time_lora_lr2 = time.time()\n",
    "training_time_lora_lr2 = end_time_lora_lr2 - start_time_lora_lr2\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_lr2 = peak_vram_bytes_lora_lr2 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_lr2 = lora_lr2_trainer.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 07 (deberta-v3-base, LoRA, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (deberta-v3-base, LoRA, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_lr2:.4f}\")\n",
    "\n",
    "trainable_params_lora_lr2 = sum(p.numel() for p in lora_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb679bf-1597-4246-b7ec-7197c5a1aebc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, LoRA, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c2580d-6cc5-42de-86f6-b62254512da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA (Attn+FFN) adapters...\n",
      "--- Starting ExpID 07: deberta-v3-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 33:34, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.203600</td>\n",
       "      <td>0.179019</td>\n",
       "      <td>0.935084</td>\n",
       "      <td>0.935064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.173134</td>\n",
       "      <td>0.937191</td>\n",
       "      <td>0.937174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (LoRA, Seed 43) ---\n",
      "Accuracy: 0.9372\n",
      "F1-macro: 0.9372\n",
      "Training Time (s): 2015.68\n",
      "Peak VRAM (GB): 10.6750\n",
      "Trainable Params (M): 2.36\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (LoRA, LR=2e-5, Seed 43)...\")\n",
    "base_model_lora_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define LoRA Configuration (Same as ExpID 04) ---\n",
    "lora_config_lr2_s43 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], # DeBERTa Attn+FFN\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    ")\n",
    "\n",
    "# --- 3. Apply LoRA adapters ---\n",
    "print(\"Applying LoRA (Attn+FFN) adapters...\")\n",
    "lora_model_lr2_s43 = get_peft_model(base_model_lora_lr2_s43, lora_config_lr2_s43)\n",
    "\n",
    "# --- 4. Define Training Arguments (ExpID 07, LoRA, Seed 43) ---\n",
    "lora_lr2_s43_training_args = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_lora_r16_ffn_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_lora_r16_ffn_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 5. Initialize Trainer ---\n",
    "lora_lr2_s43_trainer = Trainer(\n",
    "    model=lora_model_lr2_s43,\n",
    "    args=lora_lr2_s43_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 6. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 7. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base LoRA r=16 Attn+FFN, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_lora_lr2_s43 = time.time()\n",
    "lora_lr2_s43_trainer.train()\n",
    "end_time_lora_lr2_s43 = time.time()\n",
    "training_time_lora_lr2_s43 = end_time_lora_lr2_s43 - start_time_lora_lr2_s43\n",
    "\n",
    "# --- 8. Get VRAM Usage ---\n",
    "peak_vram_bytes_lora_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_lora_lr2_s43 = peak_vram_bytes_lora_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 9. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_lora_lr2_s43 = lora_lr2_s43_trainer.evaluate()\n",
    "\n",
    "# --- 10. Report All Metrics for ExpID 07 (LoRA, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (LoRA, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_lora_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_lora_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_lora_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_lora_lr2_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_lora_lr2_s43 = sum(p.numel() for p in lora_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_lora_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f0359-c6db-4850-9ddd-1ca05446565f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, QLORA, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c928ef5a-f4fd-4fe4-90de-48173ff50de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PreTrainedModel.to monkey-patch applied.\n",
      "✅ DeBERTa _no_split_modules monkey-patch applied.\n",
      "🔹 Loading 4-bit quantized ENCODER for ExpID 07 (QLORA, LR=2e-5)...\n",
      "✅ Original PreTrainedModel.to restored.\n",
      "🔹 Preparing model for k-bit training...\n",
      "✅ Encoder loaded and custom float head placed on cuda\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model (LR=2e-5) Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 144,907,780 | Trainable %: 2.04\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 07: deberta-v3-base QLORA r=16, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 46:10, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.203511</td>\n",
       "      <td>0.928114</td>\n",
       "      <td>0.927993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>0.936786</td>\n",
       "      <td>0.936761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (deberta-v3-base, QLORA, Seed 42) ---\n",
      "Accuracy: 0.9368\n",
      "F1-macro: 0.9368\n",
      "Training Time (s): 2771.17\n",
      "Peak VRAM (GB): 7.8991\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,  # Using AutoModel\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. FIX: Temporary safe patch for .to() ---\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "_orig_pretrainedmodel_to = PreTrainedModel.to\n",
    "\n",
    "def _patched_to(self, *args, **kwargs):\n",
    "    try:\n",
    "        return _orig_pretrainedmodel_to(self, *args, **kwargs)\n",
    "    except ValueError as e:\n",
    "        msg = str(e)\n",
    "        if \"`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models\" in msg:\n",
    "            return self\n",
    "        raise\n",
    "\n",
    "PreTrainedModel.to = _patched_to\n",
    "print(\"✅ PreTrainedModel.to monkey-patch applied.\")\n",
    "\n",
    "try:\n",
    "    from transformers.models.deberta_v2.modeling_deberta_v2 import DebertaV2Model, DebertaV2PreTrainedModel\n",
    "    DebertaV2Model._no_split_modules = []\n",
    "    DebertaV2PreTrainedModel._no_split_modules = []\n",
    "    print(\"✅ DeBERTa _no_split_modules monkey-patch applied.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not monkey-patch DeBERTa classes: {e}\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 2. Define Quantization Config ---\n",
    "bnb_config_lr2 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 3. Load the 4-bit Quantized *Base Encoder* ---\n",
    "print(\"🔹 Loading 4-bit quantized ENCODER for ExpID 07 (QLORA, LR=2e-5)...\")\n",
    "encoder_lr2 = AutoModel.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    quantization_config=bnb_config_lr2,\n",
    "    device_map=\"auto\", \n",
    ")\n",
    "\n",
    "# --- 4. Immediately restore original .to() ---\n",
    "PreTrainedModel.to = _orig_pretrainedmodel_to\n",
    "print(\"✅ Original PreTrainedModel.to restored.\")\n",
    "\n",
    "# --- 5. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "encoder_lr2 = prepare_model_for_kbit_training(encoder_lr2)\n",
    "\n",
    "# --- 6. Custom Wrapper Class ---\n",
    "class DebertaSeqClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, encoder, hidden_size, num_labels, head_device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head_device = torch.device(head_device)\n",
    "        self.num_labels = num_labels\n",
    "        self.config = encoder.config\n",
    "        self.base_model = encoder\n",
    "        self.model = encoder\n",
    "\n",
    "        self.pooler = nn.Linear(hidden_size, hidden_size).to(device=self.head_device, dtype=torch.float32)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels).to(device=self.head_device, dtype=torch.float32)\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.encoder.get_input_embeddings()\n",
    "\n",
    "    def set_input_embeddings(self, new_emb):\n",
    "        return self.encoder.set_input_embeddings(new_emb)\n",
    "\n",
    "    def resize_token_embeddings(self, *args, **kwargs):\n",
    "        return self.encoder.resize_token_embeddings(*args, **kwargs)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        return_dict = kwargs.pop(\"return_dict\", True)\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs\n",
    "        )\n",
    "        pooled = encoder_outputs.last_hidden_state[:, 0]\n",
    "        pooled = pooled.to(self.head_device, dtype=torch.float32)\n",
    "        pooled = self.pooler(pooled)\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        outputs = {\"logits\": logits}\n",
    "        if labels is not None:\n",
    "            labels = labels.to(self.head_device)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs[\"loss\"] = loss\n",
    "        return outputs\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        if len(args) > 0 and args[0] is not None:\n",
    "            device = torch.device(args[0])\n",
    "        else:\n",
    "            device = kwargs.get(\"device\", self.head_device)\n",
    "        self.pooler = self.pooler.to(device=device, dtype=torch.float32)\n",
    "        self.classifier = self.classifier.to(device=device, dtype=torch.float32)\n",
    "        self.head_device = device\n",
    "        return self\n",
    "\n",
    "# --- 7. Instantiate Wrapper ---\n",
    "head_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = encoder_lr2.config.hidden_size\n",
    "num_labels = 2\n",
    "\n",
    "qlora_base_model_lr2 = DebertaSeqClassificationModel(encoder_lr2, hidden_size, num_labels, head_device)\n",
    "print(f\"✅ Encoder loaded and custom float head placed on {head_device}\")\n",
    "\n",
    "# --- 8. Define LoRA Configuration ---\n",
    "qlora_lora_config_lr2 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], \n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"pooler\", \"classifier\"], \n",
    ")\n",
    "\n",
    "# --- 9. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model_lr2 = get_peft_model(qlora_base_model_lr2, qlora_lora_config_lr2)\n",
    "\n",
    "# --- 10. Print Params ---\n",
    "print(\"QLORA Model (LR=2e-5) Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model_lr2)\n",
    "\n",
    "# --- 11. Optimizer Fallback ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice = \"adamw_torch\"\n",
    "\n",
    "# --- 12. Define Training Arguments (ExpID 07, QLORA, Seed 42) ---\n",
    "qlora_training_args_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_qlora_r16_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_qlora_r16_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    \n",
    "    optim=optim_choice, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, \n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 13. Initialize Trainer ---\n",
    "qlora_trainer_lr2 = Trainer(\n",
    "    model=qlora_model_lr2,\n",
    "    args=qlora_training_args_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 14. Train and Measure ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base QLORA r=16, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_qlora_lr2 = time.time()\n",
    "qlora_trainer_lr2.train()\n",
    "end_time_qlora_lr2 = time.time()\n",
    "training_time_qlora_lr2 = end_time_qlora_lr2 - start_time_qlora_lr2\n",
    "\n",
    "# --- 15. Results ---\n",
    "peak_vram_bytes_qlora_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_lr2 = peak_vram_bytes_qlora_lr2 / (1024**3)\n",
    "\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_lr2 = qlora_trainer_lr2.evaluate()\n",
    "\n",
    "print(\"\\n--- Results for ExpID 07 (deberta-v3-base, QLORA, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_lr2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e6ff9-9fe7-4a7d-8f5a-4671d556737d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, QLORA, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46ea555-195a-4b75-8a35-57c41146bb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PreTrainedModel.to monkey-patch applied.\n",
      "✅ DeBERTa _no_split_modules monkey-patch applied.\n",
      "🔹 Loading 4-bit quantized ENCODER for ExpID 07 (QLORA, LR=2e-5)...\n",
      "✅ Original PreTrainedModel.to restored.\n",
      "🔹 Preparing model for k-bit training...\n",
      "✅ Encoder loaded and custom float head placed on cuda\n",
      "🔹 Applying LoRA adapters to prepared model...\n",
      "QLORA Model (LR=2e-5) Parameter Count:\n",
      "Trainable Params: 2,951,426 | All Params: 144,907,780 | Trainable %: 2.04\n",
      "✅ Using paged_adamw_8bit optimizer.\n",
      "--- Starting ExpID 07: deberta-v3-base QLORA r=16, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 46:13, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.182104</td>\n",
       "      <td>0.935124</td>\n",
       "      <td>0.935121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.172081</td>\n",
       "      <td>0.937515</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAST\\anaconda3\\envs\\genai_A3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (deberta-v3-base, QLORA, Seed 43) ---\n",
      "Accuracy: 0.9375\n",
      "F1-macro: 0.9375\n",
      "Training Time (s): 2774.41\n",
      "Peak VRAM (GB): 8.1468\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,  # Using AutoModel\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. FIX: Temporary safe patch for .to() ---\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "_orig_pretrainedmodel_to = PreTrainedModel.to\n",
    "\n",
    "def _patched_to(self, *args, **kwargs):\n",
    "    try:\n",
    "        return _orig_pretrainedmodel_to(self, *args, **kwargs)\n",
    "    except ValueError as e:\n",
    "        msg = str(e)\n",
    "        if \"`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models\" in msg:\n",
    "            return self\n",
    "        raise\n",
    "\n",
    "PreTrainedModel.to = _patched_to\n",
    "print(\"✅ PreTrainedModel.to monkey-patch applied.\")\n",
    "\n",
    "try:\n",
    "    from transformers.models.deberta_v2.modeling_deberta_v2 import DebertaV2Model, DebertaV2PreTrainedModel\n",
    "    DebertaV2Model._no_split_modules = []\n",
    "    DebertaV2PreTrainedModel._no_split_modules = []\n",
    "    print(\"✅ DeBERTa _no_split_modules monkey-patch applied.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not monkey-patch DeBERTa classes: {e}\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 2. Define Quantization Config ---\n",
    "bnb_config_lr2 = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",       \n",
    "    bnb_4bit_compute_dtype=torch.float16, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    ")\n",
    "\n",
    "# --- 3. Load the 4-bit Quantized *Base Encoder* ---\n",
    "print(\"🔹 Loading 4-bit quantized ENCODER for ExpID 07 (QLORA, LR=2e-5)...\")\n",
    "encoder_lr2 = AutoModel.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    quantization_config=bnb_config_lr2,\n",
    "    device_map=\"auto\", \n",
    ")\n",
    "\n",
    "# --- 4. Immediately restore original .to() ---\n",
    "PreTrainedModel.to = _orig_pretrainedmodel_to\n",
    "print(\"✅ Original PreTrainedModel.to restored.\")\n",
    "\n",
    "# --- 5. Prepare for k-bit training ---\n",
    "print(\"🔹 Preparing model for k-bit training...\")\n",
    "encoder_lr2 = prepare_model_for_kbit_training(encoder_lr2)\n",
    "\n",
    "# --- 6. Custom Wrapper Class ---\n",
    "class DebertaSeqClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, encoder, hidden_size, num_labels, head_device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head_device = torch.device(head_device)\n",
    "        self.num_labels = num_labels\n",
    "        self.config = encoder.config\n",
    "        self.base_model = encoder\n",
    "        self.model = encoder\n",
    "\n",
    "        self.pooler = nn.Linear(hidden_size, hidden_size).to(device=self.head_device, dtype=torch.float32)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels).to(device=self.head_device, dtype=torch.float32)\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.encoder.get_input_embeddings()\n",
    "\n",
    "    def set_input_embeddings(self, new_emb):\n",
    "        return self.encoder.set_input_embeddings(new_emb)\n",
    "\n",
    "    def resize_token_embeddings(self, *args, **kwargs):\n",
    "        return self.encoder.resize_token_embeddings(*args, **kwargs)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        return_dict = kwargs.pop(\"return_dict\", True)\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs\n",
    "        )\n",
    "        pooled = encoder_outputs.last_hidden_state[:, 0]\n",
    "        pooled = pooled.to(self.head_device, dtype=torch.float32)\n",
    "        pooled = self.pooler(pooled)\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        outputs = {\"logits\": logits}\n",
    "        if labels is not None:\n",
    "            labels = labels.to(self.head_device)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs[\"loss\"] = loss\n",
    "        return outputs\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        if len(args) > 0 and args[0] is not None:\n",
    "            device = torch.device(args[0])\n",
    "        else:\n",
    "            device = kwargs.get(\"device\", self.head_device)\n",
    "        self.pooler = self.pooler.to(device=device, dtype=torch.float32)\n",
    "        self.classifier = self.classifier.to(device=device, dtype=torch.float32)\n",
    "        self.head_device = device\n",
    "        return self\n",
    "\n",
    "# --- 7. Instantiate Wrapper ---\n",
    "head_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = encoder_lr2.config.hidden_size\n",
    "num_labels = 2\n",
    "\n",
    "qlora_base_model_lr2 = DebertaSeqClassificationModel(encoder_lr2, hidden_size, num_labels, head_device)\n",
    "print(f\"✅ Encoder loaded and custom float head placed on {head_device}\")\n",
    "\n",
    "# --- 8. Define LoRA Configuration ---\n",
    "qlora_lora_config_lr2 = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"query_proj\", \n",
    "        \"value_proj\", \n",
    "        \"intermediate.dense\", \n",
    "        \"output.dense\"\n",
    "    ], \n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    modules_to_save=[\"pooler\", \"classifier\"], \n",
    ")\n",
    "\n",
    "# --- 9. Apply LoRA adapters ---\n",
    "print(\"🔹 Applying LoRA adapters to prepared model...\")\n",
    "qlora_model_lr2 = get_peft_model(qlora_base_model_lr2, qlora_lora_config_lr2)\n",
    "\n",
    "# --- 10. Print Params ---\n",
    "print(\"QLORA Model (LR=2e-5) Parameter Count:\")\n",
    "print_trainable_parameters(qlora_model_lr2)\n",
    "\n",
    "# --- 11. Optimizer Fallback ---\n",
    "try:\n",
    "    from bitsandbytes.optim import PagedAdamW8bit\n",
    "    optim_choice = \"paged_adamw_8bit\"\n",
    "    print(\"✅ Using paged_adamw_8bit optimizer.\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytes optimizer not usable, falling back to adamw_torch.\")\n",
    "    optim_choice = \"adamw_torch\"\n",
    "\n",
    "# --- 12. Define Training Arguments (ExpID 07, QLORA, Seed 43) ---\n",
    "qlora_training_args_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_qlora_r16_lr2_seed_43\", # <-- Changed to seed_43\n",
    "    logging_dir=\"./logs/deberta_qlora_r16_lr2_seed_43\",   # <-- Changed to seed_43\n",
    "    \n",
    "    learning_rate=2e-5,                          \n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                          # <-- Changed seed to 43\n",
    "    \n",
    "    optim=optim_choice, \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False, \n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 13. Initialize Trainer ---\n",
    "qlora_trainer_lr2 = Trainer(\n",
    "    model=qlora_model_lr2,\n",
    "    args=qlora_training_args_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 14. Train and Measure ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base QLORA r=16, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_qlora_lr2 = time.time()\n",
    "qlora_trainer_lr2.train()\n",
    "end_time_qlora_lr2 = time.time()\n",
    "training_time_qlora_lr2 = end_time_qlora_lr2 - start_time_qlora_lr2\n",
    "\n",
    "# --- 15. Results ---\n",
    "peak_vram_bytes_qlora_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_qlora_lr2 = peak_vram_bytes_qlora_lr2 / (1024**3)\n",
    "\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_qlora_lr2 = qlora_trainer_lr2.evaluate()\n",
    "\n",
    "print(\"\\n--- Results for ExpID 07 (deberta-v3-base, QLORA, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_qlora_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_qlora_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_qlora_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_qlora_lr2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218756ea-b364-47e1-8e58-2617a767b09e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, IA³, Seed 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7d755aa-8b21-4ad4-a18e-6b617b94c426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable Params: 56,834 | All Params: 184,480,516 | Trainable %: 0.03\n",
      "--- Starting ExpID 07: deberta-v3-base IA³ Attn+FFN, LR=2e-5 (Seed 42) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 28:25, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.692491</td>\n",
       "      <td>0.547330</td>\n",
       "      <td>0.469565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.692116</td>\n",
       "      <td>0.591215</td>\n",
       "      <td>0.588199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (deberta-v3-base, IA³, Seed 42) ---\n",
      "Accuracy: 0.5912\n",
      "F1-macro: 0.5882\n",
      "Training Time (s): 1706.20\n",
      "Peak VRAM (GB): 11.4881\n",
      "Trainable Params (M): 0.06\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter # For device map printing\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 42)...\")\n",
    "base_model_ia3_lr2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (Same as ExpID 06 for DeBERTa) ---\n",
    "# IA3 must target 'value_proj' and 'output.dense' (FFN)\n",
    "ia3_config_lr2 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"value_proj\", \"output.dense\"],  # DeBERTa layer names\n",
    "    feedforward_modules=[\"output.dense\"],   # DeBERTa FFN layer\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_lr2 = get_peft_model(base_model_ia3_lr2, ia3_config_lr2)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model_lr2) # This should be 0.06M\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 07, IA³, Seed 42) ---\n",
    "ia3_training_args_lr2 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_ia3_ffn_lr2_seed_42\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_ia3_ffn_lr2_seed_42\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- CHANGED\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer_lr2 = Trainer(\n",
    "    model=ia3_model_lr2,\n",
    "    args=ia3_training_args_lr2,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base IA³ Attn+FFN, LR=2e-5 (Seed 42) ---\")\n",
    "\n",
    "start_time_ia3_lr2 = time.time()\n",
    "ia3_trainer_lr2.train()\n",
    "end_time_ia3_lr2 = time.time()\n",
    "training_time_ia3_lr2 = end_time_ia3_lr2 - start_time_ia3_lr2\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_lr2 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_lr2 = peak_vram_bytes_ia3_lr2 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_lr2 = ia3_trainer_lr2.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 07 (deberta-v3-base, IA³, Seed 42) ---\n",
    "print(\"\\n--- Results for ExpID 07 (deberta-v3-base, IA³, Seed 42) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_lr2['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_lr2['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_lr2:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_lr2:.4f}\")\n",
    "\n",
    "trainable_params_ia3_lr2 = sum(p.numel() for p in ia3_model_lr2.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_lr2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1200d077-4f5e-4aa4-b3b7-e1e198b3e2fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization Sensitivity (ExpID 07, IA³, Seed 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7da2382e-6097-4b2d-8ca9-08481eecd5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying IA³ adapters...\n",
      "IA³ Model Parameter Count:\n",
      "Trainable Params: 56,834 | All Params: 184,480,516 | Trainable %: 0.03\n",
      "--- Starting ExpID 07: deberta-v3-base IA³ Attn+FFN, LR=2e-5 (Seed 43) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 28:24, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.692408</td>\n",
       "      <td>0.622295</td>\n",
       "      <td>0.619770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.692116</td>\n",
       "      <td>0.577599</td>\n",
       "      <td>0.534488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3085' max='3085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3085/3085 04:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for ExpID 07 (deberta-v3-base, IA³, Seed 43) ---\n",
      "Accuracy: 0.6223\n",
      "F1-macro: 0.6198\n",
      "Training Time (s): 1704.87\n",
      "Peak VRAM (GB): 12.1847\n",
      "Trainable Params (M): 0.06\n"
     ]
    }
   ],
   "source": [
    "# --- All Libraries Used So Far ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    IA3Config,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from collections import Counter # For device map printing\n",
    "\n",
    "# --- Check for external variables ---\n",
    "assert 'model_checkpoint' in locals() and model_checkpoint == \"microsoft/deberta-v3-base\", \"model_checkpoint is not set to 'microsoft/deberta-v3-base'. Please run the preprocessing cell first.\"\n",
    "assert 'tokenized_dataset' in locals(), \"tokenized_dataset is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'compute_metrics' in locals(), \"compute_metrics is not defined. Please run the preprocessing cell first.\"\n",
    "assert 'tokenizer' in locals(), \"tokenizer is not defined. Please run the preprocessing cell first.\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"Trainable Params: {trainable_params:,} | \"\n",
    "        f\"All Params: {all_param:,} | \"\n",
    "        f\"Trainable %: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# --- 1. Load a FRESH Base Model ---\n",
    "print(f\"Reloading base model for ExpID 07 (IA³, LR=2e-5, Seed 43)...\")\n",
    "base_model_ia3_lr2_s43 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# --- 2. Define IA³ Configuration (Same as ExpID 06 for DeBERTa) ---\n",
    "ia3_config_lr2_s43 = IA3Config(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"value_proj\", \"output.dense\"],  # DeBERTa layer names\n",
    "    feedforward_modules=[\"output.dense\"],   # DeBERTa FFN layer\n",
    ")\n",
    "\n",
    "# --- 3. Apply IA³ adapters ---\n",
    "print(\"Applying IA³ adapters...\")\n",
    "ia3_model_lr2_s43 = get_peft_model(base_model_ia3_lr2_s43, ia3_config_lr2_s43)\n",
    "\n",
    "# --- 4. Calculate and Print Trainable Parameters ---\n",
    "print(\"IA³ Model Parameter Count:\")\n",
    "print_trainable_parameters(ia3_model_lr2_s43)\n",
    "\n",
    "# --- 5. Define Training Arguments (ExpID 07, IA³, Seed 43) ---\n",
    "ia3_training_args_lr2_s43 = TrainingArguments(\n",
    "    output_dir=\"./results/deberta_ia3_ffn_lr2_seed_43\", # <-- Changed\n",
    "    logging_dir=\"./logs/deberta_ia3_ffn_lr2_seed_43\",   # <-- Changed\n",
    "    \n",
    "    # --- From Design Matrix ---\n",
    "    learning_rate=2e-5,                          # <-- LR=2e-5\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=43,                                     # <-- CHANGED\n",
    "    # --------------------------\n",
    "    \n",
    "    optim=\"adamw_torch\", # Use standard optimizer\n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, \n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",                 \n",
    ")\n",
    "\n",
    "# --- 6. Initialize Trainer ---\n",
    "ia3_trainer_lr2_s43 = Trainer(\n",
    "    model=ia3_model_lr2_s43,\n",
    "    args=ia3_training_args_lr2_s43,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "# --- 7. Prepare for Metrics Measurement ---\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# --- 8. Start Training & Measure Time ---\n",
    "print(f\"--- Starting ExpID 07: deberta-v3-base IA³ Attn+FFN, LR=2e-5 (Seed 43) ---\")\n",
    "\n",
    "start_time_ia3_lr2_s43 = time.time()\n",
    "ia3_trainer_lr2_s43.train()\n",
    "end_time_ia3_lr2_s43 = time.time()\n",
    "training_time_ia3_lr2_s43 = end_time_ia3_lr2_s43 - start_time_ia3_lr2_s43\n",
    "\n",
    "# --- 9. Get VRAM Usage ---\n",
    "peak_vram_bytes_ia3_lr2_s43 = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
    "peak_vram_gb_ia3_lr2_s43 = peak_vram_bytes_ia3_lr2_s43 / (1024**3)\n",
    "\n",
    "# --- 10. Evaluate Model ---\n",
    "print(\"\\n--- Evaluating Test Set ---\")\n",
    "eval_results_ia3_lr2_s43 = ia3_trainer_lr2_s43.evaluate()\n",
    "\n",
    "# --- 11. Report All Metrics for ExpID 07 (deberta-v3-base, IA³, Seed 43) ---\n",
    "print(\"\\n--- Results for ExpID 07 (deberta-v3-base, IA³, Seed 43) ---\")\n",
    "print(f\"Accuracy: {eval_results_ia3_lr2_s43['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-macro: {eval_results_ia3_lr2_s43['eval_f1_macro']:.4f}\")\n",
    "print(f\"Training Time (s): {training_time_ia3_lr2_s43:.2f}\")\n",
    "print(f\"Peak VRAM (GB): {peak_vram_gb_ia3_lr2_s43:.4f}\")\n",
    "\n",
    "# Get the trainable param count again\n",
    "trainable_params_ia3_lr2_s43 = sum(p.numel() for p in ia3_model_lr2_s43.parameters() if p.requires_grad)\n",
    "print(f\"Trainable Params (M): {trainable_params_ia3_lr2_s43 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cda692-8a65-4c4c-8312-7b241dc1fd9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc31432-b29b-4d5f-a64e-41060b4ae021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. AGGREGATED EXPERIMENTAL DATA (Mean over Seeds 42, 43)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Data compiled from your successful runs (ExpID 01 through ExpID 07)\n",
    "DATA = [\n",
    "    # Model: DistilBert (DB)\n",
    "    {'Model': 'DB (67M)', 'Method': 'Full FT', 'ExpID': '01', 'Rank': 0, 'FFN': 0, 'LR': 1e-5, 'Params_M': 66.96, 'Accuracy': 0.9092, 'VRAM_GB': 2.03, 'Time_s': 729.52},\n",
    "    {'Model': 'DB (67M)', 'Method': 'LoRA', 'ExpID': '02', 'Rank': 8, 'FFN': 0, 'LR': 1e-5, 'Params_M': 0.74, 'Accuracy': 0.8574, 'VRAM_GB': 2.41, 'Time_s': 600.70},\n",
    "    {'Model': 'DB (67M)', 'Method': 'LoRA', 'ExpID': '03', 'Rank': 16, 'FFN': 0, 'LR': 1e-5, 'Params_M': 0.89, 'Accuracy': 0.8581, 'VRAM_GB': 2.94, 'Time_s': 598.52},\n",
    "    {'Model': 'DB (67M)', 'Method': 'LoRA', 'ExpID': '04', 'Rank': 16, 'FFN': 1, 'LR': 1e-5, 'Params_M': 1.62, 'Accuracy': 0.8707, 'VRAM_GB': 3.70, 'Time_s': 690.31},\n",
    "    {'Model': 'DB (67M)', 'Method': 'QLoRA', 'ExpID': '05', 'Rank': 16, 'FFN': 1, 'LR': 1e-5, 'Params_M': 2.95, 'Accuracy': 0.8714, 'VRAM_GB': 1.52, 'Time_s': 993.42},\n",
    "    {'Model': 'DB (67M)', 'Method': 'IA3', 'ExpID': '06', 'Rank': 0, 'FFN': 1, 'LR': 1e-5, 'Params_M': 0.06, 'Accuracy': 0.8145, 'VRAM_GB': 1.53, 'Time_s': 598.33},\n",
    "    {'Model': 'DB (67M)', 'Method': 'LoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'FFN': 1, 'LR': 2e-5, 'Params_M': 1.62, 'Accuracy': 0.8838, 'VRAM_GB': 3.65, 'Time_s': 703.97},\n",
    "    {'Model': 'DB (67M)', 'Method': 'QLoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'FFN': 1, 'LR': 2e-5, 'Params_M': 2.95, 'Accuracy': 0.8826, 'VRAM_GB': 1.11, 'Time_s': 989.00},\n",
    "\n",
    "    # Model: RoBERTa-Base (RB)\n",
    "    {'Model': 'RB (125M)', 'Method': 'Full FT', 'ExpID': '01', 'Rank': 0, 'FFN': 0, 'LR': 1e-5, 'Params_M': 124.65, 'Accuracy': 0.9390, 'VRAM_GB': 3.81, 'Time_s': 1461.87},\n",
    "    {'Model': 'RB (125M)', 'Method': 'LoRA', 'ExpID': '02', 'Rank': 8, 'FFN': 0, 'LR': 1e-5, 'Params_M': 0.89, 'Accuracy': 0.9133, 'VRAM_GB': 4.51, 'Time_s': 1157.44},\n",
    "    {'Model': 'RB (125M)', 'Method': 'LoRA', 'ExpID': '03', 'Rank': 16, 'FFN': 0, 'LR': 1e-5, 'Params_M': 1.18, 'Accuracy': 0.9143, 'VRAM_GB': 5.47, 'Time_s': 1157.08},\n",
    "    {'Model': 'RB (125M)', 'Method': 'LoRA', 'ExpID': '04', 'Rank': 16, 'FFN': 1, 'LR': 1e-5, 'Params_M': 2.95, 'Accuracy': 0.9236, 'VRAM_GB': 7.01, 'Time_s': 1374.66},\n",
    "    {'Model': 'RB (125M)', 'Method': 'QLoRA', 'ExpID': '05', 'Rank': 16, 'FFN': 1, 'LR': 1e-5, 'Params_M': 2.95, 'Accuracy': 0.9102, 'VRAM_GB': 0.59, 'Time_s': 1949.58},\n",
    "    {'Model': 'RB (125M)', 'Method': 'IA3', 'ExpID': '06', 'Rank': 0, 'FFN': 1, 'LR': 1e-5, 'Params_M': 0.65, 'Accuracy': 0.8220, 'VRAM_GB': 2.35, 'Time_s': 1151.56},\n",
    "    {'Model': 'RB (125M)', 'Method': 'LoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'FFN': 1, 'LR': 2e-5, 'Params_M': 2.95, 'Accuracy': 0.9318, 'VRAM_GB': 2.85, 'Time_s': 1382.74},\n",
    "    {'Model': 'RB (125M)', 'Method': 'QLoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'FFN': 1, 'LR': 2e-5, 'Params_M': 2.95, 'Accuracy': 0.9214, 'VRAM_GB': 1.11, 'Time_s': 1986.31},\n",
    "    \n",
    "    # Model: DeBERTa-v3-Base (DBV3)\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'Full FT', 'ExpID': '01', 'Rank': 0, 'FFN': 0, 'LR': 1e-5, 'Params_M': 184.42, 'Accuracy': 0.9495, 'VRAM_GB': 7.19, 'Time_s': 2145.39},\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'LoRA', 'ExpID': '02', 'Rank': 8, 'FFN': 0, 'LR': 1e-5, 'Params_M': 0.30, 'Accuracy': 0.9133, 'VRAM_GB': 8.34, 'Time_s': 1760.30},\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'LoRA', 'ExpID': '03', 'Rank': 16, 'FFN': 0, 'LR': 1e-5, 'Params_M': 0.59, 'Accuracy': 0.9093, 'VRAM_GB': 6.45, 'Time_s': 1818.41},\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'LoRA', 'ExpID': '04', 'Rank': 16, 'FFN': 1, 'LR': 1e-5, 'Params_M': 2.36, 'Accuracy': 0.9323, 'VRAM_GB': 6.16, 'Time_s': 2066.22},\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'QLoRA', 'ExpID': '05', 'Rank': 16, 'FFN': 1, 'LR': 1e-5, 'Params_M': 2.95, 'Accuracy': 0.9315, 'VRAM_GB': 1.52, 'Time_s': 2848.29},\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'IA3', 'ExpID': '06', 'Rank': 0, 'FFN': 1, 'LR': 1e-5, 'Params_M': 0.06, 'Accuracy': 0.5504, 'VRAM_GB': 4.15, 'Time_s': 1698.50},\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'LoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'FFN': 1, 'LR': 2e-5, 'Params_M': 2.36, 'Accuracy': 0.9368, 'VRAM_GB': 10.31, 'Time_s': 2017.00},\n",
    "    {'Model': 'DBV3 (184M)', 'Method': 'QLoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'FFN': 1, 'LR': 2e-5, 'Params_M': 2.95, 'Accuracy': 0.9372, 'VRAM_GB': 8.02, 'Time_s': 2772.79},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(DATA)\n",
    "\n",
    "# Assign a categorical hue for simpler plotting in Pareto analysis\n",
    "df['Category'] = df['Model'] + ' - ' + df['Method'].apply(lambda x: x.split(' ')[0])\n",
    "df['Category'] = df['Category'].replace({\n",
    "    'DB (67M) - LoRA (Opt)': 'DB (67M) - LoRA',\n",
    "    'RB (125M) - LoRA (Opt)': 'RB (125M) - LoRA',\n",
    "    'DBV3 (184M) - LoRA (Opt)': 'DBV3 (184M) - LoRA',\n",
    "    'DB (67M) - QLoRA (Opt)': 'DB (67M) - QLoRA',\n",
    "    'RB (125M) - QLoRA (Opt)': 'RB (125M) - QLoRA',\n",
    "    'DBV3 (184M) - QLoRA (Opt)': 'DBV3 (184M) - QLoRA',\n",
    "})\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. PLOT 1: LoRA Rank Sensitivity (Line Plot)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Filter data to only include ExpID 02 and 03 (LoRA r=8 and r=16, Attn-only)\n",
    "df_rank = df[df['ExpID'].isin(['02', '03'])]\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.lineplot(data=df_rank, x='Rank', y='Accuracy', hue='Model', \n",
    "             marker='o', markersize=8, linewidth=2, linestyle='--')\n",
    "\n",
    "plt.title(r'LoRA Rank Sensitivity: Accuracy vs. Rank ($r$) (Attn-Only, $LR=1e^{-5}$)', fontsize=14)\n",
    "plt.xlabel(r'LoRA Rank ($r$)', fontsize=12)\n",
    "plt.ylabel(r'Test Accuracy ($\\mu$) $\\uparrow$', fontsize=12)\n",
    "plt.xticks([8, 16], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', alpha=0.5, linestyle='--')\n",
    "plt.legend(title='Model', loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rank_sensitivity_plot.png')\n",
    "plt.show() # Show plot in notebook\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. PLOT 2: Pareto Frontier - VRAM vs. Accuracy (Scatter Plot)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Filter IA3 (Exp 06) off for clarity on the main performance scale\n",
    "df_pareto = df[~df['ExpID'].isin(['06'])] \n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_pareto,\n",
    "    x='VRAM_GB',\n",
    "    y='Accuracy',\n",
    "    hue='Category',\n",
    "    style='Method',\n",
    "    size='Params_M',\n",
    "    sizes=(50, 400),\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "# Highlight QLoRA points with a specific shape/color pattern (QLoRA is the VRAM winner)\n",
    "qlora_df = df_pareto[df_pareto['Method'].str.contains('QLoRA')]\n",
    "plt.scatter(qlora_df['VRAM_GB'], qlora_df['Accuracy'], \n",
    "            facecolors='none', edgecolors='black', s=200, marker='D', linewidths=1.5, label='QLoRA Frontier')\n",
    "\n",
    "\n",
    "plt.title('Pareto Frontier: Peak VRAM Usage vs. Test Accuracy (All Methods)', fontsize=14)\n",
    "plt.xlabel(r'Peak VRAM Usage (GB) $\\downarrow$ (Lower is Better)', fontsize=12)\n",
    "plt.ylabel(r'Test Accuracy ($\\mu$) $\\uparrow$ (Higher is Better)', fontsize=12)\n",
    "plt.ylim(0.85, 0.96) \n",
    "plt.legend(title='Configuration (Size of Marker = Trainable Params)', loc='center left', bbox_to_anchor=(1, 0.5), fontsize=9)\n",
    "plt.grid(axis='both', alpha=0.5, linestyle=':')\n",
    "\n",
    "plt.tight_layout(rect=(0, 0, 0.9, 1)) \n",
    "plt.savefig('pareto_vram_accuracy.png')\n",
    "plt.show() # Show plot in notebook\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. PLOT 3: Pareto Frontier - Training Time vs. Accuracy (Scatter Plot)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_pareto,\n",
    "    x='Time_s',\n",
    "    y='Accuracy',\n",
    "    hue='Category',\n",
    "    style='Method',\n",
    "    size='Params_M',\n",
    "    sizes=(50, 400),\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "# Highlight Full FT points (They are the Speed winner among high-acc methods)\n",
    "full_ft_df = df_pareto[df_pareto['Method'].str.contains('Full FT')]\n",
    "plt.scatter(full_ft_df['Time_s'], full_ft_df['Accuracy'], \n",
    "            facecolors='none', edgecolors='red', s=200, marker='s', linewidths=1.5, label='Full FT Frontier')\n",
    "\n",
    "\n",
    "plt.title('Pareto Frontier: Training Time vs. Test Accuracy (All Methods)', fontsize=14)\n",
    "plt.xlabel(r'Training Time (s) $\\downarrow$ (Lower is Better)', fontsize=12)\n",
    "plt.ylabel(r'Test Accuracy ($\\mu$) $\\uparrow$ (Higher is Better)', fontsize=12)\n",
    "plt.ylim(0.85, 0.96) \n",
    "plt.xlim(500, 3000) \n",
    "plt.legend(title='Configuration (Size of Marker = Trainable Params)', loc='center left', bbox_to_anchor=(1, 0.5), fontsize=9)\n",
    "plt.grid(axis='both', alpha=0.5, linestyle=':')\n",
    "\n",
    "plt.tight_layout(rect=(0, 0, 0.9, 1))\n",
    "plt.savefig('pareto_time_accuracy.png')\n",
    "plt.show() # Show plot in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "576f4c33-3867-4de4-bddb-42f9dda84cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Generating Dataset Visualizations...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Data loaded. Generating Experiment Plots...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKAAAAJLCAYAAADQCu7HAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhbBJREFUeJzt3QmcjfX///+Xfd/3KIlPqJBsyRIqZSlLKtmyZKlQaaOQUihUlpRClkILiVAS7UVUUqGylV32fZv5357v7/+a35nVzJjrnDkzj/vtdm5mrnPNud7nzJnLXM95vV/vDJGRkZEGAAAAAAAA+CSjXw8MAAAAAAAACAEUAAAAAAAAfEUABQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwFQEUAAAAAAAAfEUABQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwVWZ/Hx4AUk7jxo1t69at1r17d3v00UdDPZywdvjwYZszZ4598skn7jU9evSoFStWzOrUqeNe34svvtjSi44dO9rKlSvt999/t8yZw+u/xf79+9uHH36Y4D4VKlSwjz76KEmPu23bNrvhhhvs1ltvtVGjRiXpdUrKmLzHTIzhw4db69atLTWZO3euDRgwINZ2vT558+a1K664wj3HBg0anPdrYtLrP2HCBPfxihUrrFOnTuf9mnnz5tm6desS9fhSs2ZNmzFjRpz3BY6zc+fOCT6m933UOeSrr76y5NqyZYtdeuml8b4H/XT27Fm78sorE3xNAADAhQmv37QBpFu6uFFQkjNnTndh1LdvX8uaNWuohxWWfvnlF3vooYdsz549dsstt7hbtmzZ7I8//nDBwYIFC+zNN9+06tWrW3rQq1cva9OmjWXKlMnC+Tlcdtllcd6XP39+S61j8l57z4EDB1zQpK/TfYGuueYaS61uuukmd/NERETY3r17bfbs2dazZ0977rnn7I477kjwa2IqUaJErG36mbzzzjvj/ZqLLrrIcufObS+++GK07a+//rpt2rTJhUgFChSI2l64cOFEPb9PP/3UBYsZMmSIdd/u3btt1apVdqGBeI8ePVz4NGLEiAt6LAAAkHoRQAEIC6rWUUDQrVs3GzdunH322WfWrFmzUA8r7OzatctdEOu1VJCnSpRA7dq1sw4dOrgqqKVLl1qhQoUsrVPVV7i77rrrrFatWhZuY4r52qvqRQGUgpEWLVpYuChfvnyc49W2m2++2VXw6OPA0Dy+r0mIKhPP9zX58uWLVcH4wQcfuADqxhtvtFKlSiXpmKVLl3bh/5o1a+zqq6+Odb+qKHU+yZMnjyWXgseff/45qvoJAACkTfSAApDqaXqY/gJfqVKlqIsvVRYg6UaOHGkHDx50FRkxwyfRlCFVIhw/ftzef//9kIwRSCs0Je3aa691P3N///23hSNVSHpBU1wWLVrkgkRVXgEAACSEAApAqqcLnBMnTriLHP1lv3Llym5K3saNG2Pt+88//7ipIvXq1bMqVapYkyZN3PST06dPR9vv+++/t3vvvddVaFSrVs1Na9FxPOq5ogqFl19+OdYx7r77bnefR5VE+nz+/PluOtFVV13lqh40ZlF41rVrV3cs9RjRv5pe9Ntvv8V67ITGpVCoatWq1rRp0zhfJ/VKadiwoZv+E1+Qp6omVUA0atQo3tdbFVDaL+YUqC+//NLuueceNxVK3wOFgdOnT492PFWw6LWYNGmS66Oi10HBofp3eaHhrFmz3EWtvj96LupbE0hjU8+Z7777zvX80bH0vDStyHtNPfq+6li33367e2302qvfzsCBA23fvn2xvp8ak74X2q9+/fq2c+dO179G96kHjEevedu2bV0/GFV96LlOmTIl1murijIdS4/lPaY+1/ZAOoae84YNG1zAp++txqvnqcqSQN77Se/jlKbH1fs3Jr3PdZ9ep3DTsmVL91rGfG+IpurqZ+6///6L+vnSe7h27drufanzwyuvvGInT570bXwZM/7fr1qB769wonOu3ts6j8W0fft2N6U3vmpU/bzoZ04/P/o51hRCnd9Wr14d7f2u84NoCnBc70OF4Tq/aRx169Z1AfqxY8ei7XPu3Llox9J5Sn2zdN6Kaf/+/TZ48GD3WDoP6edTU5Bj0mOOHz/eHVvnAY1f+y5btiwJryAAAPAQQAEIi+l34gUv3sWOgoxAf/75p7Vq1cpdKDVv3tz1O1FFjy6uH3/88aj9dJHTpUsXNyVFF6P9+vVzvU0efvhhmzlzZrLH+fTTT7veNQog1O8lR44cNnXqVHcRrIvP3r1726BBg1zfl2+++cZdHOlCKLHjUv8rXTAreIsZXqkxtPf8vQvemBR+6EJb4UdCVMkQcwqPwhcFJwpsND1PY9OUm+eff9769OkTK5h5++23XR8pBUOPPfaYC4r0+ijUmjhxoguWHnnkERcaKGjRRWwgPUcdT6/nE0884S4oJ0+e7F4fXRR6HnzwQTe9yQts9H0uV66cu2C9//77Yz23l156yTWI1vdBY4irz86SJUvc88uVK5frlaXjq2fRCy+8YKNHj442RoUfCtA0tempp55y4Zk+1/dh8+bN0R5X32uFe3rd9Jq0b9/e9c5RCHXo0KGo/WrUqOHCtrvuussS68iRI+7xY960PVSCNSa9xxTOKjQNpNd0+fLlLhTUlD69x/Te1Xvuvvvucz+n//vf/+y1117zJezzQl9NLdO5QMcKpHHE9fp4t8D3uUc/R/HtH1/wnBJ07t2xY0esn1MFtdmzZ3fNwuOin3GFRZrGp58jhb9qNK4Qx6uo0vtd94kCHr33y5YtG/UYn3/+ufu5VUiln7HLL7/cBU362KPnrvOrjqUpiDqugi6NWeeRt956K9r3ROGypiXq51bnDP186+cwJk0HffXVV12YpePpfaOeVzq3xBVsAQCAhNEDCkCqpot8XfTookPBgiiEURigVbR0oaGLO1EYcurUKXdh4U0v04WG+q7or+wKPy655BIbOnSouyBSsOVNG1FgpDBBf+1OqMlvQlRpEdj8VxeQqr6qWLGiuwAKbHKtFbIUqKiSS5UxuoBOzLhUYaX7FXKoGiAwvFJYpeAjPmo6LkWLFk3S8/r3339d8KKLQr22CsJEIZlWI/z444/d9yLw2Ko+0sWpF2Qp6NEFoiobdOGpqUmi+/V9+eKLL6L1l9FYFf7ogk8U1gwbNsymTZvmvpd6XdavX+8qERTqKFDyKNjT/Xrf6MK8YMGCUffpYwUOCTUc1+ur95QCNC/M02uv5xtYdffss8+63jUKGVVR41EIpaBDFRaBq2kpEFGYGFhZpot39TRTaOq97/SaJHUVwgceeCDO7aFc0StYY1J1in7u9B7Ux56FCxe6wEYBlahC8cyZM+777/U2U8inEFMVa9o3uQsbeGGSR8dRAKlV7LRdr4V3nvLo51+3+OhnXOeOQHpOusVFQU1S+zslls65mr6rn93An9PFixe7ikOFtTHp5183ha0Kgzz6OdJ5bMiQIXb99de797oCLJ3TA3tcqZpSFN7rjw1efyj9bOucqcBR53stoKDvrc4FOleqibnXLF3nAn3/NXYdQ+d/henqaaXjaX/v/KLPdV/Mc4GqpJ555ploYZwed+3atW78AAAg8QigAKRqCjxEFU0ehRf6S7nCG12M6WJGQYA+1wVBzN5GCkn01+0yZcq4v1pr6obCkMCeJbrw1IWpJHc1NPV6CaTH0ZLkujgNfEyFTVmyZIn6a7x8++23iRqX/hKvqiBd2KlqQ9U8uthVCKRKgoSCC+0rcVVWJEQN33URqFDFC5/Eq87SsTWewABK01oCx+Kthqbxe+GTKHATVRUEUpWQGs4HUvN0BVCqUNJFqL7PmsoTs+JL4ZfXEFmvaWAApfDjfN/f4sWLu++RAk1VSamKTl+jqi6PQgWFaXq8wPBJVHGj7Xo/aiyBjdxvu+22aPt6IaJWTLsQqiCJq6eXgs5QCdaYVL2iShaFeHodixQp4rYrkFLlkwIS7/sqqpJRaKkgRd/XMWPGXPAY4guTVI2jCsG4qvEUtHgBSFwUlsSkMCTmz4XHe95+0Op6+pn2VsMTVTKp8jLmVF2PF5RpGm5gOCeqZlI4/+OPP7qfl4To+xTYnFznMf3cKBjX4yrc9qqpVG0auFKfzqU6b6gaVmP3FlfQeybmz6LuixlA6T2jMSpk9hq463g6JwIAgKQjgAKQain00F+2RRc/3l/ERT2SdIGvvkIKoNSLRNMwFDLFpADACwF00SJxLQ/vhSHJFdeS5gqQFJKoUkAVERqnprFFRka6+71/kzIu7y/6X3/9teuNpFBNAZxX6REfL/hJatihvlriVaAF0gWZQqnA701cr4UXfsXc7oVB3usQ+JxjVqPoe6gLem88on0UfinAU1WDxqHQx7sIjTktKTHLziswWLdunQucdFOApXBRF6C6mNZz0XE05pjTqjzarven9gsMoGIe33uOFzp9yustlpoEc0w6B+h9oNBDYbN+1lQBpylf3ntP0770s+hV5iikVGirijUF3DErlJIiZpik72uBAgVccBJf4KmAVisFJoVCpqR+TUpWQWlKmnqW6Xys11ABT3xVQN4UVP3cxEfnw/OJK1hT5aB4vf10TtB5qGTJkrH29X5GvXOUzrU6z8YMrvVzHhhWi0JoVWLqeeumUFC9CDUNXO8dAACQNARQAFItTcvymgdr2kZcNA1Cf4X3GvwG/vU7LondLyHxVRDFdaGpKYKqEFJ4o7/k62JXVSG6OAuc1pGUcelCV32tVOGhAEpTdTQFRuFIQnRcXTAGNgCOi8IsVQOockQVWTHDoZgUnsQMi7yL/pgS+7rHNxVKr71XPaYpbe3atXPT4lQRpz5RqsJSc2lVSnnhZaD4+mMFUkj03nvvufeWwr0ffvjBVTzoglvfQ4VS53tNvPdIzOeRmOOHQlKr4lIbVaGpSkc/EwqgvMb2CqY8CpjUf0yr0ak3lL6vakquqVuabqnvuSpjkiM5YVK4UQCl6W2qNlIApVBd4ZKmwMV3XtBrrmmI8YnrDwYxJeZnJqGfRy/cDfxZjLkoRcx9ParYVMWU3isK/FX1qD96aEqg+tH51TsMAIC0igAKQKpvPq7+IVrlKib1AlLfE10QqI+LxGz8LH/99Ze7CNLFqNcjRfvF/Mu9qid0kaEKGC9MiutCxQvFzkcNphU+6cJNgVFg+BKzmW9ix6W/8Csg0bQVhSOagqJpfup9c74KDl2AaeqL97rF1zhY/aQUvmjqWeBUIF24K9wJpGoCNTaPq5n3hVBFgy4GAy8+NU1PUxa9i9Z33nnHjUm9ltTDJTnfo7guZPV+0XNSoKXnqxBOx1UvG4UVaiCvC3DRvnHRuPT9DpxumBrofX0h7+nUSu8ThY9qGK2foQULFriwMLCZtbarOk5hpQJhhazqIaTeYjqH6GdVU/MQN72XFchoKpteay16oOnN8dE5Ta+5KpBiVjGpwlB93i6k6iyQzlFavEEVVTGroLyfUQWUXnWlqiVj9vxSoH3w4MGoz/Xe0MINqrrU+dabKqhznkJOhdwxp0wDAICEpc4/xQJI93RBrGBF/WL0S77+0h7z5oVOunDUlAyFVAoHAhtFiypWvCk3mj6hqRqqdlCfH48uRlQdob9262LJCw5UXRVI/UASM21EvIsZXYAFhk8KjbzeVl7lU2LH5VGYpv3UOFcXSupVlBiaTqLjaEU6NfGOKzTTsvSqqFLvFNGqfQouVCUSODaFNdpX1BQ4pb//CsICeZUUXj8wVWqJVsALpFXH9H0KfH0TS98nvd/U/DxwtTZdZKoRvui10FQdr8+TqmgC6T2o11H3x5zSE2pqQK/ePV7vMe91TAsreulnQN8/NczXz2jMKalqGq/gQCujeVS9o6mCF9L7LT1RmK7XVqvSaYqhzlvx8SoyY/bY0ntP5yE1Zte5S7ygOblTUb1jjR07Nlo1lHrA6byl7603FVBNxHUeU1+nQDF7eOk8rYUB1DMsZrWbzsV6r6XWikYAAFIrKqAApEqaQqPwQH9pj++v5AoeNO3lu+++c1NvVAmjCgZdNKgiRn/x9hqVq2m1KlrkySefdKum6bF1kapARtO19Ndu9VbSX8V1kVGtWjU35UIXS7rQ0l/z3333XVeBE1elVUyqFtCUHl0AqaJGf6VXHxJVdnnhhvev/sqemHF5VCWliyC9Tuozo7EmhoI1NTVXyKIQSxduqhTRhZ96u2hajcI8Xch5lQQat14DXdhr+p8u9PU9USim11fTAGM29L1QmmanVbJ+++03V62iHk+q2lIY5l1sajqjVlPTMuqaiqewUvsruNIFp5qzB4ZIiaULYz2mVkjTc9X3RhUbCgdVFeZNtVKIp+Oqkkb7apyqtvCmcun+5FCFxU8//eRe97gq/y6Evn/6/nsrken1UfWPwoSYjaLDjSpu1KtL0yX1/lTQEEiBqt6v+p7pHKGfH4VxM2fOdBV8gfvrfCLeimx+0M+1d5z4aEzelNPUQD97qhjTFEa95+Obaiv62dF0vffff9+9p1VxqXO6PtfrropCL+hXUKswR98f/fwkFGzFRd8nHUvnQ/XY07G0+IPOtaqmVKWWtyiCQkjtq/OZqqb0/4KmJau6MfD/Gr0ndB7WHwvU+F3nG4VOqkZVyK3/awIXZQAAAOdHAAUgVdI0Mf2yf/fddye4ny4mFEDpIlqhky5uxo8f7y5idAGii3gFU7pY8iiM0oWPgiFdjCusUH+kSZMmWb169aL201/udZGiXlS6OFHgpb/8q1okMQGULqq0qpK+RuNRNZOOq4s49Q9R1ZAuZnr06JGkcYku/HTRpfsSW/3k0UW6pijpNdOFpMagigCt+KTXW1MevekqHo1RjXtVNaCKLFEQp9dWX5PSlQB67dRvRo1/dQGoMEyhkL7fgX1/9Nrq9dLUKwV0GrfCMoVBGrOeW+Cy8Ymh11UVYJpio6oIhTS6GFUTa1VGeRfdOobepzq2piUpnFSooWBH+yV3+p2qt7Rql4LIlA6gFK7p50rBhxos6/XS89JYtaJhuNNrr4o0/YzFnBql9/1bb73l3i8KnVShqOmsmr6q10VBo0fvNb8DKAVl51tNTeFuagqgVEHnrUCqRtwJ0flLK93p50jvt1GjRrmAR9Mix40b56YDe/TzppBI35uhQ4e68DkpDex1LFVI6lgKobxjaQqtQv3AlfZ0nlBwrf8nvMb1Os/q2P369Yv2uBqHxqvH1LlGvdJ0HtRjKsgEAABJkyHyfJ1UAQCpki6ydEGtcCy19Rq6EKo0UKWEpmACAAAASBuYvA4AYUgNc1V9o7AmLYVPAAAAANImpuABQBjRlJ0lS5a4HiQKoTTVCwAAAABSu1RVAaW+IupFkRCt1vPII49YjRo13ApDzzzzjOvzAgDpgVbtUt8mTVHTCnhqig0AAAAAqV2q6QH1zjvvuKVu1dxSzSHjo4BKgZOCp8OHD9tTTz3lwihdiAEAAAAAACD1CfkUvN27d7ulqrXUuZYST4imnGjlFa1aolVJ5Nlnn3UrNmnlEvqgAAAAAAAApD4hn4L3+++/uyWG58+fb1WqVElw31WrVrklrr3wSTQNT0tKr169OgijBQAAAAAAQNhVQGkFJ90SWy1VokSJaNuyZs1q+fPnt507dybr+Kqq0ixEhWAAAAAAgPBz5swZV5hQtWrVUA8FQGoNoJJCvZ8UOMXVlPfUqVPJekyFT7qdPn06BUYIAAAAAACAsA6gsmfPHmdQpPApZ86cyXpMVT4pgCpXrlwKjBAAAAAAEGx///23q4ACkHqFVQBVvHhxW7p0abRtCqQOHjxoRYsWTfbj6kSV3AALAAAAABBahE9A6hfyJuRJUaNGDdu1a5dt3bo1aptWxZNq1aqFcGQAAAAAAAAIywDq3LlztnfvXjt58qT7XKvkXXPNNfbwww/br7/+aj/88IMNHjzYWrZsacWKFQv1cAEAAAAAABBuAZRWtqtbt64tWrQoqqxy/PjxVqpUKbvnnnvsoYcesvr169uQIUNCPVQAAAAAAADEI0OkOnCnY2vXrnX/VqpUKdRDAQAAAAAkA9d1QOoXVk3IAQAAAABIT9Sa5syZM6EeBhCnLFmyWKZMmSwxCKAAAAAAAEhlNFlJi3Bp1XcgNcufP78VL178vKtREkABAAAAAJDKeOFT0aJFLWfOnOe9uAdCEZIeP37c9uzZ4z4vUaJEgvsTQAEAAAAAkMqm3XnhU6FChUI9HCBeOXLkcP8qhNL7NaHpeKl6FTwAAAAAANIbr+eTKp+A1M57n56vVxkBFAAAAAAAqRDT7pCW3qcEUAAAAAAAACnUFwlxI4ACAAAAAABJsnbtWnvsscesQYMGVrlyZbvxxhtt0KBB9u+///pyvKlTp1qdOnXcsSZMmGAdO3Z0t9Tkr7/+srvvvjvatvLly9u4ceNCNqbUhCbkAAAAAAAg0d555x0bNmyY1apVyx555BHXfHrr1q02efJkW7JkiU2bNs0qVKiQYsc7evSovfDCCy7s6tq1q5UqVcoaN25sqc0nn3xiP//8c7Rt7777rhUvXjxkY0pNCKAAAAAAAECirF692p5//nlr3769PfXUU1HbFUapCqply5b25JNP2ty5c1PsmIcOHbKIiAj3+DVq1LBwcvXVV4d6CKkGU/AAAAAAAECiqMopT5481q9fv1j3FSxY0Pr372833HCDHT9+3M6dO+eqpW699VY3dU4VTKNGjbJTp05FfY3279y5s82ZM8duvvlmu+qqq6xFixb21VdfufsVZDVq1Mh9rGBLU9ok5hQ8VUkNHjzYateubVWrVrWHH37YTdvz9hc9jo4XSI+vfbZt2+Y+13S5m266ycaPH281a9a0unXrugDs5MmTNnr0aFd5pTFec8011qVLF1u3bl3U1+lrYk67izkFb8+ePTZgwAC7/vrr3WvSpk0b+/zzz6ONSV+j100Bn8ag5/Pggw/af//9Z+GMCigAAAAAAJCoBtvffPONC3Jy5MgR5z5NmzaN+lgBykcffWTdu3e36tWr2x9//GGvvvqqC20mTZoUtXrab7/95oKZvn37Wu7cuW3MmDHWp08fF0IptFKw07t3b7vvvvvc53G5//773eMqeLrooots5syZLjBKjh07dtiXX35pL7/8sh08eNDy5cvnxrZq1SoXvF1yySVuyqHGqSmICxcutDvuuMN27dplH3zwQbzT7v777z8XOGXLls2Ns0CBAi4Ae+CBB+zFF1+02267LWpfHVtB2EsvveT6ag0fPtwyZcrkPg9XBFAAAAAAAOC8Dhw44KqX1IPpfP7++28Xxiig6dGjh9umJuLqF/X444+7cElVQHLkyBEXxCjYkZw5c1qHDh3shx9+cFVRFStWdNt1f1xT2r7//ntbsWKFqzTyekPVr1/fmjdvbhs3bkzy8zx79qw98cQTLjST06dP27Fjx2zgwIFRAZsqk1R1NWLECBcsKXDyQqf4pt299dZbtn//fvv000+tZMmSbpteA1WAKYDSeDNm/L+JapdffrkLnTy//vqr6zEVzpiCBwAAAAAAzksVOKKpdeezcuVK92+zZs2ibdfnehwFRoFT97zwSbwg58SJE4kal4KqLFmyuB5RHgU5gdVYSeWFXpI1a1Y39VCPt3v3bne82bNn2/Lly6MCqsRYuXKlm07nhU8eVT7t3bvXNm3aFLUtZoil1ySxr0dqRQUUAAAAAAA4L01Fy5Url5uiFh/1fjpz5ozrmyRFihSJdn/mzJnd1DNVPXliTufzpuap8XhiK7Py588fVT3kKVSokCWXnmegr7/+2q38p5BI92mVP1VqeVMTE+PQoUN28cUXx9peuHBh9+/hw4fjfU303BJ7nNSKCigAAAAAAJAoasqt6qXARuKB3nvvPbv22mujPldlTyCFUwqMFEKllGLFirnHjBlY7du3L9a+Mau3FJidzz///OP6NKkq6rPPPnMrAarHVMOGDZMc4O2N8XqIty0lX5PUiAAKAAAAAAAkSteuXV1j7ldeeSXOIGXKlClWrlw510Bb1KA7kD5XCFStWrUUG5P6Malv07Jly6K2qVpo6dKl0fZTg3M1Cg+kMOl81CRdgZt6WWmqoFehpaoo71gSswIrpho1atjPP/9s27dvj7Z9/vz5rlKsdOnSlpYxBQ8AAAAAACSKehM9+OCDLoBSg++WLVu6yp2//vrL9UlSUKP7ypYta61atbKxY8e63kUKX7RKnVa0q1WrltWrVy/FxqTHVoNzrbqnhuBaBU8N0Dds2BAVFokqliZOnOhuVapUcYGV+jmdz5VXXummDo4cOdIFcOr5pKbpX3zxRbQqqrx587p/P/74Y/f4MafbdenSxYVNajquVf00bXDevHluDJred74AK9yl7WcHAAAAAABS1H333WdvvPGG+1jBiSqD3n77bWvQoIELVBQ+yfPPP++mri1YsMDt884771inTp3szTffTPGw5eWXX7ZGjRrZ6NGjXUCmxuF33313VJ8m6dmzp91xxx0uKNNzUMWWxng+qkzS46oBub5u8ODBbvuMGTNcwLVq1Sr3uVbgq1SpkvXv398dI6YiRYrYrFmzXKD13HPPuXHu3LnTJkyYYLfffruldRkiw72L1QVau3at+1dvEgAAAABA+Elr13UnT560zZs3W5kyZSx79uyhHk6qpyltv/zyi91www3RXq++ffvav//+ax9++GFIx5fWnUzk+5UpeAAAAAAAIGypmkpVRwqg2rRpY5kyZXL9mZYsWWLDhw8P9fDw/yOAAgAAAAAAYatEiRJuWt+rr75qDz30kGtIrmmAo0aNsubNm4d6ePj/EUABAAAAAICwdu2117obUi+akAMAAAAAAMBXBFAAAAAAAADwFQEUAAAAAAAAfEUABQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwFQEUAAAAAAAAfJXZ34cHAAAAAAAp5VxEhGXKmDFsjt2xY0dbuXJlnPd17drVnnjiifM+xooVK6xTp072+eefW6lSpdxjlixZ0kaMGJGsY/7vf/+zAQMGJHjM6dOnW61atc47NiQeARQAAAAAAGFCAdDAmV/b5j2HgnrcMkXz2XPt6iXra5s0aWJPPfVUrO05cuRIgZEl/ZiZM2e2evX+33Pp06ePFS9ePNr++fLl821s6RUBFAAAAAAAYUTh0/rt+y1cZM+e3YoUKZKqjqn7PVmyZAnJGNMbekABAAAAAICQ0ZS5/v37n3cbwhsBFAAAAAAAAHzFFDwAAAAAAOCbBQsW2KeffhptW7Vq1WzSpElp6phIGAEUAAAAAADwTaNGjezRRx+NtwdTWjkmEkYABQAAAAAAfJMrVy4rXbp0kr7m7NmzQT8m/EUPKAAAAAAAEDJahe7o0aNRn0dERNi///4b0jEh5RFAAQAAAACAkLn66qvt22+/ta+++sq2bt1qQ4cOtcOHD4d6WEhhTMEDAAAAACCMlCmaL00ds2vXrvbPP//Ygw8+aFmzZrU2bdpYs2bNLDIy0rdjIvgyRKbz7+jatWvdv5UqVQr1UAAAAAAAyZDWrutOnjxpmzdvtjJlysRqnH0uIsIyZQzNZKZQHhvh+X4NxDsHAAAAAIAwEcoAiPAJF4J3DwAAAAAAAHxFAAUAAIBUT9M+0tNxAQBIa2hCDgAAgFRP0z4GzvzaNu85FNSGu8+1qxe04wEAkJYRQAEAACAsKHxav31/qIcBAACSgSl4AAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVzQhBwAAAAAAvmjUqJG1atXK+vTpc0GPsX379mjbsmXLZsWKFbNmzZpZ3759LWPG6PU1R48etTp16liuXLnsyy+/tCxZspgf/vnnHxs2bJitWrXKsmfP7sb62GOPWZ48eXw5XjijAgoAAAAAgDARGXEuXR67a9eu9s0330TdPvzwQ2vRooW99tprNnny5Fj7L1y40AoVKmRHjhyxzz77zJcxnTlzxrp3726ZM2e2d99911555RVbsWKFDRw40JfjhTsqoAAAAAAACBMZMmay/+b2tzP/bQrqcbMUvswKtx5hoZIzZ04rUqRI1Of6uHfv3rZy5UpbtGiRC4ICzZkzx+rVq2c7duyw2bNnW9OmTVN8TH///bdt2bLFxo4da2XLlnXb2rdv74IoxEYABQCI5lxEhGWKUcKclo8LAAAQbhQ+ndm1ztKKefPm2ZQpU1yYU7hwYWvTpo317NnTMmXKdN6v1VS8EydORNu2ceNGW7Nmjd1777126NAhV5G0efNmK1OmTJyPMW7cOFe5pFBL0/U0ZTB//vw2fvz4OPevWbOmzZgxwwoUKOCm/r333nv2xBNPuGl/n3zyiVWpUiWZr0TaRgAFAIhGIdDAmV/b5j2HgnbMMkXz2XPt6gXteAAAAEgdpk6daqNHj7b+/fu7nk0Kjp599lk7cOCAPfXUU/F+3enTp13l07fffmtPPvlktPs++OADVzFVv359O3nypD3zzDOuCmrAgAHxPt6PP/5onTp1so8++sjOnTvnwqi2bdvGua/XT6p48eIu3Bo1apTNnDnTIiIi7PLLL7dXX3012a9HWkYABQCIReHT+u37Qz0MAADSjMiISMuQMUPQj6sL4pjNmdPiMRGeIiMj7c0337QOHTq4qWty6aWX2sGDB23kyJGuubjXzHvixImuSsqjqidVNCmkateuXdT2s2fP2vz5810zcDUF161u3bquyqpfv36uYio+gccTNTBPiEKwDRs2WOPGjd34FZq9+OKL9tBDD7mxJqaCKz0hgAIAAAAAnyl82j7vdzu971jQjpnrskJWtGFZ1wvnv//+C8oxNX3q9ttvD8qxEP7279/v3pvVqlWLNcVNDb43bdoUNZ1N1UgdO3Z01Unff/+9q5q65ZZbooIrj6bQ6TG1Op5HHy9fvtwWL15sLVu2jHMsalgeGD69/vrrLvSKi8Y7adIkV72lqXuqxPLCJgVoCqR0vBtvvPECXp20hwAKAAAAAIJA4dPJXUeDdryshXK6f3UxvnPnzqAdF0hKBVR8VXSi1eU8+fLls9KlS7uPL7vsMledpL5LmmoX2IB87ty57l81KI9J0/DiC6BUKRVIgVeTJk0S3Hf16tV2xRVXRKt00hjVG0r9rBAdARQAAAAAAAg6VczppiAnsFpo1apVrs/SJZdcEu/XKkhSldGYMWNcr6fy5cvbvn37XAVU69atrUuXLtH2V7WSqgH//PNP16fpfNSEXLeEFCtWzH766ScXpGXI8H9TbHfv3u2mEKoSCtExMRcAAAAAAPhm69at9tVXX0W7rVy50t3XrVs3e/vtt10Tb+23YMECt/rcXXfdFW1KXFwGDx7sKqHUCFxVU+r9pB5QqohSyBR469Wrl+tNpiqolKLpfxrzoEGD3Mp7v/zyi+sjVaFCBbv++utT7DhpBRVQAAAgTQlVo99QHRdIKZHnzlmGIDfMjYiItIwhacwdmuMCKSVL4cvC6pgKlXQLVLJkSVu2bJl17drVsmbNatOmTbNhw4a5leUUICmYOh/1bdLKdpqKN336dDf97rrrrnNT9GJSNZWqrBRSPfroo27q3oVS1dWMGTPspZdecoFZjhw5XMPzxx57LGqlPPw/BFAAACBNCUWj36yFclnJllcG7XiAHxQ+rRs61I5v3RqU4xWsVcvKdO9uS975yQ7sDl5fpALFclvj9tcE7XhASouMOGeFW48I2bEzZExaUK2Q6Xy0Cp5uyXkMTcXz+jp17tw5weOMGzcuzu19+vRxt+S4+uqrXfiF8yOAAgAAaU6wG/0CaYXCp6N//hWUY+X4/3u7KHzau/1QUI4JpAVJDYDSyrER/ugBBQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwFQEUAAAAAAAAfEUABQAAAAAAAF8RQAEAEGSR586li2MCAAAAnsxRHwEAgKDIkCmTrRs61C13Hgw5S5e2ioMGBeVYAAAAQFwIoAAACAGFT0f//CvUw0AKyZQrq0VERFjGjMEtLg/FMQEAAJKDAAoAAOACZcqe2QVBc+bMsf/++y8oxyxcuLDdfvvtQTkWAADAhSKAAgAASCEKn3bu3BnqYQAA0rBzEecsU8ZMYXPsRo0aWatWraxPnz7JPq4eY/v27dG2ZcuWzYoVK2bNmjWzvn37xqoIPnr0qNWpU8dy5cplX375pWXJksX8dOrUKbvjjjusc+fO1rp162j36fhjxoyxv/76y425S5cu1r59e0tvCKAAAAAAAAgTCoCe+fQZ23JgS1CPe2mBS+3pm5+2UOnatau7eQ4fPmyLFy+2cePGuZCpe/fu0fZfuHChFSpUyPbu3WufffaZNW3a1LexHTlyxB566CHbsGFDrPtWrlxp9913n/Xq1cteeeUVW7FihT399NNWoEABX8eUGhFAAQAAAAAQRhQ+/bn3T0tPcubMaUWKFIn6XB/37t3bBTyLFi2KFUBpWny9evVsx44dNnv2bN/CnmXLltnQoUNdoBQXBWQ33nijq9KSSy65xH7++WdbtWoVARQAAAAAAECwzJs3z6ZMmWJbtmxxPQ7btGljPXv2tEyZzj/dT1PxTpw4EW3bxo0bbc2aNXbvvffaoUOHbODAgbZ582YrU6ZMvCGRKpMUamm6nKYM5s+f38aPHx/n/jVr1rQZM2a4j5cuXWpt27Z10+oqVaoUbT+NS0HT2LFjo20fNmyYpUcEUAAAAAAAICSmTp1qo0ePtv79+7ueTQqOnn32WTtw4IA99dRT8X7d6dOnXeXTt99+a08++WS0+z744ANXMVW/fn07efKkPfPMM64KasCAAfE+3o8//midOnWyjz76yM6dO+fCKAVLcQnsJ5VQmLR161a3Yq2CtL59+7pjFC1a1Dp06OD6RaU3BFAAAAAAACDoIiMj7c0333SBjNeU+9JLL7WDBw/ayJEjXWiTJ08et33ixImuSiqwukgVTQqp2rVrF7X97NmzNn/+fNe4PHv27O5Wt25dV2XVr18/VzEVn8DjiXpLXQg1QpfBgwdbjx49XC8oVVopEJP0FkIRQAEAQq5QnuwWGXHOMgR5RZdQriIDIPUL1bkpFMcEgFDYv3+/W0G2WrVqsaa4nTlzxjZt2mRVqlRx21SN1LFjR1ed9P3337uqqVtuuSXWanKaQqfH1Op4Hn28fPly17S8ZcuWcY5FDcsDw6fXX3/dhV5x0XgnTZp03ufnVUq1aNHCVVdJxYoVXWWUKr8IoAAACLI82bO6i63/5va3M/9tCsoxs5erawUa9Q36KjLXXnKt9byuZ9COByC8zk1ZCl9mhVuPCMqxACA1VEDFRdPWJHPm/xdZ5MuXz0qXLu0+vuyyy1x10hNPPOGm2gU2IJ87d677Vw3KY9I0vPgCKFVKBVLg1aRJk0TtG5/ixYu7fy+//PJo28uVKxc1zvSEAAoAkGroAu/MrnVBOVbmQmVCsopM6QL/94sTgPARzHMTAKQnajiu2+rVq91KcR417lb1kFaMi4+CJFU1jRkzxvV6Kl++vO3bt89VQLVu3do1BQ+kiiOtjPfnn3/GCoTioibkul2IYsWKueegvlYtWrSI2q4xJPTc0qqMoR4AAAAAAABIuzTl7Kuvvop2W7lypbuvW7du9vbbb9vMmTPdfgsWLHCrz911113RpsTFRb2VVAmlVe5UNaXeT+oBpYoohUyBt169elnGjBldFVQwqRLr3XfftXfeecf+/fdfd3wFYXre6Q0VUAAApHFZCha0iIhIy5gxQ9CPHarjAuEqY65C9KcDcF6XFrg0rI6pUEm3QCVLlrRly5ZZ165dLWvWrDZt2jS3opymrSlASkxAo75NWtlOU/GmT5/uprVdd911bopeTKo4UpWVQqpHH33UTd0LBq/yaeLEiTZ8+HD3vJ9++ul4pwKmZQRQIXROyzFmzJjmjwkACK3MuXO7EGjJOz/Zgd3/txpLMBQoltsat78maMcD0oKM2fO68In+dADio5D66ZufDtmxkxqQK2Q6H62Cp1tyHkNBjhfmdO7cOcHjjBs3Ls7tffr0cbcLtWHDhnhDqBYBU/DSKwKoEFIQNHDm17Z5z6GgHK9M0Xz2XLt6QTkWACD1Ufi0d3tw/s8BcGHoTwcgPqGskKQ6ExeCACrEFD6t374/1MMAAAAAAADwTaqYi6VmYWPHjrV69erZ1Vdf7eZ7qjlXfLZs2WI9evSw6tWru273+lo1GgMAAAAAAEDqkyoCqAkTJriO90OHDnUd4RVI3XvvvXb69OlY+x46dMjat29vJ06ccE3KXnrpJVu8eLHrfg8AAAAAAIDUJ+QBlEKmKVOmWN++fa1BgwZWoUIFe/nll23Xrl22ZMmSWPt/+OGHdvz4cRszZoxdeeWVrgrqueeec8sYbtu2LSTPAQAAAAAAAKk4gFq/fr0dO3bMateuHbUtb968dsUVV9iPP/4Ya/+tW7e6JRULFiwYtU37yqpVq4I0agAAAAAAAIRNAKVKJylRokS07UWLFo26L+b2PXv22Llz56K2bd++3f27b98+38cLAAAAAACAMFsFT72cJGvWrNG2Z8uWzfV7iqlJkyauZ9Tw4cOtX79+bjqepuBlzpzZzpw5k6wxREZGuscJpgwZMliOHDksVK+5njMApKZzE9KuYP6/kx7fw+nh//X0+H2F/zg3pa1zk46l1xlA6hXyACp79uxRvaC8j+XUqVNxnqQvvfRS1/9JTcffeecdy5kzp/Xp08f+/vtvy5MnT7LGoOBq3bp1Fkx6bt7UwWDbvHlzVPAHAKnl3IS0K5j/76TH93B6+H89PX5f4T/OTWnv3BSzqAFA6hLyAMqbeqdpdZdccknUdn1evnz5OL+mUaNG7qZ98ufPb2fPnrURI0bYxRdfnKwxZMmSxcqVK2fBFMp0vkyZMmn+L6UAkoe/HCLc/99Jj+/h9PD/enr8vsJ/nJvS1rlJBQkAUreQB1Ba9S537ty2YsWKqADq8OHD9scff1iHDh1i7a9G46qAeuutt1w/KFm0aJH7q8I111yT7P8QVEmVXqS38l8AQGjx/46/eH2B5OFnJ229vukp5Is8d84yZMoUNsdW8UirVq3czKXk0mN4vZ8D2/YUK1bMmjVrZn379rWMGaO3uD569KjVqVPHcuXKZV9++aUrPDmfpUuX2pw5c+y1116Ltv3ll1+2119/3Z588km75557Yn3d8uXLXUGMV9iyevVqF8BWr17dUsrcuXNtwIABcd6nwhxlKtu2bbMbbrgh3sdYsGCBXX755a7Yp3LlyjZ79mzLFOP72bFjRytZsqQr8lEV4+23326TJk2yiy66KPwDKJVJKmgaNWqUW9lOT3TkyJFWvHhxa9y4sWs2vn//fje9TlP0tALehg0b7IUXXrBOnTq5j9UDqmfPni7IAgAAAAAgrVIAtG7oUDu+dWtQj5uzdGmrOGiQhUrXrl3dzaPClcWLF9u4ceNcyNS9e/do+y9cuNAKFSpke/futc8++8yaNm2a4OOrB/XQoUNt+vTp0bZHRETYvHnzXFXfu+++GyuAUjDWq1cv93VeANWuXTvXtzolAyjPN998YzHFDN/0mlStWjXWfgUKFIj6+Ndff7XJkydbjx49LKEg+d5777WBAwfalClTLOwDKFFaqWl0elInT560GjVquBdCCaWX4Omb17p1axdSKXlUGte8eXMrUqSI9e7d2zp37hzqpwEAAAAAgO8UPh398y9LTzRrSdf/Hi8LWLlypZsVFTOAUiVTvXr1bMeOHa7S53wB1LRp06xKlSpWunTpWIHPrl273GJo999/v/34448us/Ck9FTTjh07Ws2aNeOtGAt8DeKTL1++8+6nii0FVaouS6glUYsWLWz06NH2/fffW+3ate1CRI/JQkQlX4899ph7Qj///LO98cYbVqpUKXef/lWVk8Inj6bavffee7ZmzRpXIkf4BAAAAABAeFKF0W233eamhSkQUdij2VCJoal4mTNHr63ZuHGjyws0BU8zqzQ9TY3x46NF0LTIWZMmTeKc+qZpaxqXelgrzPIETnnTDC0FOl4va02X69+/v9tH2z799FO744477KqrrnKPpWqqUFJlk9ogPfHEEwm+1sprbr75ZtcG6UKligAKAAAAAACkP1OnTrVBgwbZXXfdZfPnz7cHH3zQzYjSrKeEnD592gVX3377ravSCfTBBx+4iqn69evbTTfd5GZXBQZHcfWa1pQ+7R/o4MGD9vnnn9stt9zi+owpoFKQpDZBokDq/fffdx8rfNIUQW+KnPpFPfXUU1GPNXz4cDdVT9MGGzRoYEOGDLF///3XQtkOSWNat26dvfnmmwnuq/F+9913F7yyJQEUAAAAAAAIOk1fU/ihvtDt27e3Sy+91IVJatMza9YsO3LkSNS+EydOdH2NvJuqpbRNIY++1qP2PgqyVGWkPtJq0F23bl0XVqnSKS6//PKL60etXlKBPv74Yxd0qdG56N8zZ864qiivOkhtgrxpb/p6b+qb+ljr5uncubOrltLUt4cfftj1llKVlleN5D0vhWGBz1UtiAIFvgbeTdMMA2k6Ysx99JrEpNdQxx4/frz9+eef8X6fVAGm5/37779b2PeAAgAAAAAA6Ysqif777z+rVq1atO3qgaTAY9OmTa4vk7Rt29b1R9J0MbXvUV8iVSYFhk+iFe/0mF5oJPpYK9Wp+qhly5axxqH91bA8JvWRuvLKK10wJpo+p4/VEqhbt25JWn2xbNmyUR97wZSeozz//POuH7Y8+uij7jnruXrBViAFaTEVLVo02udaqM173TxxPT9RH61ly5a56YJ6XnHxQjY1dL8QBFAAAAAAACDo4mvgreogCeztpCDGaxB+2WWXuWoj9S/SVLvABuRedZKClZg0DS+uAEqryMXsg7R+/Xr7448/XMh0xRVXRBubxq0paeoxlZQpb/E9/2LFikVtU9VW4HONKb7tgfR4idkvcCqeAj71446L99rEXG0vqQigAAAAAABA0BUuXNjdVq9ebTfeeGPUdk1DU98mNcmOj4IkVTWNGTPG9W5So+99+/a5CigtYtalS5dYvaZU0aSpZppSFkjT5ry+ToF9pDSG6dOnW+7cuaO2Hzt2zFUnqYm4AqikVEGlVpUqVXJT8dT8Xd8PTUcMpNc1rkqrpCKAAgAAAAAAvtm6dat99dVX0bap0kdT7TSV7eWXX3a9kRTo/Prrr64nkZqSB/ZQisvgwYPthx9+sIEDB7pASH2O1ANKFVGqkgqkBuAffvihq4LS1wXSdLVXXnnFNR1Xzyj1fVqwYIFb/e2aa66JddzmzZu7+zUlTRVYomBLlVIas7ZpJb4DBw4k+bWaMWOGhcIDDzzgpuLF1QtKlWBabdBb4S+5CKAAAAAAAAgjORM5vSq1HFNhjW6BVGWjwEMrx2ka2LRp02zYsGFWvHhxFyApmDof9TUaMGCAm4qnSiVNv7vuuutihU+iaipVWSmkUp8lLziSGjVqWN68eW3FihUudFJllcKomP2lAhuKK8zSCnj333+/3X777fbiiy+6oE1hmJ7TpEmTXAilz8NB1qxZ3cqDd955Z6z79LrodQ18zZKDAAoAAAAAgDARee6cVRw0KGTHzpApU5K+RiHT+WgVPN2S8xiaiuf1dVIwlJBx48bFuV29pu6++24XYCmA0m3Dhg3xPk6FChWi3a/gTDdPnz593M0T12NtSODx46JphbolpFSpUol63Pj2UcP1mCvdqRpMqwGqSu1CXVgHKQAAAAAAEDRJDYDSyrH9pp5Ra9eudVVLiL7qnnpmqQLqQhFAAQAAAACAdE29nwYNGmQjR44M9VBSjePHj9vkyZOjVXddCKbgAUi2yIhIy5AxuKs+aNnTC13+M5yOCwAAACA4mjRp4m74P+r59Omnn1pKIYACkGwKn7bP+91O7zsWlOPluqyQFW1Y1i2f+t9//1mwaClSNRYEAAAAACQPARSAC6Lw6eSuo0E5VtZC/7fqgsKnnTt3BuWYAAAAAIALx3wSAAAAAAAA+IoACgAAAAAAAL4igAIAAAAAAICvCKAAAAAAAADgKwIoAAAAAAAA+IoACgAAAACAMBERERl2xz59+rRNmjTJWrZsaVWrVrVatWrZPffcY0uWLIm2X/ny5W3u3LkXNEY9RsxblSpVrGnTpjZ9+vQ4v2bLli1uP40P/sns42MDAAAAAIAUlDFjBlvyzk92YPfRoB63QLHc1rj9NUn+uqNHj7qw6eDBg9anTx+rVq2aHT9+3IVP/fr1szvvvNMGDx6comN98sknXeDk2b9/v82aNcuef/55K1y4cLT7RKFXmTJlbN26dbZmzRoXWCHlEUABAAAAABBGFD7t3X7IwsGLL75oe/futXnz5lnBggWjtqviqFKlStazZ08XSjVr1izFjpknTx4rUqRI1Of6+Omnn7ZvvvnGFi1aFC2AOnfunBtbhw4d3L+zZ88mgPIJU/AAAAAAAECKO3LkiH344YfWtWvXaOGTp0GDBla7dm2bNm1aoh5PYdHUqVPt5ptvduGV/lVlU2JkyJDBsmbNapkzR6/DUSi1e/duq1OnjjVu3NgWL15shw8fTuQzRFIQQAEAAAAAgBT366+/uv5PqnCKjwIo7XfmzJnzPt6IESNswoQJ1rt3b1uwYIG1b9/eTatTKJUQTfl74403bOPGjdaiRYto982ZM8cuueQSu/LKK11l1IkTJ1wlFFIeU/CQZkWeO2cZMmUKSWM+zctO68cEAAAAgIQcOHDA/Zs3b9549ylQoIBFRkZG7ZtQLylVO/Xv399uvfVWt+3SSy+1bdu2uXBJfaZU5SSabjd06FD3sR771KlTVqFCBXvllVesYcOG0ca3bNky69atm/v88ssvd7d3333XOnXqlAKvAAIRQCHNUvi0buhQO751a9COWbBWLSvTvXtQmwImtxkgAAAAAPjJm3Z36FD8/arUnNzr25SQTZs2uSqpmNVUNWvWdFP49u3b5xqMS9++fd10urNnz7opdZMnT3bNzps0aRLta1VFpccM7AmlXlQvv/yyrVq1yqpXr56MZ434EEAhTVP4dPTPv4J2vByXXBJ2TQEBAAAAwA/q05QtWzZbuXKlVa5cOc59dJ+qjnLkyJHgY6mSKS4RERHu38DeToUKFbLSpUu7jzVdT4YMGWL58uWLFjZp9Ttp1apVrOOo2ooAKmURQAEAAAAAgBSnqqbWrVvbW2+9ZbfddpsVLVrUBUbNmzd3U+GqVq3qmoA/++yz532ssmXLWpYsWWz16tVWsWLFqO2qVNIqdwqX4nPffffZ119/7abmKVTSOP744w9bt26d9erVK9YKfFq5b8mSJW6KnqYIImUQQAEAAAAAEEbUhiNcjvn444/bhg0brG3btm5qnKbQKRBSRdKkSZPc53fccUfU/n/++ad99dVX0R4jf/78roLqrrvusrFjx7rPVV2l8GrmzJnWr1+/qP5PccmUKZNrVt6yZUvXG2rcuHGu+klVV1qhL2Z41b17dxdYaR+vPxQuHAEUAAAAAABhQgsQhaoHbHIWP8qZM6dNnz7d3nnnHder6ZlnnnHT5cqXL++qkdTw+4EHHnDVSaJqKd1i9nmaMWOGDRgwwFUkjRo1yv777z/XhHzw4MGuv9P5lCtXzlU7KXxatGiR6/+kZuZxVU7VqlXLrYr33nvvuYAqoXALiUcABQAAAABAmAjl6tfJPbamznXu3NndYurSpYu9//77brqeKqUSouBKPZ28vk5xSegxAr82sBdUXLz+UEg5BFAAAAAAACAkVNHUo0ePUA8DQZAxGAcBAAAAAABA+kUABQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwFQEUguJcxLlQDwEAAAAAAIQIq+ClI4XyZLfIiHOWIWOmoB87U8ZM9synz9iWA1uCcrxrL7nWel7XMyjHAgAAAAAACSOASkfyZM/qwqf/5va3M/9tCtpxs5erawUa9XXh0597/wzKMUsXKB2U4wAAAAAAgPMjgEqHFD6d2bUuaMfLXKhM0I4FAAAAAABSH3pAAQAAAAAQJiIiIsLq2P3797eOHTvGepwGDRrYVVddZfv374/1NefOnbOxY8daw4YNrXLlyta6dWv74osvLmjsCD0qoAAAAAAACBMZM2a0eRPG2L4d24J63EIXlbKW9z+YIo/13Xff2aFDh6xQoUL2wQcfWI8ePaLdP2bMGHv//fdt+PDhVrZsWfv444/t/vvvt/fee8+FVghPBFAAAAAAAIQRhU+7tmy2cDVnzhyrVq2alSpVygVN3bt3twwZMkTdf+bMGXvqqadclZTcd999NmXKFPvhhx8IoMIYU/AAAAAAAEBQqPJp6dKlVqdOHbv55pvtn3/+sW+//TbaPk888YQ1b97cfXzy5EmbMWOGnThxwmrVqhWiUSMlUAEFAAAAAACCQtPpVOGk8KlYsWJuGt7s2bOtbt26sfadP3++Pf744xYZGWl9+vSxSpUqhWTMSBlUQAEAAAAAgKBNv7v66qvtoosuskyZMlmTJk1s+fLltmfPnlj71qhRw+bNm+dCqNdee81mzpwZkjEjZRBAAQAAAAAA361fv95+//13a9asWdQ2fXz27FnXCyqmEiVKWIUKFaxbt252++232+TJk4M8YqQkAigAAAAAAOC7uXPnun+HDRtmV1xxhbt16NDBbdNqeBERES6MUo+oHTt2RPva8uXL2+7du0MybqQMAigAAAAAAOAr9X1STyf1evroo4/c1Drvdv/997vA6csvv3TT8gYNGmSzZs2K9vVr1qyxcuXKhWz8uHA0IQcAAAAAAL5Sn6cDBw5Yly5d7PLLL492n/pBTZ8+3TUjb9iwoXXt2tXGjx/v9lPj8SVLlrjm5ePGjQvZ+HHhCKAAAAAAAAgjhS4qFXbH1PS7MmXKWJ06dWLdlzt3brvjjjts2rRprhJKPZ+yZMniAqedO3faZZddZmPHjrUbbrjhgsaA0CKAAgAAAAAgTKhPUsv7HwzZsTNmTFonnxEjRiRqv/79+7ubp3Pnzu6GtIMeUAAAAAAAhImkBkBp5dgIf7x7AAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAwkRkRGRYHbtRo0Y2bty4CzquHqN8+fLRbpUrV7abbrrJXnnlFYuIiIj1NUePHrUqVarYddddZ2fOnEnUcZYuXWr33XdftG2bNm2yJ554wurVq2dXXXWVG8ugQYNs69atSX4ef/31l33xxRfuY435jjvusLVr11p6kTnUAwAAAAAAAImTIWMG2z7vdzu971hQj5u1UC4r2fJKC5WuXbu6m+fw4cO2ePFiF27lypXLunfvHm3/hQsXWqFChWzv3r322WefWdOmTRN8/EOHDtnQoUNt+vTpUdu+/fZbe+CBB6xOnTr20ksv2UUXXWT//POPTZo0yVq3bm3jx4+32rVrJ/o59OzZ01q1amUNGjSwjBkz2qOPPmoDBgywuXPnWtasWS2tI4ACAAAAACCMKHw6ueuopSc5c+a0IkWKRH2uj3v37m0rV660RYsWxQqg5syZ46qWduzYYbNnzz5vADVt2jRXMVW6dOmoQOrhhx+22267zZ599tmo/UqWLGnXXnutu++xxx5zx86bN2+ynlOtWrVc8DR//nxr06aNpXVMwQMAAAAAACEzb948F/RoWp2muE2YMMHOnTuXqK/Nli2bZc4cvbZm48aNtmbNGle51LhxY1uxYoVt3rw53sc4deqUvfPOO9akSZOobR999JEdOXLEHnrooVj7Z8iQwU3L+++//1yllfTv39/69evnwqprrrnGVUaNGDHCTp8+7e5v1KiRbd++3VVNdezYMeqxmjVrZm+99ZalBwRQAAAAAAAgJKZOnep6Kt11112uEujBBx+0yZMnu/AmIQp2FFxpmlyLFi2i3ffBBx+4iqn69eu7PlFZsmRxVVDxWbVqlZvSp/09P//8s5UpU8YKFiwY59eUKFHCVUutXr06atuSJUtsz5497ljPPfecG9/zzz8fNabixYu7aYSBPbE0He/vv/9OVk+pcMMUPAAAAAAAEHSRkZH25ptvWocOHax9+/Zu26WXXmoHDx60kSNHWt++fS1Pnjxu+8SJE23KlClRX3vixAkXED311FPWrl27qO1nz551QZYqjrJnz+5udevWdWGQKpRUMRXTL7/84qbWqZeUR1Pw8ufPn+D4CxQoYAcOHIj6XFPxNO4cOXLY5Zdf7sIoBVCaqlewYEHLlCmTC8YCH1fPVwGZAi9v+l9aRQUUAAAAAAAIuv3797tpbNWqVYu2vWbNmm7lOq1A52nbtq0LkdTbSc27FeTccsstLrjSlDjPl19+6R5TU9s8+lihlpqWx0X7q2F5zHBJU/ASoqop7efRFEKFT56qVau655HQ9L9MmTK5QEpjSOuogAIAAAAAACGpgIpLRESE+zewt1O+fPmiKoQuu+wyV62kPkwKogIbkGtFOVGD8pg0Na5ly5axtmtFupg9pxSKffLJJy4ki2sanlbXU7Ck6i2PKpnieh4KmRKiY2sMaV3af4YAAAAAACDVKVy4sLsF9lHyejIpzLnkkkvi/VoFSaqAGjNmjG3YsMFt27dvn6uAat26tauWCrzdfvvtbprbn3/+GeuxtKKegqZAt956q6tuGjVqVJzH13bd37x586htv//+e7QgS8dTRZSmCsZH+2u6X9GiRS2tI4ACAAAAAAC+UYPtr776Ktpt5cqV7r5u3brZ22+/bTNnznT7LViwwK0Up6bkXv+n+AwePNhVQg0cONBVG6n3k3pAqSJKPZgCb7169XJVRnE1I69SpYrt2LHDTdPz6NivvPKKffbZZ66aSqHYzp073b8PPPCA2z569GjX98mjVe6eeeYZtwqfGpKPHTvWVUh50/Jy5cplW7ZsiTbdbv369S6E0hjSOqbgAQAAX+TMk839MpgeSsoBAAimrIVyhdUxFSrpFkhNv5ctW+ZWhcuaNatNmzbNhg0b5laKU4CkYOp81LdpwIABbire9OnT3fS76667zk3Ri0nVVDfeeKMLqbweUp4aNWq4IGnFihV28803R22vXr26e8xJkybZ448/7qbdqWJLTc0//PDDWE3Dr776avd7T5s2bVyA1alTJ7vvvvui7u/YsaO98MIL9tdff7lxiI6pgOziiy+2tI4ACgAA+CJbjizul7B5E8bYvh3bgnLMyypXtYZ3/r+VcAAASGsiIyKtZMsrQ3bsDBn/X8PvxFDIdD6qEgrspZSUx9BUPK+vU+fOnRM8zrhx4+Lcrl5Td999twubAgMoUTCkqqbEUJA2ZMgQd4vLnXfe6W6BFGQpqEoPkhVAablDlZ1t27bNdYXXvEell0oH9YIDAAB4FD7t2hL/6i8pqVCJkkE5DgAAoZLUACitHNtvXbp0saZNm7rpc2XLlg3KMb/99ls7ffp0nI3RLb0HUOvWrbOJEyfa559/7pYSjEnzGhs2bGg9evSwChUqpOQ4AQAAAAAAfJE/f34bNGiQjRw50l5//XXfjxcREWEvvfSSm5IXc/W8dB1AHT161IYOHWoLFy60WrVquUZflSpVslKlSrnQSR3bd+/e7aqivv76a9ddvkmTJm6/wIZcAAAAAAAAqZFyDN2SY8SIEUnaP2PGjDZnzhxLTxIVQLVo0cI16/riiy9cw62YChYs6G4VK1Z0TbXU+X3KlCmujCwx8z0BAAAAAACQzgModXwvU6ZMoh9U/aBUuta+ffsLGRsAAAAAAADSgESti5yU8ClQXEsfAgAAAAAAIH1JVAAFIPXKmSeba2AHAAAAAECaWAUPQOqTLUcW18Bu3oQxbqnzYLmsclVreGe7oB0PAAAAAJDGA6gBAwYk+gEzZMhgw4YNu5AxAUgGhU+7tmwO2vEKlSgZtGMBAAAAANJBAHXs2DFbsmSJ5ciRwwoUKHDeAAoAAAAAAEBOnz5t06dPt48//ti2bt1qWbNmtQoVKriFyxo3bhxt3/Lly9vw4cOtdevWyT6eHiOm7NmzuwXT2rZta506dYp1/5YtW+zmm2+2ihUr2rx58xJ1nKlTp9q2bdts4MCBUdt+/fVXe/PNN23VqlV29OhRK1GihDVq1Mi6detmRYoUSdLzWL16tUVGRlr16tXtxIkTdvvtt7tF4i666CJLswHU2LFj7fnnn7cPPvjAXn/9dbv88sv9HxkAAAAAAIhG/V/VgiNcjq0Q5p577rGDBw9anz59rFq1anb8+HFX5NKvXz+78847bfDgwSk+1ieffNKaNm0a9fn+/ftt1qxZLtsoXLhwtPtk7ty5bgG2devW2Zo1a6xKlSoJPv4///xjU6ZMsQULFkRt+/DDD10Y1bJlS5edFCpUyP766y+bMGGCC98mT54cZzgWn3bt2rkwTgGUCoLuvfde9/g6bpruAaVvnr4Rzz77rL399tv+jgoAAAAAAMSiAGjOnDn233//BfW4Cm1UgZNUL774ou3du9dVFRUsWDBqu4KYSpUqWc+ePV0o1axZsxQdb548eaJVHOnjp59+2r755htbtGhRtADq3LlzbnwdOnRw/86ePfu8AdSrr77qxpwvXz73+ebNm23QoEHWt29f95w8pUqVsjp16rgQ7pFHHrGPPvrIMmXKlKzn1KJFCxs9erR9//33Vrt2bUuzAZSm1ilp69+/v0vw/ve///k7MgAAAAAAEIvCp507d1pqd+TIEVcVpOAlMHzyNGjQwAUp06ZNS3QApbBoxowZrpppx44dbjpa586d7e67705UrqHpf5kzR49CFErt3r3bBUWqztLUOvXCzps3b5yPo30XLlxoM2fOjNqm0CpXrlzWpUuXWPvrmI888oibcvjtt99a/fr1rWPHjm4a4r59++zzzz93QZYCsO7du7txepVSGsfKlSttxIgRLrjSNMG33norLAOoJNXO6cVRGkj4BAAAAAAAEqJ+SOr/pAqn+ChI0X5nzpxJ1GMqiNGUtt69e7vpbwp1NK1OoVFCFCy98cYbtnHjRldJFEgVZZdccoldeeWVrjJK/ZYS6gP15ZdfunCqcuXKUdt+/vln97nCprhcc801li1bNtfXyaMQTZVamv738MMPu6oq9Y/yQjFvNtpTTz0VLbT77rvv3BjDTWgmjgIAAAAAgDTtwIED7t/4KolEC52p0ba37/n6SSm00TS3W2+91S699FLXUFy9khQu6XE8mm5XtWpVd7v66qtdCLZ48WJ75ZVXrGHDhtHGuGzZsqgpeep5rdu7774b7zh++eWXWIU5hw4dsvz58yc4dTJfvnzRnqd6Tg0ZMsTKli1rrVq1clVRatau5+FNH1RApZtHY1NY9/vvv1u6CqDUgOyGG25wU/Iu5DHU5LxevXruTaFys3///Tfe/VWeptK1a6+91mrVquVSQpW/AQAAAACA1MObdqdwJj5qTi6BIUt8Nm3a5MKXmBVVNWvWdFmBbh6FVKpi0mJqat6tVfDU8LxJkybRvlZVVHrMwJ5Qmg74999/u5Xs4psCqQbjMYM0TTmMT2RkpAvQtJ9HmYam23kUlqlfVkJhnPeaar90FUDpBdy+fbsrqUsulc5p3uTQoUPdnEkFUnpzxPeYDz30kJvnqTmPuunjBx544AKeBQAAAAAASGlqMq5pZ+phFB/dp6oerfJ2PoEVToGUI0hgbycFRKVLl3bVRZqu161bN1dtpAbkgTT9TVSBdMUVV7jbmDFj3DZVW8VXzaReVIEUimn1vPiyjLVr17ppgJqK54nZi8p7Hgk1KfeOG6qVEC9ESEesb4yWD1QyqXmM6jH18ssv265du9ySjDEdPnzYvTlVJVWxYkX3xujRo4f7RnqpKQAAAAAACD1VNbVu3doVj+zZsycqZFG10ciRI23p0qWu15GmniWGwqQsWbJE66MkqlTSlDVvRbq43HfffW7WlabmeWP5448/bN26ddarVy9XLeXdtFKdZmkpl4irGknH2r9/f7Rtbdu2tZMnT0b1cAp09uxZt3rdZZddZnXr1o3ariwj0E8//eRWzUvoeXhVXkWLFrVwE9IAav369Xbs2LFo3ds1N1TB0o8//hhrf5XMqau83hAqXdNNbwzNm0xoTikAAAAAAAi+xx9/3DX4VkCja3nNolIYpBlQms2kiqA77rgj2tf8+eef9tVXX0W7qVF57ty57a677nJtfD7++GPbunWrvfPOO25WVdeuXaNNZ4tJVUVqVq7m3ZqB5VU/qfJKX+v1fvJuKnxR0YxXIRVIzcY3bNgQVbEkF198sQ0fPtwmTpxogwYNcuPVSoUK2O655x43pU8FN4HVTQrO9Fy2bNnipgrquWhGmCdnzpyuaXpgCKbQTFVl3ip54SR6vVcSqeRLZWqBcxiTQpVOUqJEiWjbleR59wVSN3l1vB88eLBVr17dvbm079tvv31B5Wcq41MpXDBp7IkpMQSQeug/q/jKftMKzk1A+OHcBKT+n530+B4O9rlJx0oofEhrChcuHDbHVIiixtoKV6ZNm2bPPPOMm3qmAEXX9Wr2rSBKlUnFihVzX+O13InZ52nGjBk2YMAAl0GMGjXK9WJSI3JlBOrvdD7lypVz1U7jxo1zU/HU/0nNzOOqOFJ/Jq2K995778UKtxo1auTGqzDoqquuitp+yy23uPFMmjTJTftTcFS8eHG3/yuvvBLVWNyjntoKmG677TaXbei53X333VH367h6LO3z+uuvu20rVqyw6667zr2u6SKA0slE1UcKffTmiW+ZwcQ8jsT8eqV5cTUp00lF5XFqzKVUUHMflSDef//9bm6m0tDkUMMxPW4w6T8gVXoBCB+bN28Oy+VOk4JzExB+ODcBqf9nJz2+h0NxbkrudWm4UdXN7bffHrJjJ6f4Q9PmOnfu7G4xdenSxd5///2oJuSqLEqIwiuFO7rFJ6HHCPzawMbjcYmr+snrL6Vm5ro/MIAStRZSOJYYefPmdUU28enTp4+7eVSRpcov5SDhKNEBlFam01zGL7/8Mmq+pOeiiy5y8xgVCqnsLLE0pc57Eb2P5dSpU3H+hUBLJqraafny5VFhk1JALaGocrW43syJ/WFQEhpM6SmdB9IKTfdND1UGAMIL5yYg9f/spMf3cLDPTZrelF6Esvm0H8dWNZN6O4cbhVjt2rVz/3or0/lt3rx5bnqgKqDSbACluYtKJVWWphIxzd9ULyZRDyfNu/ziiy9s4cKFrkxOne4Tw5t6p0BLj+nR53HNZ9T8SJ3IAiudNCZt0xgu5D+EcCxfAxBc6a10HkB44NwEJA8/O2nr9U2PIR9CSzmEVtYbP368mwLot+PHj9vkyZPdlLxwlagA6oUXXnBlZaqAiq+sUXMVVQH14osvunmZiaHSNIVJmsPoBVBa6U7zKDt06BBrf82dVMilCilN0/O+Cdu2bXNzJgEAAAAAAIIhsGF4Us1IZG7iUdHMp59+auEsUfVzv//+u6uASmhOre5Tg6zffvst0QfX1yho0vzIzz//3K2K9/DDD7ugqXHjxq7H0969e91ShtKyZUv370MPPeT21a1fv34ujNLSjgAAAAAAAAjTACp//vxuqcTz0dKB3tS8xOrbt6+1adPGBg4c6Lq9a0lClZWpL5OWLFRvKXWnF3WF1/KKmkusZQwVimk/bfMalgEAAAAAACAMp+Cp8khVSuo2f+ONN7qO74G0tKBKwdSJPXDJwMRQ4PTYY4+5W0ylSpWK1b2+bNmyUcsPAgAAAACQVqX1RSaQvt6niQqgtOzf0aNHbejQoTZkyBBX5eQ1AlcTct2nA7Zq1coeeeSRCxs5AAAAAADpmGb6eD2PaZiP1E7v08D37QUFUKpS0hQ5Ndj67rvvbNOmTXbkyBEXOimIUvf3OnXq2EUXXZQyowcAAAAAIJ3SNbha4WiFeK8BNSv9IbVRJqTwSe9TvV/1vr3gAMqj5uA0+wYAAAAAwF+6/hYvhAJSK4VP3vv1ggMorVSnCqgKFSokegBr1661YcOG2axZsxL9NQAAAAAAwFzFU4kSJdxiXGfOnAn1cIA4adrd+SqfkhRAdezY0bp162aVK1e2W2+91Ro2bBjnPFT1gvr666/t3XfftXXr1tnTTz+dqEEAAAAAAIDYdHGf2At8IDVLVAB18803W40aNWzChAn21FNP2dmzZ61cuXJulToFUYcPH7Zdu3bZX3/95VbKu+OOO9yqeYULF/b/GQAAAAAAACBVS3QPqIIFC7ppePfff78tWbLEVqxYYf/++69rRl6gQAErW7asderUyVVH6XMAAAAAAAAgyU3IvSCqbdu27gYAAAAAAACcT8bz7gEAAAAAAABcAAIoAAAAAAAA+IoACgAAAAAAAL4igAIAAAAAAEDqCqB2797tz0gAAAAAAACQJiU5gGrYsKHde++9tmjRIjt9+rQ/owIAAAAAAED6DaCGDx9uERER9uijj1rdunXtmWeesbVr1/ozOgAAAAAAAIS9zEn9ghYtWribpuJ9+OGH9tFHH9msWbOsXLly1rp1a7vtttuscOHC/owWAAAAAAAA6acJebFixaxXr162ePFimzNnjhUoUMBGjhxpDRo0sD59+tiaNWtSdqQAAAAAAABIf6vgrVq1ygYNGmTdunWz1atXW506dax///524sQJu/vuu23q1KkpN1IAAAAAAACkjyl4W7duddPu5s+fb9u3b7eSJUtax44d3fS7EiVKuH06dOjgekS99tpr1rlzZz/GDQAAAAAAgLQaQN18882WLVs2u/HGG23o0KFWu3btOPe77LLLbMuWLSkxRgAAAAAAAKSnAEpT7tRoPE+ePAnud//997sbAAAAAAAA0rck94Bq3769ff311zZ48OCobT/99JO1adPGli1bltLjAwAAAAAAQHoLoObNm2f9+vWzgwcPRm3Lnz+/FSlSxHr37m1Lly5N6TECAAAAAAAgPQVQkydPti5dutjYsWOj9XtSw/F77rnHJkyYkNJjBAAAAAAAQHoKoP755x+7/vrr47yvfv36tmnTppQYFwAAAAAAANJrAKWpdr/++muc961fv94KFCiQEuMCAAAAAABAel0Fr3nz5m66Xc6cOe2mm26yggUL2v79+2358uU2btw469ixoz8jBQAAAAAAQPoIoB544AE3ze65556z559/Pmp7ZGSk3XLLLdanT5+UHiMAAAAAAADSUwCVJUsW14D8zz//tNWrV9uhQ4csT548Vq1aNatQoYI/owQAAAAAAED6CaA8l19+ubvFdPToUcudO/eFjgsAAAAAAADpNYA6ffq0TZs2zVauXOk+1tQ70b/Hjx+3v//+29asWePHWAEAAAAAAJAeAqgXX3zR3n77bVf9pObj2bJlc43INSXvzJkz1rt3b39GCgAAAAAAgLCUMalfsGTJEuvSpYvNnz/fOnToYFdddZW9//77bnvJkiUtIiLCn5ECAAAAAAAgfQRQqnqqX7+++1hVUGvXrnUfFytWzHr06GGLFi1K+VECAAAAAAAg/QRQWvFOvZ+kdOnStnPnTtd4XC699FL3OQAAAAAAAJDsAKp69eo2Y8YMO3HihAugcuTIYUuXLnX3/fzzz6yABwAAAAAAgAsLoB544AH75Zdf3HS7zJkzW7t27WzQoEHWunVrGzNmjN18881JfUgAAAAAAACkYUleBa9ChQq2ePFit+qdPPLII67q6aeffrJGjRq5YAoAAAAAAABIdgClaqc2bdpYnTp13OcZMmSwXr16JfVhAAAAAAAAkE4keQre/Pnz7dixY/6MBgAAAAAAAGlOkgOoqlWr2ooVK/wZDQAAAAAAANKcJE/BK1++vE2ePNk++eQT1w8qZ86c0e7XlLxhw4al5BgBAAAAAACQngKozz77zIoWLWpnzpyxtWvXxrpfARQAAAAAAACQ7ABq2bJlSf0SAAAAAAAApGNJ7gEFAAAAAAAA+FoB1alTp/PuM3369KQ+LAAAAAAAANKoJAdQkZGRsbYdP37cNm7c6BqSN27cOKXGBgAAAAAAgPQYQM2YMSPO7YcOHbLu3bvbZZddlhLjAgAAAAAAQBqRYj2g8uXLZz169LCpU6em1EMCAAAAAAAgDUjxJuT79u1L6YcEAAAAAABAepqC9+OPP8badu7cOdu1a5dNmDDBrrzyypQaGwAAAAAAANJjANWxY0fLkCGDa0aufwMbk5coUcKefPLJlB8lAAAAAAAA0k8ANX369FjbFETlzp3bypcvbxkzpvisPgAAAAAAAISxJKdFNWvWtAoVKtjJkyfdx7qp8umnn36yY8eO+TNKAAAAAAAApJ8AauPGjdasWTMbMmRI1LZ///3Xhg8fbrfffrvt2LEjpccIAAAAAACA9BRAjRw50ooVK2azZs2K2la7dm378ssvLX/+/Pbiiy+m9BgBAAAAAACQngIoTbXr06ePC6ECFSpUyHr16mU//PBDSo4PAAAAAAAA6S2AUsPxEydOxHnf2bNn7cyZMykxLgAAAAAAAKTXAKpGjRr26quv2v79+6NtP3jwoL3++uuuKTkAAAAAAADgyWxJ9Mgjj9idd95pN9xwg1199dVWsGBBO3DggP3yyy+WNWtWGz16dFIfEgAAAAAAAGlYkiugypQpYx9//LG1bdvWjh8/br/99psdPnzYhVLz5s1z9wMAAAAAAADJroASNSDv3r27q36SQ4cO2d69e6148eLJeTgAAAAAAACkYUmugDpy5Ijde++91r59+6hta9assebNm1vfvn3t5MmTKT1GAAAAAAAApKcAatSoUbZu3Trr06dP1LZrr73Wxo0bZz/99JP7FwAAAAAAAEh2ALVs2TJ74oknrGnTplHb1Hz8pptusn79+tmiRYuS+pAAAAAAAABIw5IcQB09etTy5csX531FihSx/fv3p8S4AAAAAAAAkF4DqAoVKticOXPivE+r4JUvXz4lxgUAAAAAAID0ugper1693K1169Zu2l2hQoVc1dPy5ctt7dq19tprr/kzUgAAAAAAAKSPAOr666+3CRMmuGbjY8eOtcjISMuQIYNVrFjRbdf9AAAAAAAAQLIDKGnYsKG7nTp1yg4ePGh58uSxnDlzuvuOHDniPgcAAAAAAACS1QMqULZs2axYsWIufPr1119twIABVr9+fV5ZAAAAAAAAXFgFlOf48eM2f/58e/fdd239+vVuW40aNS7kIQEAAAAAAJDGJCuAWrdunc2aNcsWLlzoQqjSpUvbgw8+aC1atLASJUqk/CgBAAAAAACQ9gMo9Xv6+OOPXbWTVrvLlSuX3XDDDbZgwQIbOnQolU8AAAAAAABIfgD13HPPual2R48etVq1atkLL7xgjRs3ttOnT7vtAAAAAAAAwAUFUG+//baVL1/ehgwZYlWrVo3afubMmcR8OQAAAAAAANKxRK2C17NnTzt06JC1a9fObrvtNps6dart37/f/9EBAAAAAAAgfQRQDz/8sC1fvtwmTpxoZcqUsZdeesnq169vDz30kGXIkMEiIyP9HykAAAAAAADSdhNyBU0KnXRTNZR6P82dO9eFT/fdd59rSN6sWTOrW7euZcqUyd9RAwAAAAAAIO0FUIHy5ctnHTt2dLd169bZnDlz3Ap5CqXy589vP/zwQ8qPFAAAAAAAAGl3Cl5CKlasaAMHDrSvv/7aTc2rVKlSyowMAAAAAAAA6bcCKi5ZsmSxpk2buhsAAAAAAACQYhVQAAAAAAAAQEIIoAAAAAAAABBeAdSuXbtS+iEBAAAAAACQngIoNR3/9ddf47xv1apV1qRJk5QYFwAAAAAAANJTE/IpU6bY8ePH3ceRkZH2/vvv21dffRVrv59//tmyZs2a8qMEAAAAAABA2g6gTp06ZePHj3cfZ8iQwQVQMWXMmNHy5Mlj9913X5IGEBER4R5bj3nkyBGrUaOGDR482C6++OJY+44bNy5qHDG1bt3ahg8fnqRjAwAAAAAAIJUEUAqVvGCpQoUK9u6771qVKlVSZAATJkywmTNn2ogRI6x48eI2cuRIu/fee23BggWxqqm6du1qbdu2jbbtrbfeslmzZlnnzp1TZDwAAAAAAAAIcQ+o9evXxwqfzp49awcPHkzywU+fPu2m9/Xt29caNGjgwq2XX37ZNTJfsmRJrP1z5cplRYoUibrt3bvXpk+f7iqmypcvn+TjAwAAAAAAIBUGUOfOnXPT4FShJCtWrLA6depY7dq17Z577rFDhw4lKcw6duyY+1pP3rx57YorrrAff/zxvF//7LPPWvXq1a1Vq1ZJfRoAAAAAAABITVPwAo0ZM8YmT55sTz75pPv8ueees/z589sDDzzgpsONHj3aBUOJoUonKVGiRLTtRYsWjbovPsuXL3dNz+fNm2cXSo3VvSbrwaJeWjly5AjqMQFcmBMnTrjzRVrGuQkIP5ybgNT/s5Me38PBPjfpWHqdAaShAGrhwoXWr18/a9++vW3cuNH++usv17+pZcuWLoh68cUXEx1A6aQkMXs9ZcuW7byVVAq7GjZsaBUrVrQLdebMGVu3bp0Fk/4DUqUXgPCxefPmqPNWWsW5CQg/nJuA1P+zkx7fw6E4N7EiO5DGAqg9e/ZE9YD64osv3Op39evXd5+ribhWskus7NmzR/WC8j72Vt1L6C8EO3bscFP/3njjDUsJWbJksXLlylkwkc4D4adMmTLposoAQHjh3ASk/p+d9PgeDva56e+//w7asQAEKYDS9Lht27a53kvLli1zFUgFCxZ092lKnEKoxPKm3inUuuSSS6K26/OEmoovXbrUHVO9p1LqP4ScOXOmyGMBSLvSW+k8gPDAuQlIHn520tbrmx5DPiDNNyFv3ry5DR8+3Lp162arV6+222+/3W1//vnnbdy4cXbrrbcm+rG06l3u3LldNZPn8OHD9scff1iNGjXi/bpVq1ZZzZo1LXPmJOdnAAAAAAAACLIkJzgPPfSQqxbSKnWPPPKItWvXzm1fu3atde3a1e6///4kzdHt0KGDjRo1ylU0lSxZ0kaOHOmqqBo3buxW3Nu/f7/lyZMn2hQ9BVRe8AUAAAAAAIA0FkCptLFnz57uFmj27NnJGkDfvn3t7NmzNnDgQDt58qSrfNIqe+rLpKl+N9xwg6u4at26ddTX7N271zU8BwAAAAAAQOqXrDlsahr+wQcf2HfffefCoGHDhtnKlSvtyiuvtMqVKyfpsTJlymSPPfaYu8VUqlQp27BhQ6zta9asSc6wAQAAAAAAEA49oDQlTtPf1PNp69at9uuvv7rKpeXLl1vHjh1dI3IAAAAAAAAg2QHUiy++aMeOHbNFixbZhx9+GLW0phqQV6pUycaOHZvUhwQAAAAAAEAaluQASpVODz74oJUuXTraUpfZsmVzTch///33lB4jAAAAAAAA0lMAderUqXgbgKuf05kzZ1JiXAAAAAAAAEivAZSm2c2cOTPO+xYsWGBXXXVVSowLAAAAAAAA6XUVPE2/69y5s7Vo0cKuv/56Nw3v448/dj2gvvnmG5s0aZI/IwUAAAAAAEDarYDq1KmTbdy40X1cvXp1e+uttyxHjhwubFIT8qlTp9revXtt4sSJdu211/o9ZgAAAAAAAKS1CqiVK1e6le88NWrUsNmzZ9vJkyft0KFDljt3bsuVK5ef4wQAAAAAAEB6mYIXKHv27O4GAAAAAAAApFgTcgAAAAAAAMCXCqgHHnjAsmbNet791JR86dKlSRoEAAAAAAAA0q5EB1BXXHGFFSxY0N/RAAAAAAAAIH1XQFWuXNnf0QAAAAAAACDNoQcUAAAAAAAAfEUABQAAAAAAgNAHUK1atbICBQr4OxIAAAAAAACk3x5Qw4cP938kAAAAAAAASJOYggcAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAADAVwRQAAAAAAAA8BUBFAAAAAAAAHxFAAUAAAAAAABfEUABAAAAAAAgbQdQERERNnbsWKtXr55dffXV1r17d/v333/j3f/MmTM2evToqP07dOhg69atC+qYAQAAAAAAEEYB1IQJE2zmzJk2dOhQmz17tguk7r33Xjt9+nSc+w8ZMsTmzp1rw4YNszlz5ljBggVdaHXkyJGgjx0AAAAAAACpPIBSyDRlyhTr27evNWjQwCpUqGAvv/yy7dq1y5YsWRJrf1VGKXR6/vnnXQVU2bJl7bnnnrOsWbPab7/9FpLnAAAAAAAAgFQcQK1fv96OHTtmtWvXjtqWN29eu+KKK+zHH3+Mtf+3335refLksfr160fbf9myZdEeAwAAAAAAAKlHSAMoVTpJiRIlom0vWrRo1H2BNm/ebBdffLGrjmrdurXVqVPHTb/buHFj0MYMAAAAAACApMlsIXTixAn3r6bQBcqWLZsdOnQo1v5Hjx61rVu3ur5Rjz/+uKt+eu2116xdu3a2aNEiK1SoULLGERkZacePH7dgypAhg+XIkSOoxwRw4ecsnS/SMs5NQPjh3ASk/p+d9PgeDva5ScfS6wwg9QppAJU9e/aoXlDex3Lq1Kk4T9CZM2d2IZT6RKn/k+jj66+/3j788EPXvDw5tLJesFfS0/PTVEMA4UNVmF5wnlZxbgLCD+cmIPX/7KTH93Aozk0xCxsApC4hDaC8qXd79uyxSy65JGq7Pi9fvnys/YsXL+5CKC98EgVXmpa3bdu2ZI8jS5YsVq5cOQsm0nkg/JQpUyZdVBkACC+cm4DU/7OTHt/DwT43/f3330E7FoAwDKC06l3u3LltxYoVUQHU4cOH7Y8//rAOHTrE2r9GjRp29uxZW7t2rVWqVMltO3nypFsdr1mzZhf0H0LOnDkv4JkASA/SW+k8gPDAuQlIHn520tbrmx5DPiDchDSAUomkgqZRo0ZZwYIFrWTJkjZy5EhX6dS4cWM7d+6c7d+/3618p0qn6tWr23XXXWdPPPGEPfvss5Y/f34bO3asZcqUyVq0aBHKpwIAAAAAAIDUuAqe9O3b19q0aWMDBw60u+++24VJkydPdtPidu7caXXr1nUNxj3jxo2zmjVrWu/evd3XqSfU9OnTXYAFAAAAAACA1CekFVCiwOmxxx5zt5hKlSplGzZsiLZNU/aGDBnibgAAAAAAAEj9Ql4BBQAAAAAAgLSNAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAKQbOfNks4iIiFAPAwDSncyhHgAAAAAABEu2HFksY8aMNm/CGNu3Y1tQjnlZ5arW8M52QTkWAKRWBFAAAAAA0h2FT7u2bA7KsQqVKBmU4wBAasYUPAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAABpO4CKiIiwsWPHWr169ezqq6+27t2727///hvv/vPnz7fy5cvHum3bti2o4wYAAAAAAEDiZLYQmzBhgs2cOdNGjBhhxYsXt5EjR9q9995rCxYssKxZs8baf8OGDVazZk176aWXom0vWLBgEEcNAAAAAACAsKiAOn36tE2ZMsX69u1rDRo0sAoVKtjLL79su3btsiVLlsT5NX/++aereCpSpEi0W6ZMmYI+fgAAAAAAAKTyAGr9+vV27Ngxq127dtS2vHnz2hVXXGE//vhjnF+jCqiyZcsGcZQAAAAAAAC4EBkiIyMjLURU5dSnTx9bs2aNZc+ePWr7gw8+aCdPnrSJEydG2//QoUNu+l3z5s1dJdSBAwescuXK9thjj1mZMmWSNYaffvrJ9BJkyZLFgi1Dhgy259BxO3MuIijHy5k1sxXInd3OHdljkedOW7BkyJLTMuUqaHuP7bUz584E5Zg5suSwAjkK2On//rOIM8E5pmTKkcOy5M9vxw6dtHNB+r5myZrZcuTOakcO7LdzZ4P3XLNmy2458+azs0dOWeS54JxGMmbNaJlyZrUjR47Y2bNnLVgyZ85sefLkceeK9CDY56ZQnZ9CcW4K1fkpFOemUJ2fQnFuCtX5iXOT/zg3+Ytzk//S07npzJkz7jxxzTXXBPW4AMKkB9SJEyfcvzF7PWXLls2FTTH99ddf7l+dzIYPH+5Cqtdee83atWvnekYVLlw4yWPQSSrw32Armi9n0I+ZKU9RC4UiuYoE/ZhZk/GeSAm58v2/QDVY8hQITR+0zHmyBf2Y+qUmFEJ1nkgv56ZQnZ9CcW4K1fkpFOemUJ2fQnFuCtX5iXOT/zg3+Ytzk//Sw7lJx0tP50MgHIU0gPKqntQLKrAC6tSpU5YjR45Y+1evXt2+//57K1CgQNTJZfz48a5/1Ny5c61Hjx5JHkPVqlUv6DkAAAAAAAAgFfeAKlGihPt3z5490bbr82LFisX5NVrtLjDZVlBVqlQp2717t8+jBQAAAAAAQNgFUFr1Lnfu3LZixYqobYcPH7Y//vjDatSoEWv/d99912rVqmXHjx+P2nb06FHbsmWLlStXLmjjBgAAAAAAQJgEUOr91KFDBxs1apR9/vnnblW8hx9+2IoXL26NGze2c+fO2d69e12vJ6lfv75FRETY448/7vpBrV271jUxV1VU69atQ/lUAAAAAAAAkBoDKOnbt6+1adPGBg4caHfffbdlypTJJk+e7Fal27lzp9WtW9cWLVoUNWVv6tSprgJK+3bu3Nk11Js+fbprXA4AAAAAAIDUJ0Nkelm7FwAAAAAAAOmzAgoAAAAAAABpGwEUAAAAAAAAfEUABQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwFQEUAAAAAAAAfJXZ34cHQqdRo0a2ffv2qM+zZMlihQsXtuuvv94efPBBK1iwoNtevnx5Gz58uLVu3fq8j3ngwAFbunSp3XHHHe7zjh07WsmSJW3EiBE2d+5cGzBggG3YsCHqvpUrV0Z9bebMma1o0aLWrFkz69u3r2XNmvWCnt+OHTvs559/do8HIPWLeU4IPC/pfPXYY49Zjhw5zvs4K1assE6dOkXblitXLrvyyivtkUcesauvvjre82CgnDlzunNIUsYW136BdD5ctmzZeZ8DgPD7fel8vN+DAuXNm9euueYae+KJJ+yyyy6L2q7fveLzv//9zz7++OM4xybZsmWzYsWKRf0+lTFjxgTPdVKzZk2bMWNGop4HAMA/BFBI07p27epucvLkSfvzzz9t5MiR1qFDB3v33XctT5489s0337h/E+PFF1+0bdu2RQVQ48aNs0yZMsW7f5MmTeypp55yH58+fdr++usvGzhwoJ07d879MnYh9PW62COAAsJH4DlBjh8/7s5BCsEjIiJsyJAhiX6s999/30qUKOG+7tChQ/b2229bt27dbPHixS7sjus8GEgXbUkdm855Z86ccffv3LnTnQu1rWrVqm5bQudDAOH9+1Ji6bwhOm/s27fPXn31VffYn376qQuPPE8++aQ1bdo01tfrD3bxjU0OHz7sznM69yh87969u33wwQfudytRsN6nT5+oc6QXqgEAQo8ACmma/sJfpEiRqM8vvvhiq1ixogttJk2aZA8//HC0+88nMjIy2uf58+dPcP/s2bNHe3wFRqogmDJlygUHUADCT8xzgpQuXdp+++03W7RoUZICKFUleI+laoBBgwbZggULbMmSJe6iMb7z4IWMLfCcd+rUKfdvvnz5knQeBRCevy8lVuDj6Nz09NNPW7169ey7776zhg0bRt2nUCsx546YY9PHvXv3dtWYOjcpgAqs0tI5KeY5EgCQOtADCunORRddZDfddJMtXLgwqgxcZeOiv9SpnLtWrVpWuXJla9u2bdR0k/79+9uHH37oPvdKxxUmaXtS6CIvpjlz5rjqAx1T/06bNs395VBUcaXjTZw40erUqWM33HCDtWrVyo1D41HZOYDwpqoA76/+qj545ZVX3M96pUqVrEWLFq5y4Hz09Rc6tfd8YzsfVXq+8MIL7rx01VVXuWkvmsKzf//+FB8XgOD+vnTkyBEXdF977bVWrVo1NxV47dq1532cxEwt9vvcpCpRVaArCNN05dq1a7vPT5w44cvYAABxI4BCunT55Zfbv//+a8eOHYu2XX/h11/1NZVFlQRlypSx+++/301F0dQUhUOaauKVlyfVpk2bbNasWVFT+ESl7Zrap7/m6Ze8hx56yN58800bNWpUtK9V2KRgShemb731lhuHxqOycwDh6ezZs/bFF1/YRx995IIm6devn82bN89d6M2fP99uvPFGF+Ko/1x8dN7SeUPBdePGjX0b2/noXKYKLPXFU2imf3/44Qd77bXXUmRMAELz+9LRo0ddpZE+1h/E3nvvPddv7u6777Y//vgj3q/X71n6vUUV4Ap9UoKCbp0jv/3220Sfm/THQo1z/Pjx7tykXlV6DP0OBgAIHqbgIV1SU0zRL1SB/vnnH/fLlkrPVamk0OnWW291fU1UAq5t6iOQ2JJuhVhe5YL6puh2ySWXRGsgPGHCBLvvvvuiejnp2BrXM8884y46Pe3atbNy5cpFfa5xaDyJbQ4KIPQCzwletZOqDNS7qVevXrZx40b7/PPP7fXXX7cGDRq4fdTLZP369W6bwihP8+bNLUOGDG5qsB5H/z766KPR+j+JLhY17TcmnYcCp9Wcb2yJoYqtW265xapXr+4+10Xndddd5/rJAAjf35e0uMAvv/ziAmVvKq7C8p9++smmT5/uwmaP1xPOOzfJ6NGjY1WAa2re0KFD4wyL7rrrrnjPYapa0h8I9TuafjdKDFWQ16hRI6qCvVSpUu6PjZybACC4CKCQLqmMXHLnzh1tu6qQtNqTLsJUXl63bl13kRfYNDMpNA1FF4ReNcGuXbvcRaQqoPSXN/1ypm0vvfSSjRkzJurrVMWgigZNv/OOrV4sAMKbd07Qz/6vv/5qzz//vAtoFPBoKom3iqbOP4F04aTzRKA33njD9Vfxqgw0LdernFSlgkdTiTVdOL4Ly8SOLTFUjaA+LxrHli1bXNXn5s2bowIpAOH5+5Iqn3RuCOzh5FUjef3gPPr9RrS/GoYvX77c/W4lgQunqOVBXBWbMf+w5p3D1GT8+++/d2GWgu727dsn+nkoqFKIpmpynZv+/vtv9ztW4Mp8AAD/EUAhXfr999/t0ksvdaunBFKvg6+//trddBGlqW4q11apuZYFTio9fmBwVLZsWVfFVL9+fdc48+abb3bbVQquC72YtHrLnj174u0dBSC8BJ4TdA5StVKXLl1clWVCDch1IRczBFJ1kv6K77niiivcRdXkyZOjBVBqyJuYADu5Yws0ePBgF+C3bNnSBVoPPPCAG8/u3bsT9fUAUufvS6q61h/tvJ6ZgWL2not5vlF/S1VPqYopMIAqVKhQos5NgecwBUY6V2khF1WmB57r4qM/6vXs2dOtRKw/KmrlPfWB0jRnAEBw0QMK6Y4qjjTFRVPrYv4VT8uN6698+uXkueeecz1XtFS5+qCIprtcKG8lPf1CpF++9Jc+HVO/XHk3/cKnngkA0jY181XIo95wX331VdT0kNWrV0fbb9WqVdGm4CZ0fom5WmdKje18Dhw44PqpaFqNQvXWrVu7VbRUBZVSYwIQmt+X1J5A7QHUSiDw9xX1ntM+wTw3KeBWBZQqx72q0YSsW7fOncO0v6o8b7vtNtcOQW0XODcBQHBRAYU0Tc3D9+7d6z5WHwL9oqJgR1UDurCK+Rc8reaiCz39Vaxw4cLuFxY9htfPQH9tU0WSAiP1ajofHdM7vqgK4OWXX3aPo7JzBVr66522qZpBlVEao6oNtAJWQita6S+A27dvd78gFi9e/AJeJQChpF5vuoDTz736MGmKi3rA6fygCzwtTqD7Y4bSWlnOm6KrKb5aHEFNyzVdJb7zYEwFChRIcHpdzLHFrBoNpOoILauu/VVdoPOfeqwoUK9SpUoSXxUAqen3JVVhK1BW3zj1XlKF9syZM11FlKocAwWeb/RYn3zyiesdFXPVYE3vi+/cpN/BEvqjn6ot9ZhayU7Bt/5YGB89ls5zixcvdn/0O3jwoGuHoGPrj48AgOAhgEKapnJvr3Glysf1C5Oqm7p27RrnhZSCIFVBqSm4fjFSqbd6mXj9S/RXt88++8yVcGulp/PRLzu6iX6RUs8VNenV1D6vd4vGoovIGTNmuCae+kXpzjvvdL0REqKLTJWg6y956omgaTIAwo9+/tWIV03BdQ5SryfddJGn/imqPBg3bpybIhwocDVNnd/U8FvnE017i+88GJNW0dQ5KbFj08VefDQGVRjoPKaKCU2bqVWrlmtUrCbCahzs13LsAPz/fUn3jxw50q3Wq59ntRVQm4KYq9upf2bgOURBun5fueeee6LtN2zYMHeLi36vSWiRFVWQq9JSj6sm6J07d453X/2+pfOSzqPvvPOOW0hGizzoa9QXCgAQPBkiqT0FAAAAAACAj+gBBQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwFQEUAAAAAAAAfEUABQAAAAAAAF8RQAEAAAAAAMBXBFAAAAAAAADwFQEUAAAAAAAAfEUABQBAKtOxY0crX768tW3bNt59Hn74YbdP//79L+hYK1ascI+jf/38GgAAAKRvBFAAAKRCGTNmtF9++cV27doV677jx4/b8uXLQzIuAAAAIDkIoAAASIWuuOIKy5Ytm33yySex7lP4lCNHDitWrFhIxgYAAAAkFQEUAACpUM6cOe3666+PM4BatGiR3XzzzZY5c+aobadOnbJXX33VbrnlFqtUqZI1btzY3njjDYuIiIj2tbNnz3ZfW7lyZevQoYPt2LEj1uNrW79+/axmzZpWpUoVu+eee+yPP/7w6ZkCAAAgPSCAAgAglWratGmsaXhHjx61r776ypo3bx61LTIy0nr16mWTJk2yO+64w15//XUXRL3yyiv29NNPR+339ttvu88VbE2YMMGFS4MGDYp2zP3797veU7///ru7b/To0S7Eat++vW3cuDFIzxwAAABpzf/70ykAAEhVGjRo4KbaqQqqc+fObttnn31mhQoVsmrVqkXtp0Dqu+++s5deesmaNWvmttWpU8eyZ89uY8aMsU6dOlm5cuVc6KRQ68knn3T71K1b1wVaqoryTJs2zQ4ePGizZs2ykiVLum3169d3X6fHGjt2bJBfBQAAAKQFVEABAJBKKUBq1KhRtGl4CxcutCZNmliGDBmitq1cudJNx1PVU6Dbbrst6v5NmzbZvn37rGHDhtH20WMF+v77761ixYquv9TZs2fdTQ3RFUIp5AIAAACSgwooAABSMQVEvXv3dtPw1JRcAdFDDz0UbZ9Dhw5ZgQIFLFOmTNG2FylSxP175MgRt49ov7j28aj6aevWrXbllVfGOZ4TJ06kyPMCAABA+kIABQBAKqbKo1y5crkqKDUmL1WqlF111VXR9smXL58dOHDAzp07Fy2E2rNnT1To5AVPqoKKGTgFypMnj2s+/vjjj8c5nqxZs6bYcwMAAED6wRQ8AABSMQU+N954o3366ae2ePHiqB5PgRQYaapczBXz5s+f7/5Vv6hLL73USpQoEWuf5cuXx3qszZs3W5kyZdxqet7to48+sg8++CBWlRUAAACQGFRAAQCQyqkBeM+ePV0vpoEDB8ZZJVWrVi133+7du61ChQqu79Obb75prVq1cg3I5dFHH7VHHnnE7ad+UVphT83GA6nZucIm/du1a1dXObVo0SJ77733bMCAAUF7zgAAAEhbCKAAAEjlrrvuOsubN6+rYCpbtmys+9WQfOLEiW6FuqlTp9r+/fvdVL1+/fpZly5dovZr3ry5C7G0Gp5Cpssvv9yeffZZt59Hzce1Kt7o0aNtyJAhdurUKVc99fzzz1ubNm2C9pwBAACQtmSIjIyMDPUgAAAAAAAAkHbRAwoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAPiKAAoAAAAAAAC+IoACAAAAAACArwigAAAAAAAA4CsCKAAAAAAAAJif/j9KyyzcuhzrCQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All visualization files generated successfully with VERIFIED data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "# from datasets import concatenate_datasets # Not strictly needed for list concatenation fix\n",
    "\n",
    "# Set visual style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. DATASET VISUALIZATION (Part 1) - CORRECTED\n",
    "# ==============================================================================\n",
    "def visualize_dataset(dataset_obj, tokenizer_obj):\n",
    "    print(\"📊 Generating Dataset Visualizations...\")\n",
    "    \n",
    "    # --- A. Class Balance ---\n",
    "    # FIX: Convert columns to Python lists before concatenation\n",
    "    train_labels = list(dataset_obj[\"train\"][\"label\"])\n",
    "    test_labels = list(dataset_obj[\"test\"][\"label\"])\n",
    "    \n",
    "    labels = train_labels + test_labels\n",
    "    label_counts = Counter(labels)\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    # Map numeric labels to text for the plot\n",
    "    label_names = {0: \"Negative\", 1: \"Positive\"}\n",
    "    plot_data = {label_names[k]: v for k, v in label_counts.items()}\n",
    "    \n",
    "    sns.barplot(x=list(plot_data.keys()), y=list(plot_data.values()), palette=\"viridis\", hue=list(plot_data.keys()), legend=False)\n",
    "    plt.title(\"IMDb Dataset Class Balance (Train + Test)\", fontsize=14)\n",
    "    plt.xlabel(\"Sentiment Label\", fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"dataset_class_balance.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # --- B. Sequence Length Distribution ---\n",
    "    # We take a sample to avoid long processing times\n",
    "    sample_size = 5000\n",
    "    # Use .select() and get text directly\n",
    "    subset = dataset_obj[\"train\"].select(range(sample_size))\n",
    "    texts = subset[\"text\"] # This returns a list in newer datasets versions, but let's be safe\n",
    "    \n",
    "    lengths = [len(x) for x in texts]\n",
    "    token_lengths = [len(tokenizer_obj(x)[\"input_ids\"]) for x in texts]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Character Length\n",
    "    sns.histplot(lengths, bins=30, kde=True, ax=axes[0], color=\"skyblue\")\n",
    "    axes[0].set_title(f\"Character Length Distribution (Sample {sample_size})\")\n",
    "    axes[0].set_xlabel(\"Number of Characters\")\n",
    "    \n",
    "    # Token Length\n",
    "    sns.histplot(token_lengths, bins=30, kde=True, ax=axes[1], color=\"orange\")\n",
    "    axes[1].set_title(f\"Token Length Distribution (Sample {sample_size})\")\n",
    "    axes[1].set_xlabel(\"Number of Tokens\")\n",
    "    axes[1].axvline(x=256, color='r', linestyle='--', label='Max Length (256)')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"dataset_length_dist.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Try to run dataset viz if variables exist\n",
    "# Use a safe check for 'dataset'\n",
    "if 'dataset' in locals() and 'tokenizer' in locals():\n",
    "    try:\n",
    "        visualize_dataset(dataset, tokenizer)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error generating dataset visualization: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ 'dataset' or 'tokenizer' not found in local scope. Skipping dataset visualization.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. EXPERIMENTAL RESULTS DATA (Aggregated Mean from outputs.txt)\n",
    "# ==============================================================================\n",
    "# Verified data from your 42 runs (Mean of Seed 42 & 43)\n",
    "DATA = [\n",
    "    # --- DistilBert (DB) ---\n",
    "    {'Model': 'DistilBert', 'Method': 'Full FT', 'ExpID': '01', 'Rank': 0,  'LR': '1e-5', 'Acc': 0.9092, 'VRAM': 2.03, 'Time': 729.5},\n",
    "    {'Model': 'DistilBert', 'Method': 'LoRA r=8', 'ExpID': '02', 'Rank': 8,  'LR': '1e-5', 'Acc': 0.8574, 'VRAM': 2.41, 'Time': 600.7},\n",
    "    {'Model': 'DistilBert', 'Method': 'LoRA r=16', 'ExpID': '03', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.8581, 'VRAM': 2.94, 'Time': 598.5},\n",
    "    {'Model': 'DistilBert', 'Method': 'LoRA (Attn+FFN)', 'ExpID': '04', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.8707, 'VRAM': 3.70, 'Time': 690.3},\n",
    "    {'Model': 'DistilBert', 'Method': 'QLoRA', 'ExpID': '05', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.8704, 'VRAM': 0.71, 'Time': 993.6},\n",
    "    {'Model': 'DistilBert', 'Method': 'IA3', 'ExpID': '06', 'Rank': 0,  'LR': '1e-5', 'Acc': 0.8145, 'VRAM': 1.53, 'Time': 598.3},\n",
    "    {'Model': 'DistilBert', 'Method': 'LoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'LR': '2e-5', 'Acc': 0.8838, 'VRAM': 3.65, 'Time': 703.9},\n",
    "    {'Model': 'DistilBert', 'Method': 'QLoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'LR': '2e-5', 'Acc': 0.8832, 'VRAM': 3.45, 'Time': 989.0},\n",
    "\n",
    "    # --- RoBERTa-Base (RB) ---\n",
    "    {'Model': 'RoBERTa', 'Method': 'Full FT', 'ExpID': '01', 'Rank': 0,  'LR': '1e-5', 'Acc': 0.9390, 'VRAM': 3.81, 'Time': 1461.9},\n",
    "    {'Model': 'RoBERTa', 'Method': 'LoRA r=8', 'ExpID': '02', 'Rank': 8,  'LR': '1e-5', 'Acc': 0.9133, 'VRAM': 4.51, 'Time': 1157.4},\n",
    "    {'Model': 'RoBERTa', 'Method': 'LoRA r=16', 'ExpID': '03', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.9143, 'VRAM': 5.47, 'Time': 1157.1},\n",
    "    {'Model': 'RoBERTa', 'Method': 'LoRA (Attn+FFN)', 'ExpID': '04', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.9236, 'VRAM': 7.01, 'Time': 1374.7},\n",
    "    {'Model': 'RoBERTa', 'Method': 'QLoRA', 'ExpID': '05', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.9102, 'VRAM': 0.59, 'Time': 1949.6},\n",
    "    {'Model': 'RoBERTa', 'Method': 'IA3', 'ExpID': '06', 'Rank': 0,  'LR': '1e-5', 'Acc': 0.8220, 'VRAM': 2.35, 'Time': 1151.6},\n",
    "    {'Model': 'RoBERTa', 'Method': 'LoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'LR': '2e-5', 'Acc': 0.9318, 'VRAM': 2.85, 'Time': 1382.7},\n",
    "    {'Model': 'RoBERTa', 'Method': 'QLoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'LR': '2e-5', 'Acc': 0.9214, 'VRAM': 1.11, 'Time': 1986.3},\n",
    "\n",
    "    # --- DeBERTa-v3 (DBV3) ---\n",
    "    {'Model': 'DeBERTa', 'Method': 'Full FT', 'ExpID': '01', 'Rank': 0,  'LR': '1e-5', 'Acc': 0.9495, 'VRAM': 7.19, 'Time': 2145.4},\n",
    "    {'Model': 'DeBERTa', 'Method': 'LoRA r=8', 'ExpID': '02', 'Rank': 8,  'LR': '1e-5', 'Acc': 0.9133, 'VRAM': 8.34, 'Time': 1760.3},\n",
    "    {'Model': 'DeBERTa', 'Method': 'LoRA r=16', 'ExpID': '03', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.9093, 'VRAM': 4.17, 'Time': 1818.4},\n",
    "    {'Model': 'DeBERTa', 'Method': 'LoRA (Attn+FFN)', 'ExpID': '04', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.9323, 'VRAM': 6.16, 'Time': 2066.2},\n",
    "    {'Model': 'DeBERTa', 'Method': 'QLoRA', 'ExpID': '05', 'Rank': 16, 'LR': '1e-5', 'Acc': 0.9315, 'VRAM': 1.52, 'Time': 2848.3},\n",
    "    {'Model': 'DeBERTa', 'Method': 'IA3', 'ExpID': '06', 'Rank': 0,  'LR': '1e-5', 'Acc': 0.5504, 'VRAM': 4.15, 'Time': 1698.5},\n",
    "    {'Model': 'DeBERTa', 'Method': 'LoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'LR': '2e-5', 'Acc': 0.9368, 'VRAM': 10.3, 'Time': 2017.0},\n",
    "    {'Model': 'DeBERTa', 'Method': 'QLoRA (Opt)', 'ExpID': '07', 'Rank': 16, 'LR': '2e-5', 'Acc': 0.9372, 'VRAM': 8.02, 'Time': 2772.8},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(DATA)\n",
    "print(\"📊 Data loaded. Generating Experiment Plots...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. EXPERIMENTAL VISUALIZATIONS (Part 3)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- A. Overall Accuracy Comparison ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df, x='Model', y='Acc', hue='Method', palette='tab10')\n",
    "plt.title(\"Accuracy Comparison: Full FT vs. PEFT Methods\", fontsize=14)\n",
    "plt.ylabel(\"Test Accuracy (0-1)\", fontsize=12)\n",
    "plt.ylim(0.5, 1.0) \n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Configuration\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparison_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "# --- B. VRAM Efficiency Comparison ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df, x='Model', y='VRAM', hue='Method', palette='rocket')\n",
    "plt.title(\"VRAM Efficiency: Lower is Better\", fontsize=14)\n",
    "plt.ylabel(\"Peak VRAM (GB)\", fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Configuration\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comparison_vram.png\")\n",
    "plt.show()\n",
    "\n",
    "# --- C. LoRA Rank Sensitivity (Line Plot) ---\n",
    "df_rank = df[df['ExpID'].isin(['02', '03'])]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(data=df_rank, x='Rank', y='Acc', hue='Model', style='Model', markers=True, dashes=False, linewidth=2.5)\n",
    "plt.title(r\"Rank Sensitivity: Does r=16 Improve Accuracy?\", fontsize=14)\n",
    "plt.xlabel(\"LoRA Rank (r)\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.xticks([8, 16])\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rank_sensitivity.png\")\n",
    "plt.show()\n",
    "\n",
    "# --- D. Pareto Frontier (VRAM vs Accuracy) ---\n",
    "key_methods = ['Full FT', 'LoRA (Attn+FFN)', 'QLoRA', 'IA3', 'LoRA (Opt)', 'QLoRA (Opt)']\n",
    "df_pareto = df[df['Method'].isin(key_methods)]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    data=df_pareto, \n",
    "    x='VRAM', \n",
    "    y='Acc', \n",
    "    hue='Method', \n",
    "    style='Model', \n",
    "    s=200, \n",
    "    alpha=0.8,\n",
    "    palette='deep'\n",
    ")\n",
    "plt.title(\"Pareto Frontier: VRAM Efficiency vs. Accuracy\", fontsize=14)\n",
    "plt.xlabel(\"Peak VRAM Usage (GB) --> (Lower is Better)\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy --> (Higher is Better)\", fontsize=12)\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pareto_frontier_vram.png\")\n",
    "plt.show()\n",
    "\n",
    "# --- E. Pareto Frontier (Time vs Accuracy) ---\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    data=df_pareto, \n",
    "    x='Time', \n",
    "    y='Acc', \n",
    "    hue='Method', \n",
    "    style='Model', \n",
    "    s=200, \n",
    "    alpha=0.8,\n",
    "    palette='deep'\n",
    ")\n",
    "plt.title(\"Pareto Frontier: Training Time vs. Accuracy\", fontsize=14)\n",
    "plt.xlabel(\"Training Time (s) --> (Lower is Better)\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy --> (Higher is Better)\", fontsize=12)\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pareto_frontier_time.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ All visualization files generated successfully with VERIFIED data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "041ee09b0a33468f92cdaaef84949410": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0bf6d24a73e842d7973292c6353b2118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_3fe12fb8a2594f9b97654b0106adb6fb",
       "max": 24678,
       "style": "IPY_MODEL_6f8b665e3ab241e2abb4ba7e99802ceb",
       "value": 24678
      }
     },
     "10abf9a1728841c9b20cfbe8b690f72c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "172f0eaa9a3b40c29dd2930c69141909": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "17f8697f9e7a4dc2b798f0bcb40d54ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7dc7e45a65644ccfa8cd2194fbeaceb2",
       "style": "IPY_MODEL_172f0eaa9a3b40c29dd2930c69141909",
       "value": "Map: 100%"
      }
     },
     "31ab5a3982ed4d5cb534c41288a5e929": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a92c3a6fbb0045c9a7c0313b0e93493f",
        "IPY_MODEL_0bf6d24a73e842d7973292c6353b2118",
        "IPY_MODEL_3f150e46922c4baba4ab26a308cf7ed6"
       ],
       "layout": "IPY_MODEL_c966de710f6d4a6c89ab10a26210ace4"
      }
     },
     "36dbc263e8464ffe9f0f62406a7eae9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_10abf9a1728841c9b20cfbe8b690f72c",
       "max": 24904,
       "style": "IPY_MODEL_ed1aab6b444a4391868b298a7d44602b",
       "value": 24904
      }
     },
     "3f150e46922c4baba4ab26a308cf7ed6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f64772fb773848e595f86b8b79a5bc69",
       "style": "IPY_MODEL_9bb7c2602e9744a58d6386b27e9bfcd7",
       "value": " 24678/24678 [00:04&lt;00:00, 5240.43 examples/s]"
      }
     },
     "3fe12fb8a2594f9b97654b0106adb6fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5d1f582d48b04573aec78d90876c9e2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_17f8697f9e7a4dc2b798f0bcb40d54ea",
        "IPY_MODEL_36dbc263e8464ffe9f0f62406a7eae9f",
        "IPY_MODEL_6e1b7e10024542179b592f2de4d9dcde"
       ],
       "layout": "IPY_MODEL_7cbe1b4c3f6d41ba8ea748d15465dbd2"
      }
     },
     "69e8fc0ac7664fc1ba5f44dcba730fb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e1b7e10024542179b592f2de4d9dcde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bd36a3fa8eb54326adb9085d17e5ed24",
       "style": "IPY_MODEL_ac7e7cceae1d4cdb8701a68dae97b42b",
       "value": " 24904/24904 [00:04&lt;00:00, 4555.52 examples/s]"
      }
     },
     "6f8b665e3ab241e2abb4ba7e99802ceb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7cbe1b4c3f6d41ba8ea748d15465dbd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7dc7e45a65644ccfa8cd2194fbeaceb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9bb7c2602e9744a58d6386b27e9bfcd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a92c3a6fbb0045c9a7c0313b0e93493f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_69e8fc0ac7664fc1ba5f44dcba730fb1",
       "style": "IPY_MODEL_041ee09b0a33468f92cdaaef84949410",
       "value": "Map: 100%"
      }
     },
     "ac7e7cceae1d4cdb8701a68dae97b42b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bd36a3fa8eb54326adb9085d17e5ed24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c966de710f6d4a6c89ab10a26210ace4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ed1aab6b444a4391868b298a7d44602b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f64772fb773848e595f86b8b79a5bc69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
